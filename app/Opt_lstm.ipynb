{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T21:42:39.19589Z",
     "iopub.status.busy": "2022-11-20T21:42:39.195291Z",
     "iopub.status.idle": "2022-11-20T21:42:41.191513Z",
     "shell.execute_reply": "2022-11-20T21:42:41.190364Z",
     "shell.execute_reply.started": "2022-11-20T21:42:39.195769Z"
    },
    "id": "wIgQxMc3H0qU"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import xgboost\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv = pd.read_csv('cleaned.csv.gz',\n",
    "                 dtype = {\n",
    "                     'store_nbr' : 'category',\n",
    "                     'family' : 'category',\n",
    "                     'sales': 'float',\n",
    "                     'city': 'category',\n",
    "                     'state': 'category',\n",
    "                     'type': 'category',\n",
    "                     'holiday_type': 'category',\n",
    "                     'holiday_transferred': 'category'\n",
    "                 },\n",
    "                  parse_dates=['date'])\n",
    "all_csv['date'] = pd.to_datetime(all_csv['date']).dt.to_period('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = all_csv.copy()  # we can start experimenting from here without reloading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for experimentation\n",
    "\n",
    "filter_by_stores = None  # note: please use string here (unlike Mine.ipynb)\n",
    "filter_by_family = None\n",
    "filter_by_dates = None\n",
    "\n",
    "#filter_by_stores = ['15']  # note: please use string here (unlike Mine.ipynb)\n",
    "#filter_by_family = ['PRODUCE', 'AUTOMOBILE']\n",
    "#filter_by_dates = '2014-06-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_by_dates == None:\n",
    "    train_start_date = '2013-01-01'\n",
    "else:\n",
    "    train_start_date = filter_by_dates\n",
    "train_end_date = '2017-08-15'\n",
    "test_start_date = '2017-08-16'\n",
    "test_end_date = '2017-08-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_by_family != None:\n",
    "    all = all[all['family'].isin(filter_by_family)]\n",
    "if filter_by_stores != None:\n",
    "    all = all[all['store_nbr'].isin(filter_by_stores)]\n",
    "if filter_by_dates != None:\n",
    "    all = all[all['date'] >= filter_by_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '10', '11', '12', '13', ..., '54', '6', '7', '8', '9']\n",
       "Length: 54\n",
       "Categories (54, object): ['1', '10', '11', '12', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all['store_nbr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3036528 entries, 0 to 3036527\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Dtype    \n",
      "---  ------               -----    \n",
      " 0   date                 period[D]\n",
      " 1   store_nbr            category \n",
      " 2   family               category \n",
      " 3   sales                float64  \n",
      " 4   onpromotion          int64    \n",
      " 5   sales_lag_01         float64  \n",
      " 6   sales_lag_02         float64  \n",
      " 7   sales_lag_03         float64  \n",
      " 8   sales_lag_04         float64  \n",
      " 9   sales_lag_05         float64  \n",
      " 10  sales_lag_06         float64  \n",
      " 11  sales_lag_07         float64  \n",
      " 12  sales_lag_08         float64  \n",
      " 13  sales_lag_09         float64  \n",
      " 14  sales_lag_10         float64  \n",
      " 15  sales_lag_11         float64  \n",
      " 16  sales_lag_12         float64  \n",
      " 17  sales_lag_13         float64  \n",
      " 18  sales_lag_14         float64  \n",
      " 19  sales_lag_15         float64  \n",
      " 20  sales_lag_16         float64  \n",
      " 21  sales_lag_17         float64  \n",
      " 22  sales_lag_18         float64  \n",
      " 23  sales_lag_19         float64  \n",
      " 24  sales_lag_20         float64  \n",
      " 25  city                 category \n",
      " 26  state                category \n",
      " 27  type                 category \n",
      " 28  cluster              int64    \n",
      " 29  month                int64    \n",
      " 30  day_of_month         int64    \n",
      " 31  day_of_year          int64    \n",
      " 32  week_of_year         int64    \n",
      " 33  day_of_week          int64    \n",
      " 34  weekday              int64    \n",
      " 35  year                 int64    \n",
      " 36  holiday_type         category \n",
      " 37  holiday_transferred  category \n",
      "dtypes: category(7), float64(21), int64(9), period[D](1)\n",
      "memory usage: 738.4 MB\n"
     ]
    }
   ],
   "source": [
    "all.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dtypes = all.dtypes.to_dict()\n",
    "\n",
    "for col_name, typ in dtypes.items():\n",
    "    if typ == 'float64':\n",
    "        all =all.astype({col_name: 'float32'})\n",
    "    if typ == 'int64':\n",
    "        all =all.astype({col_name: 'int32'})\n",
    "\n",
    "all['store_nbr']=all.store_nbr.astype('int8')\n",
    "\n",
    "all['onpromotion']=all.onpromotion.astype('int16')\n",
    "# all = all.drop(['sales_lag_01', 'sales_lag_02', 'sales_lag_03', 'sales_lag_04', 'sales_lag_05', 'sales_lag_06', 'sales_lag_07', 'sales_lag_08', 'sales_lag_09', 'sales_lag_10'], axis=1)\n",
    "# all = all.drop(['sales_lag_11', 'sales_lag_12', 'sales_lag_13', 'sales_lag_14', 'sales_lag_15', 'sales_lag_16', 'sales_lag_17', 'sales_lag_18', 'sales_lag_19', 'sales_lag_20'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3036528 entries, 0 to 3036527\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Dtype    \n",
      "---  ------               -----    \n",
      " 0   date                 period[D]\n",
      " 1   store_nbr            int8     \n",
      " 2   family               int64    \n",
      " 3   sales                float32  \n",
      " 4   onpromotion          int16    \n",
      " 5   sales_lag_01         float32  \n",
      " 6   sales_lag_02         float32  \n",
      " 7   sales_lag_03         float32  \n",
      " 8   sales_lag_04         float32  \n",
      " 9   sales_lag_05         float32  \n",
      " 10  sales_lag_06         float32  \n",
      " 11  sales_lag_07         float32  \n",
      " 12  sales_lag_08         float32  \n",
      " 13  sales_lag_09         float32  \n",
      " 14  sales_lag_10         float32  \n",
      " 15  sales_lag_11         float32  \n",
      " 16  sales_lag_12         float32  \n",
      " 17  sales_lag_13         float32  \n",
      " 18  sales_lag_14         float32  \n",
      " 19  sales_lag_15         float32  \n",
      " 20  sales_lag_16         float32  \n",
      " 21  sales_lag_17         float32  \n",
      " 22  sales_lag_18         float32  \n",
      " 23  sales_lag_19         float32  \n",
      " 24  sales_lag_20         float32  \n",
      " 25  city                 category \n",
      " 26  state                category \n",
      " 27  type                 category \n",
      " 28  cluster              int32    \n",
      " 29  month                int32    \n",
      " 30  day_of_month         int32    \n",
      " 31  day_of_year          int32    \n",
      " 32  week_of_year         int32    \n",
      " 33  day_of_week          int32    \n",
      " 34  weekday              int32    \n",
      " 35  year                 int32    \n",
      " 36  holiday_type         category \n",
      " 37  holiday_transferred  category \n",
      "dtypes: category(5), float32(21), int16(1), int32(8), int64(1), int8(1), period[D](1)\n",
      "memory usage: 405.4 MB\n"
     ]
    }
   ],
   "source": [
    "all.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "ordinal_encoder = OrdinalEncoder(dtype=int)\n",
    "all[['family']] = ordinal_encoder.fit_transform(all[['family']])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = all[all['date'] <= train_end_date]\n",
    "# X = X.drop(['sales'], axis=1)\n",
    "# y = all[['date', 'sales']][all['date'] <= train_end_date]\n",
    "# y.set_index('date', inplace=True)\n",
    "\n",
    "X_test = all[all['date'] >= test_start_date]\n",
    "# X_test = X_test.drop(['sales'], axis=1)\n",
    "\n",
    "# X.drop('date', axis=1, inplace=True)\n",
    "# X_test.drop('date', axis=1, inplace=True)\n",
    "# y.set_index(X.index, inplace=True)\n",
    "# train_all, val_all = train_test_split(X, random_state=1,shuffle=False, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_data(input_data, idx, cols, value):\n",
    "    return input_data.pivot(index=idx, columns=cols, values=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pivoted = pivot_data(X, ['date'], ['store_nbr', 'family'], 'sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pivoted = pivot_data(X_test, ['date'], ['store_nbr', 'family'], 'sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.734591</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.188285</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>6.059123</td>\n",
       "      <td>6.084499</td>\n",
       "      <td>4.352134</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>5.861031</td>\n",
       "      <td>5.843544</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>6.579994</td>\n",
       "      <td>4.644968</td>\n",
       "      <td>7.603877</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.972054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>6.995766</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.156241</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>6.363028</td>\n",
       "      <td>5.106364</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>5.928341</td>\n",
       "      <td>6.180017</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>6.480492</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>7.643729</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.408305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>6.824374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.741897</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>6.729824</td>\n",
       "      <td>6.118097</td>\n",
       "      <td>5.027702</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>5.996111</td>\n",
       "      <td>5.921578</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>6.235383</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>7.428047</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.258096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>6.860664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.295142</td>\n",
       "      <td>3.091043</td>\n",
       "      <td>6.719013</td>\n",
       "      <td>6.133398</td>\n",
       "      <td>4.885911</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>5.742612</td>\n",
       "      <td>5.783825</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>5.810158</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>7.016474</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>7.057037</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.710616</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>6.699501</td>\n",
       "      <td>6.142037</td>\n",
       "      <td>4.784262</td>\n",
       "      <td>...</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>6.106321</td>\n",
       "      <td>6.135565</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.044523</td>\n",
       "      <td>6.238166</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>7.586124</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.379667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-11</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.914731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.987756</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>5.834811</td>\n",
       "      <td>5.840641</td>\n",
       "      <td>4.179023</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>5.737362</td>\n",
       "      <td>5.924256</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>6.265727</td>\n",
       "      <td>4.728272</td>\n",
       "      <td>7.282127</td>\n",
       "      <td>4.948760</td>\n",
       "      <td>3.212093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>7.414573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.498069</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>5.863631</td>\n",
       "      <td>6.267200</td>\n",
       "      <td>4.610038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.565661</td>\n",
       "      <td>5.993961</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>5.951650</td>\n",
       "      <td>4.874464</td>\n",
       "      <td>7.258598</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>2.882508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-13</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.689599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.924925</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.135798</td>\n",
       "      <td>5.587249</td>\n",
       "      <td>3.887115</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>5.793642</td>\n",
       "      <td>6.236370</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>6.024556</td>\n",
       "      <td>4.665032</td>\n",
       "      <td>7.435206</td>\n",
       "      <td>5.303305</td>\n",
       "      <td>3.044523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>7.697121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.849434</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>6.349139</td>\n",
       "      <td>6.551080</td>\n",
       "      <td>5.047147</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>5.805059</td>\n",
       "      <td>6.100319</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>5.650484</td>\n",
       "      <td>4.745975</td>\n",
       "      <td>7.207434</td>\n",
       "      <td>5.209486</td>\n",
       "      <td>2.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-15</th>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>7.571989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800731</td>\n",
       "      <td>3.091043</td>\n",
       "      <td>6.556778</td>\n",
       "      <td>6.401917</td>\n",
       "      <td>4.765604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>6.109754</td>\n",
       "      <td>6.259582</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>6.084802</td>\n",
       "      <td>5.046987</td>\n",
       "      <td>7.791824</td>\n",
       "      <td>4.804021</td>\n",
       "      <td>2.833213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1688 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "store_nbr          1                                                         \\\n",
       "family            0    1         2         3         4         5         6    \n",
       "date                                                                          \n",
       "2013-01-01  1.098612  0.0  0.693147  6.734591  0.693147  5.188285  2.833213   \n",
       "2013-01-02  1.098612  0.0  1.098612  6.995766  0.693147  6.156241  2.833213   \n",
       "2013-01-03  1.386294  0.0  1.945910  6.824374  0.000000  5.741897  2.564949   \n",
       "2013-01-04  1.386294  0.0  1.386294  6.860664  0.000000  5.295142  3.091043   \n",
       "2013-01-05  1.791759  0.0  1.386294  7.057037  0.693147  5.710616  2.890372   \n",
       "...              ...  ...       ...       ...       ...       ...       ...   \n",
       "2017-08-11  0.693147  0.0  0.693147  6.914731  0.000000  4.987756  1.609438   \n",
       "2017-08-12  1.945910  0.0  1.386294  7.414573  0.000000  5.498069  1.386294   \n",
       "2017-08-13  0.693147  0.0  0.693147  6.689599  0.000000  4.924925  0.693147   \n",
       "2017-08-14  0.693147  0.0  1.945910  7.697121  0.000000  5.849434  1.609438   \n",
       "2017-08-15  1.609438  0.0  1.609438  7.571989  0.000000  5.800731  3.091043   \n",
       "\n",
       "store_nbr                                 ...         9                      \\\n",
       "family            7         8         9   ...        23        24        25   \n",
       "date                                      ...                                 \n",
       "2013-01-01  6.059123  6.084499  4.352134  ...  1.791759  5.861031  5.843544   \n",
       "2013-01-02  6.966967  6.363028  5.106364  ...  2.564949  5.928341  6.180017   \n",
       "2013-01-03  6.729824  6.118097  5.027702  ...  2.484907  5.996111  5.921578   \n",
       "2013-01-04  6.719013  6.133398  4.885911  ...  1.945910  5.742612  5.783825   \n",
       "2013-01-05  6.699501  6.142037  4.784262  ...  2.890372  6.106321  6.135565   \n",
       "...              ...       ...       ...  ...       ...       ...       ...   \n",
       "2017-08-11  5.834811  5.840641  4.179023  ...  1.791759  5.737362  5.924256   \n",
       "2017-08-12  5.863631  6.267200  4.610038  ...  1.098612  5.565661  5.993961   \n",
       "2017-08-13  5.135798  5.587249  3.887115  ...  1.386294  5.793642  6.236370   \n",
       "2017-08-14  6.349139  6.551080  5.047147  ...  2.564949  5.805059  6.100319   \n",
       "2017-08-15  6.556778  6.401917  4.765604  ...  2.484907  6.109754  6.259582   \n",
       "\n",
       "store_nbr                                                               \\\n",
       "family            26        27        28        29        30        31   \n",
       "date                                                                     \n",
       "2013-01-01  2.302585  2.772589  6.579994  4.644968  7.603877  1.386294   \n",
       "2013-01-02  1.609438  2.564949  6.480492  4.430817  7.643729  1.098612   \n",
       "2013-01-03  2.484907  2.397895  6.235383  4.204693  7.428047  1.609438   \n",
       "2013-01-04  1.791759  3.135494  5.810158  4.060443  7.016474  0.693147   \n",
       "2013-01-05  1.945910  3.044523  6.238166  4.442651  7.586124  1.791759   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-08-11  2.484907  1.098612  6.265727  4.728272  7.282127  4.948760   \n",
       "2017-08-12  2.079442  2.397895  5.951650  4.874464  7.258598  4.934474   \n",
       "2017-08-13  1.098612  2.302585  6.024556  4.665032  7.435206  5.303305   \n",
       "2017-08-14  1.098612  2.708050  5.650484  4.745975  7.207434  5.209486   \n",
       "2017-08-15  1.945910  1.945910  6.084802  5.046987  7.791824  4.804021   \n",
       "\n",
       "store_nbr             \n",
       "family            32  \n",
       "date                  \n",
       "2013-01-01  2.972054  \n",
       "2013-01-02  3.408305  \n",
       "2013-01-03  3.258096  \n",
       "2013-01-04  2.484907  \n",
       "2013-01-05  3.379667  \n",
       "...              ...  \n",
       "2017-08-11  3.212093  \n",
       "2017-08-12  2.882508  \n",
       "2017-08-13  3.044523  \n",
       "2017-08-14  2.890372  \n",
       "2017-08-15  2.833213  \n",
       "\n",
       "[1688 rows x 1782 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(X_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int (total_rows* 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all ,val_all = X_pivoted[:train_split], X_pivoted[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot_data(val_all, ['date'], ['store_nbr', 'family'], 'sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.734591</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.188285</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>6.059123</td>\n",
       "      <td>6.084499</td>\n",
       "      <td>4.352134</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>5.861031</td>\n",
       "      <td>5.843544</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>6.579994</td>\n",
       "      <td>4.644968</td>\n",
       "      <td>7.603877</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.972054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>6.995766</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.156241</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>6.363028</td>\n",
       "      <td>5.106364</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>5.928341</td>\n",
       "      <td>6.180017</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>6.480492</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>7.643729</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.408305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>6.824374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.741897</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>6.729824</td>\n",
       "      <td>6.118097</td>\n",
       "      <td>5.027702</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>5.996111</td>\n",
       "      <td>5.921578</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>6.235383</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>7.428047</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.258096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>6.860664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.295142</td>\n",
       "      <td>3.091043</td>\n",
       "      <td>6.719013</td>\n",
       "      <td>6.133398</td>\n",
       "      <td>4.885911</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>5.742612</td>\n",
       "      <td>5.783825</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>5.810158</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>7.016474</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>7.057037</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.710616</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>6.699501</td>\n",
       "      <td>6.142037</td>\n",
       "      <td>4.784262</td>\n",
       "      <td>...</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>6.106321</td>\n",
       "      <td>6.135565</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.044523</td>\n",
       "      <td>6.238166</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>7.586124</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.379667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-23</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>7.562161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.080885</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>6.496775</td>\n",
       "      <td>6.605298</td>\n",
       "      <td>4.448107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.162841</td>\n",
       "      <td>5.799093</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>5.938936</td>\n",
       "      <td>4.884845</td>\n",
       "      <td>7.042297</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-24</th>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>7.827640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.962260</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>6.526495</td>\n",
       "      <td>6.674562</td>\n",
       "      <td>5.265345</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>5.591338</td>\n",
       "      <td>5.817111</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>6.003536</td>\n",
       "      <td>4.569864</td>\n",
       "      <td>6.961898</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-25</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>7.695758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.871577</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>6.480044</td>\n",
       "      <td>6.559615</td>\n",
       "      <td>5.058282</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>6.013371</td>\n",
       "      <td>6.655440</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>6.222509</td>\n",
       "      <td>5.102813</td>\n",
       "      <td>7.506379</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-26</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.538140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.828914</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>5.398163</td>\n",
       "      <td>5.429346</td>\n",
       "      <td>3.820807</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.906138</td>\n",
       "      <td>6.298949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.091043</td>\n",
       "      <td>6.219299</td>\n",
       "      <td>4.836639</td>\n",
       "      <td>7.350065</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.772589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-27</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>6.507277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.662382</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>4.983607</td>\n",
       "      <td>5.214936</td>\n",
       "      <td>3.861319</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>5.987923</td>\n",
       "      <td>6.230482</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>6.136406</td>\n",
       "      <td>4.801033</td>\n",
       "      <td>7.265448</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1519 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "store_nbr          1                                                         \\\n",
       "family            0    1         2         3         4         5         6    \n",
       "date                                                                          \n",
       "2013-01-01  1.098612  0.0  0.693147  6.734591  0.693147  5.188285  2.833213   \n",
       "2013-01-02  1.098612  0.0  1.098612  6.995766  0.693147  6.156241  2.833213   \n",
       "2013-01-03  1.386294  0.0  1.945910  6.824374  0.000000  5.741897  2.564949   \n",
       "2013-01-04  1.386294  0.0  1.386294  6.860664  0.000000  5.295142  3.091043   \n",
       "2013-01-05  1.791759  0.0  1.386294  7.057037  0.693147  5.710616  2.890372   \n",
       "...              ...  ...       ...       ...       ...       ...       ...   \n",
       "2017-02-23  0.693147  0.0  1.791759  7.562161  0.000000  6.080885  3.135494   \n",
       "2017-02-24  2.639057  0.0  1.609438  7.827640  0.000000  5.962260  2.302585   \n",
       "2017-02-25  1.098612  0.0  1.098612  7.695758  0.000000  5.871577  2.079442   \n",
       "2017-02-26  0.693147  0.0  0.693147  6.538140  0.000000  4.828914  1.609438   \n",
       "2017-02-27  1.386294  0.0  1.609438  6.507277  0.000000  4.662382  3.135494   \n",
       "\n",
       "store_nbr                                 ...         9                      \\\n",
       "family            7         8         9   ...        23        24        25   \n",
       "date                                      ...                                 \n",
       "2013-01-01  6.059123  6.084499  4.352134  ...  1.791759  5.861031  5.843544   \n",
       "2013-01-02  6.966967  6.363028  5.106364  ...  2.564949  5.928341  6.180017   \n",
       "2013-01-03  6.729824  6.118097  5.027702  ...  2.484907  5.996111  5.921578   \n",
       "2013-01-04  6.719013  6.133398  4.885911  ...  1.945910  5.742612  5.783825   \n",
       "2013-01-05  6.699501  6.142037  4.784262  ...  2.890372  6.106321  6.135565   \n",
       "...              ...       ...       ...  ...       ...       ...       ...   \n",
       "2017-02-23  6.496775  6.605298  4.448107  ...  0.693147  6.162841  5.799093   \n",
       "2017-02-24  6.526495  6.674562  5.265345  ...  1.386294  5.591338  5.817111   \n",
       "2017-02-25  6.480044  6.559615  5.058282  ...  1.386294  6.013371  6.655440   \n",
       "2017-02-26  5.398163  5.429346  3.820807  ...  1.098612  5.906138  6.298949   \n",
       "2017-02-27  4.983607  5.214936  3.861319  ...  2.484907  5.987923  6.230482   \n",
       "\n",
       "store_nbr                                                               \\\n",
       "family            26        27        28        29        30        31   \n",
       "date                                                                     \n",
       "2013-01-01  2.302585  2.772589  6.579994  4.644968  7.603877  1.386294   \n",
       "2013-01-02  1.609438  2.564949  6.480492  4.430817  7.643729  1.098612   \n",
       "2013-01-03  2.484907  2.397895  6.235383  4.204693  7.428047  1.609438   \n",
       "2013-01-04  1.791759  3.135494  5.810158  4.060443  7.016474  0.693147   \n",
       "2013-01-05  1.945910  3.044523  6.238166  4.442651  7.586124  1.791759   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-02-23  1.386294  2.302585  5.938936  4.884845  7.042297  0.693147   \n",
       "2017-02-24  1.945910  1.791759  6.003536  4.569864  6.961898  1.791759   \n",
       "2017-02-25  2.197225  3.295837  6.222509  5.102813  7.506379  1.098612   \n",
       "2017-02-26  2.564949  3.091043  6.219299  4.836639  7.350065  0.693147   \n",
       "2017-02-27  2.197225  2.564949  6.136406  4.801033  7.265448  1.098612   \n",
       "\n",
       "store_nbr             \n",
       "family            32  \n",
       "date                  \n",
       "2013-01-01  2.972054  \n",
       "2013-01-02  3.408305  \n",
       "2013-01-03  3.258096  \n",
       "2013-01-04  2.484907  \n",
       "2013-01-05  3.379667  \n",
       "...              ...  \n",
       "2017-02-23  2.397895  \n",
       "2017-02-24  2.302585  \n",
       "2017-02-25  2.397895  \n",
       "2017-02-26  2.772589  \n",
       "2017-02-27  2.995732  \n",
       "\n",
       "[1519 rows x 1782 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_all =  pivot_data(train_all, ['date'], ['store_nbr', 'family'], 'sales')\n",
    "#val_all = pivot_data(val_all, ['date'], ['store_nbr', 'family'], 'sales')\n",
    "train_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-02-28</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>6.966024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.907066</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>5.736572</td>\n",
       "      <td>5.891644</td>\n",
       "      <td>4.142087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>6.100101</td>\n",
       "      <td>6.552508</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>6.428296</td>\n",
       "      <td>5.054365</td>\n",
       "      <td>7.951757</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.135494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-01</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>8.114923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.337979</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>6.937314</td>\n",
       "      <td>7.058758</td>\n",
       "      <td>5.116508</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>6.212408</td>\n",
       "      <td>6.447306</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>6.175118</td>\n",
       "      <td>4.859580</td>\n",
       "      <td>7.429440</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-02</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>7.832014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.019537</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>6.829794</td>\n",
       "      <td>6.744059</td>\n",
       "      <td>4.868826</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>6.251804</td>\n",
       "      <td>6.329721</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>6.232340</td>\n",
       "      <td>5.150739</td>\n",
       "      <td>7.383362</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-03</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>7.838737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.152807</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>6.806829</td>\n",
       "      <td>6.792345</td>\n",
       "      <td>5.209464</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>5.921578</td>\n",
       "      <td>6.137727</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>6.301312</td>\n",
       "      <td>4.493110</td>\n",
       "      <td>7.250632</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.833213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-04</th>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>7.854769</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.118198</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>6.624065</td>\n",
       "      <td>6.801283</td>\n",
       "      <td>4.893989</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>6.292228</td>\n",
       "      <td>6.740520</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.091043</td>\n",
       "      <td>6.545467</td>\n",
       "      <td>5.130857</td>\n",
       "      <td>7.720755</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-11</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.914731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.987756</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>5.834811</td>\n",
       "      <td>5.840641</td>\n",
       "      <td>4.179023</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>5.737362</td>\n",
       "      <td>5.924256</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>6.265727</td>\n",
       "      <td>4.728272</td>\n",
       "      <td>7.282127</td>\n",
       "      <td>4.948760</td>\n",
       "      <td>3.212093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>7.414573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.498069</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>5.863631</td>\n",
       "      <td>6.267200</td>\n",
       "      <td>4.610038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.565661</td>\n",
       "      <td>5.993961</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>5.951650</td>\n",
       "      <td>4.874464</td>\n",
       "      <td>7.258598</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>2.882508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-13</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.689599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.924925</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.135798</td>\n",
       "      <td>5.587249</td>\n",
       "      <td>3.887115</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>5.793642</td>\n",
       "      <td>6.236370</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>6.024556</td>\n",
       "      <td>4.665032</td>\n",
       "      <td>7.435206</td>\n",
       "      <td>5.303305</td>\n",
       "      <td>3.044523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>7.697121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.849434</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>6.349139</td>\n",
       "      <td>6.551080</td>\n",
       "      <td>5.047147</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>5.805059</td>\n",
       "      <td>6.100319</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>5.650484</td>\n",
       "      <td>4.745975</td>\n",
       "      <td>7.207434</td>\n",
       "      <td>5.209486</td>\n",
       "      <td>2.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-15</th>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>7.571989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800731</td>\n",
       "      <td>3.091043</td>\n",
       "      <td>6.556778</td>\n",
       "      <td>6.401917</td>\n",
       "      <td>4.765604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>6.109754</td>\n",
       "      <td>6.259582</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>6.084802</td>\n",
       "      <td>5.046987</td>\n",
       "      <td>7.791824</td>\n",
       "      <td>4.804021</td>\n",
       "      <td>2.833213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "store_nbr          1                                                         \\\n",
       "family            0    1         2         3         4         5         6    \n",
       "date                                                                          \n",
       "2017-02-28  1.098612  0.0  1.098612  6.966024  0.000000  4.907066  2.079442   \n",
       "2017-03-01  0.693147  0.0  1.386294  8.114923  0.000000  6.337979  2.708050   \n",
       "2017-03-02  1.386294  0.0  2.197225  7.832014  0.000000  6.019537  3.135494   \n",
       "2017-03-03  1.791759  0.0  2.302585  7.838737  0.000000  6.152807  3.135494   \n",
       "2017-03-04  1.945910  0.0  1.791759  7.854769  0.693147  6.118198  2.079442   \n",
       "...              ...  ...       ...       ...       ...       ...       ...   \n",
       "2017-08-11  0.693147  0.0  0.693147  6.914731  0.000000  4.987756  1.609438   \n",
       "2017-08-12  1.945910  0.0  1.386294  7.414573  0.000000  5.498069  1.386294   \n",
       "2017-08-13  0.693147  0.0  0.693147  6.689599  0.000000  4.924925  0.693147   \n",
       "2017-08-14  0.693147  0.0  1.945910  7.697121  0.000000  5.849434  1.609438   \n",
       "2017-08-15  1.609438  0.0  1.609438  7.571989  0.000000  5.800731  3.091043   \n",
       "\n",
       "store_nbr                                 ...         9                      \\\n",
       "family            7         8         9   ...        23        24        25   \n",
       "date                                      ...                                 \n",
       "2017-02-28  5.736572  5.891644  4.142087  ...  1.791759  6.100101  6.552508   \n",
       "2017-03-01  6.937314  7.058758  5.116508  ...  1.945910  6.212408  6.447306   \n",
       "2017-03-02  6.829794  6.744059  4.868826  ...  1.609438  6.251804  6.329721   \n",
       "2017-03-03  6.806829  6.792345  5.209464  ...  2.079442  5.921578  6.137727   \n",
       "2017-03-04  6.624065  6.801283  4.893989  ...  1.945910  6.292228  6.740520   \n",
       "...              ...       ...       ...  ...       ...       ...       ...   \n",
       "2017-08-11  5.834811  5.840641  4.179023  ...  1.791759  5.737362  5.924256   \n",
       "2017-08-12  5.863631  6.267200  4.610038  ...  1.098612  5.565661  5.993961   \n",
       "2017-08-13  5.135798  5.587249  3.887115  ...  1.386294  5.793642  6.236370   \n",
       "2017-08-14  6.349139  6.551080  5.047147  ...  2.564949  5.805059  6.100319   \n",
       "2017-08-15  6.556778  6.401917  4.765604  ...  2.484907  6.109754  6.259582   \n",
       "\n",
       "store_nbr                                                               \\\n",
       "family            26        27        28        29        30        31   \n",
       "date                                                                     \n",
       "2017-02-28  2.484907  3.295837  6.428296  5.054365  7.951757  1.945910   \n",
       "2017-03-01  2.564949  2.708050  6.175118  4.859580  7.429440  1.609438   \n",
       "2017-03-02  1.609438  2.890372  6.232340  5.150739  7.383362  1.791759   \n",
       "2017-03-03  2.197225  2.708050  6.301312  4.493110  7.250632  1.386294   \n",
       "2017-03-04  2.564949  3.091043  6.545467  5.130857  7.720755  1.945910   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-08-11  2.484907  1.098612  6.265727  4.728272  7.282127  4.948760   \n",
       "2017-08-12  2.079442  2.397895  5.951650  4.874464  7.258598  4.934474   \n",
       "2017-08-13  1.098612  2.302585  6.024556  4.665032  7.435206  5.303305   \n",
       "2017-08-14  1.098612  2.708050  5.650484  4.745975  7.207434  5.209486   \n",
       "2017-08-15  1.945910  1.945910  6.084802  5.046987  7.791824  4.804021   \n",
       "\n",
       "store_nbr             \n",
       "family            32  \n",
       "date                  \n",
       "2017-02-28  3.135494  \n",
       "2017-03-01  2.890372  \n",
       "2017-03-02  1.791759  \n",
       "2017-03-03  2.833213  \n",
       "2017-03-04  3.218876  \n",
       "...              ...  \n",
       "2017-08-11  3.212093  \n",
       "2017-08-12  2.882508  \n",
       "2017-08-13  3.044523  \n",
       "2017-08-14  2.890372  \n",
       "2017-08-15  2.833213  \n",
       "\n",
       "[169 rows x 1782 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1519, 1782)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169, 1782)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>470.652008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>164.069000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374.531006</td>\n",
       "      <td>482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651.291992</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.214001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>310.654999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>151.582001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.863007</td>\n",
       "      <td>372.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.496002</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.365997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>131.410995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>310.877991</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.671997</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.057007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>118.612999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>447.684998</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.919006</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>481.324005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>177.190994</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>264.743988</td>\n",
       "      <td>268.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>477.296021</td>\n",
       "      <td>79.420998</td>\n",
       "      <td>1149.986938</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2379.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.964996</td>\n",
       "      <td>7.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>140.261002</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>373.003998</td>\n",
       "      <td>569.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>503.795013</td>\n",
       "      <td>151.274002</td>\n",
       "      <td>2008.852051</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.529007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>75.682999</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>492.313019</td>\n",
       "      <td>636.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>688.776001</td>\n",
       "      <td>149.067001</td>\n",
       "      <td>2424.743896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.709999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>418.028992</td>\n",
       "      <td>16.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>129.026993</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>319.782013</td>\n",
       "      <td>345.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>321.631989</td>\n",
       "      <td>111.423004</td>\n",
       "      <td>1413.035034</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2365.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>413.152008</td>\n",
       "      <td>8.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>127.908997</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "store_nbr     1                                                          \\\n",
       "family       0    1    2       3    4           5     6       7      8    \n",
       "date                                                                      \n",
       "2013-01-01  0.0  0.0  0.0     0.0  0.0    0.000000   0.0     0.0    0.0   \n",
       "2013-01-02  2.0  0.0  2.0  1091.0  0.0  470.652008   0.0  1060.0  579.0   \n",
       "2013-01-03  3.0  0.0  0.0   919.0  0.0  310.654999   0.0   836.0  453.0   \n",
       "2013-01-04  3.0  0.0  3.0   953.0  0.0  198.365997   0.0   827.0  460.0   \n",
       "2013-01-05  5.0  0.0  3.0  1160.0  0.0  301.057007   0.0   811.0  464.0   \n",
       "...         ...  ...  ...     ...  ...         ...   ...     ...    ...   \n",
       "2017-05-19  5.0  0.0  4.0  2743.0  0.0  481.324005  24.0   826.0  957.0   \n",
       "2017-05-20  4.0  0.0  3.0  2379.0  0.0  392.964996   7.0   588.0  795.0   \n",
       "2017-05-21  1.0  0.0  1.0   974.0  0.0  161.529007   1.0   243.0  337.0   \n",
       "2017-05-22  2.0  0.0  5.0  2620.0  1.0  418.028992  16.0   712.0  754.0   \n",
       "2017-05-23  4.0  0.0  1.0  2365.0  1.0  413.152008   8.0   822.0  736.0   \n",
       "\n",
       "store_nbr               ...    9                                             \\\n",
       "family              9   ...   23          24     25    26    27          28   \n",
       "date                    ...                                                   \n",
       "2013-01-01    0.000000  ...  0.0    0.000000    0.0   0.0   0.0    0.000000   \n",
       "2013-01-02  164.069000  ...  0.0  374.531006  482.0   0.0   0.0  651.291992   \n",
       "2013-01-03  151.582001  ...  0.0  400.863007  372.0   0.0   0.0  509.496002   \n",
       "2013-01-04  131.410995  ...  0.0  310.877991  324.0   0.0   0.0  332.671997   \n",
       "2013-01-05  118.612999  ...  0.0  447.684998  461.0   0.0   0.0  510.919006   \n",
       "...                ...  ...  ...         ...    ...   ...   ...         ...   \n",
       "2017-05-19  177.190994  ...  2.0  264.743988  268.0   6.0   8.0  477.296021   \n",
       "2017-05-20  140.261002  ...  5.0  373.003998  569.0  10.0  12.0  503.795013   \n",
       "2017-05-21   75.682999  ...  2.0  492.313019  636.0  10.0  18.0  688.776001   \n",
       "2017-05-22  129.026993  ...  4.0  319.782013  345.0   8.0   9.0  321.631989   \n",
       "2017-05-23  127.908997  ...  NaN         NaN    NaN   NaN   NaN         NaN   \n",
       "\n",
       "store_nbr                                            \n",
       "family              29           30   31         32  \n",
       "date                                                 \n",
       "2013-01-01    0.000000     0.000000  0.0   0.000000  \n",
       "2013-01-02   83.000000     0.000000  0.0  29.214001  \n",
       "2013-01-03   66.000000     0.000000  0.0  25.000000  \n",
       "2013-01-04   57.000000     0.000000  0.0  11.000000  \n",
       "2013-01-05   84.000000     0.000000  0.0  28.361000  \n",
       "...                ...          ...  ...        ...  \n",
       "2017-05-19   79.420998  1149.986938  2.0   9.238000  \n",
       "2017-05-20  151.274002  2008.852051  3.0  27.380001  \n",
       "2017-05-21  149.067001  2424.743896  7.0  39.709999  \n",
       "2017-05-22  111.423004  1413.035034  2.0  19.097000  \n",
       "2017-05-23         NaN          NaN  NaN        NaN  \n",
       "\n",
       "[1600 rows x 1782 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th colspan=\"10\" halign=\"left\">49</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">48</th>\n",
       "      <th colspan=\"6\" halign=\"left\">49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-23</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>318.722992</td>\n",
       "      <td>377.0</td>\n",
       "      <td>253.345001</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-24</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>377.063995</td>\n",
       "      <td>430.0</td>\n",
       "      <td>340.471008</td>\n",
       "      <td>7220.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.513000</td>\n",
       "      <td>1962.948975</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.826000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1242.181030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-25</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>320.688995</td>\n",
       "      <td>384.0</td>\n",
       "      <td>360.852997</td>\n",
       "      <td>6108.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.520000</td>\n",
       "      <td>1153.500977</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6344.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-26</th>\n",
       "      <td>37.0</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>645.552979</td>\n",
       "      <td>607.0</td>\n",
       "      <td>563.788025</td>\n",
       "      <td>9076.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146.997009</td>\n",
       "      <td>2593.545898</td>\n",
       "      <td>7.0</td>\n",
       "      <td>71.542000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9427.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1509.379028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>485.095001</td>\n",
       "      <td>492.0</td>\n",
       "      <td>468.471008</td>\n",
       "      <td>8151.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.897003</td>\n",
       "      <td>2494.528076</td>\n",
       "      <td>8.0</td>\n",
       "      <td>43.864998</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8284.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1237.318970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-11</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>505.334991</td>\n",
       "      <td>498.0</td>\n",
       "      <td>428.885010</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>149.759003</td>\n",
       "      <td>2218.711914</td>\n",
       "      <td>440.0</td>\n",
       "      <td>34.452999</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1323.130005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>417.339996</td>\n",
       "      <td>433.0</td>\n",
       "      <td>336.897003</td>\n",
       "      <td>7030.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>124.281998</td>\n",
       "      <td>2185.397949</td>\n",
       "      <td>461.0</td>\n",
       "      <td>32.198002</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6667.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1131.045044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>469.890991</td>\n",
       "      <td>542.0</td>\n",
       "      <td>343.044006</td>\n",
       "      <td>7655.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.251999</td>\n",
       "      <td>2856.343994</td>\n",
       "      <td>453.0</td>\n",
       "      <td>36.005001</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.881958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>385.858002</td>\n",
       "      <td>467.0</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>7366.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.668999</td>\n",
       "      <td>1810.298950</td>\n",
       "      <td>325.0</td>\n",
       "      <td>20.320999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1144.526978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-15</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>376.485992</td>\n",
       "      <td>418.0</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.585999</td>\n",
       "      <td>1438.812012</td>\n",
       "      <td>197.0</td>\n",
       "      <td>19.752001</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1019.124023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "store_nbr     49                                                               \\\n",
       "family        6       7       8           9      10          11      12    13   \n",
       "date                                                                            \n",
       "2017-05-23  18.0  1683.0  1961.0  318.722992  377.0  253.345001  6237.0  76.0   \n",
       "2017-05-24  18.0  1915.0  2198.0  377.063995  430.0  340.471008  7220.0  87.0   \n",
       "2017-05-25  39.0  1426.0  1914.0  320.688995  384.0  360.852997  6108.0  51.0   \n",
       "2017-05-26  37.0  2260.0  2821.0  645.552979  607.0  563.788025  9076.0  71.0   \n",
       "2017-05-27  28.0  2066.0  2535.0  485.095001  492.0  468.471008  8151.0  81.0   \n",
       "...          ...     ...     ...         ...    ...         ...     ...   ...   \n",
       "2017-08-11  31.0  1624.0  2241.0  505.334991  498.0  428.885010  7680.0  78.0   \n",
       "2017-08-12  21.0  1666.0  2005.0  417.339996  433.0  336.897003  7030.0  77.0   \n",
       "2017-08-13  13.0  1903.0  2257.0  469.890991  542.0  343.044006  7655.0  79.0   \n",
       "2017-08-14  31.0  1774.0  2190.0  385.858002  467.0  286.000000  7366.0  97.0   \n",
       "2017-08-15  23.0  1765.0  1832.0  376.485992  418.0  274.000000  7001.0  95.0   \n",
       "\n",
       "store_nbr              ...          48                                   49  \\\n",
       "family       14    15  ...          29           30     31         32    0    \n",
       "date                   ...                                                    \n",
       "2017-05-23  2.0  28.0  ...         NaN          NaN    NaN        NaN   NaN   \n",
       "2017-05-24  2.0  36.0  ...  112.513000  1962.948975    9.0  15.826000  15.0   \n",
       "2017-05-25  2.0  23.0  ...   59.520000  1153.500977    2.0  10.000000  10.0   \n",
       "2017-05-26  1.0  39.0  ...  146.997009  2593.545898    7.0  71.542000  14.0   \n",
       "2017-05-27  0.0  59.0  ...  102.897003  2494.528076    8.0  43.864998   7.0   \n",
       "...         ...   ...  ...         ...          ...    ...        ...   ...   \n",
       "2017-08-11  1.0  69.0  ...  149.759003  2218.711914  440.0  34.452999  23.0   \n",
       "2017-08-12  5.0  42.0  ...  124.281998  2185.397949  461.0  32.198002   8.0   \n",
       "2017-08-13  0.0  57.0  ...  103.251999  2856.343994  453.0  36.005001  14.0   \n",
       "2017-08-14  1.0  81.0  ...   91.668999  1810.298950  325.0  20.320999   4.0   \n",
       "2017-08-15  1.0  38.0  ...   80.585999  1438.812012  197.0  19.752001  11.0   \n",
       "\n",
       "store_nbr                                        \n",
       "family       1     2       3    4            5   \n",
       "date                                             \n",
       "2017-05-23  NaN   NaN     NaN  NaN          NaN  \n",
       "2017-05-24  0.0   7.0  6689.0  0.0  1242.181030  \n",
       "2017-05-25  0.0   6.0  6344.0  0.0  1009.799988  \n",
       "2017-05-26  0.0  16.0  9427.0  1.0  1509.379028  \n",
       "2017-05-27  0.0   8.0  8284.0  0.0  1237.318970  \n",
       "...         ...   ...     ...  ...          ...  \n",
       "2017-08-11  0.0  11.0  6696.0  0.0  1323.130005  \n",
       "2017-08-12  0.0   9.0  6667.0  0.0  1131.045044  \n",
       "2017-08-13  0.0  22.0  7178.0  0.0  1189.881958  \n",
       "2017-08-14  0.0  17.0  6154.0  0.0  1144.526978  \n",
       "2017-08-15  0.0  26.0  5820.0  0.0  1019.124023  \n",
       "\n",
       "[85 rows x 1782 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = MinMaxScaler()\n",
    "minmax.fit(X_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_np = minmax.transform(train_all)\n",
    "val_all_np = minmax.transform(val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.any(np.isnan(train_all_np)))\n",
    "# print(np.any(np.isnan(val_all_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_all_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_np = train_all.to_numpy()\n",
    "val_all_np = val_all.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_all_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.analyticsvidhya.com/blog/2020/10/multivariate-multi-step-time-series-forecasting-using-stacked-lstm-sequence-to-sequence-autoencoder-in-tensorflow-2-0-keras/\n",
    "\n",
    "def split_series(series, n_past, n_future):\n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "            break\n",
    "            \n",
    "        # slicing past and future\n",
    "        past, future = series[window_start:past_end,:], series[past_end:future_end,:]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "past = 16\n",
    "future = 16\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_series(train_all_np, past, future)\n",
    "X_val, y_val = split_series(val_all_np, past, future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488, 16, 1782)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488, 16, 1782)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 16, 1782)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 16, 1782)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.39793998, 0.        , 0.3868528 , ..., 0.203269  ,\n",
       "         0.37948874, 0.39053315],\n",
       "        [0.544068  , 0.        , 0.3868528 , ..., 0.28760767,\n",
       "         0.27797046, 0.78258824],\n",
       "        [0.30102998, 0.        , 0.5113916 , ..., 0.551373  ,\n",
       "         0.3591461 , 0.7071954 ],\n",
       "        ...,\n",
       "        [0.17609125, 0.        , 0.3868528 , ..., 0.25937748,\n",
       "         0.        , 0.5308664 ],\n",
       "        [0.30102998, 0.        , 0.22629434, ..., 0.25428677,\n",
       "         0.23943073, 0.4695647 ],\n",
       "        [0.47712123, 0.        , 0.77370554, ..., 0.25095797,\n",
       "         0.18974437, 0.8235892 ]],\n",
       "\n",
       "       [[0.544068  , 0.        , 0.3868528 , ..., 0.28760767,\n",
       "         0.27797046, 0.78258824],\n",
       "        [0.30102998, 0.        , 0.5113916 , ..., 0.551373  ,\n",
       "         0.3591461 , 0.7071954 ],\n",
       "        [0.        , 0.        , 0.22629434, ..., 0.62181425,\n",
       "         0.46771482, 0.83267534],\n",
       "        ...,\n",
       "        [0.30102998, 0.        , 0.22629434, ..., 0.25428677,\n",
       "         0.23943073, 0.4695647 ],\n",
       "        [0.47712123, 0.        , 0.77370554, ..., 0.25095797,\n",
       "         0.18974437, 0.8235892 ],\n",
       "        [0.69896996, 0.        , 0.        , ..., 0.7368474 ,\n",
       "         0.11971536, 0.92146933]],\n",
       "\n",
       "       [[0.30102998, 0.        , 0.5113916 , ..., 0.551373  ,\n",
       "         0.3591461 , 0.7071954 ],\n",
       "        [0.        , 0.        , 0.22629434, ..., 0.62181425,\n",
       "         0.46771482, 0.83267534],\n",
       "        [0.30102998, 0.        , 0.3868528 , ..., 0.43274403,\n",
       "         0.3360835 , 0.6766397 ],\n",
       "        ...,\n",
       "        [0.47712123, 0.        , 0.77370554, ..., 0.25095797,\n",
       "         0.18974437, 0.8235892 ],\n",
       "        [0.69896996, 0.        , 0.        , ..., 0.7368474 ,\n",
       "         0.11971536, 0.92146933],\n",
       "        [0.39793998, 0.        , 0.        , ..., 0.65785027,\n",
       "         0.23943073, 0.65998495]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.39793998, 0.        , 0.3868528 , ..., 0.4885707 ,\n",
       "         0.5338625 , 0.75867665],\n",
       "        [0.        , 0.        , 0.22629434, ..., 0.53605556,\n",
       "         0.6455432 , 0.73349714],\n",
       "        [0.6532125 , 0.        , 0.3868528 , ..., 0.4059596 ,\n",
       "         0.69828653, 0.6029426 ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.37975883,\n",
       "         0.854714  , 0.7807249 ],\n",
       "        [0.544068  , 0.        , 0.3868528 , ..., 0.3655486 ,\n",
       "         0.85224664, 0.69018173],\n",
       "        [0.        , 0.        , 0.        , ..., 0.47220516,\n",
       "         0.9159484 , 0.7346902 ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.22629434, ..., 0.53605556,\n",
       "         0.6455432 , 0.73349714],\n",
       "        [0.6532125 , 0.        , 0.3868528 , ..., 0.4059596 ,\n",
       "         0.69828653, 0.6029426 ],\n",
       "        [0.47712123, 0.        , 0.5113916 , ..., 0.70009804,\n",
       "         0.91850716, 0.7255932 ],\n",
       "        ...,\n",
       "        [0.544068  , 0.        , 0.3868528 , ..., 0.3655486 ,\n",
       "         0.85224664, 0.69018173],\n",
       "        [0.        , 0.        , 0.        , ..., 0.47220516,\n",
       "         0.9159484 , 0.7346902 ],\n",
       "        [0.        , 0.        , 0.6991802 , ..., 0.33465004,\n",
       "         0.8997447 , 0.69234216]],\n",
       "\n",
       "       [[0.6532125 , 0.        , 0.3868528 , ..., 0.4059596 ,\n",
       "         0.69828653, 0.6029426 ],\n",
       "        [0.47712123, 0.        , 0.5113916 , ..., 0.70009804,\n",
       "         0.91850716, 0.7255932 ],\n",
       "        [0.39793998, 0.        , 0.22629434, ..., 0.32810736,\n",
       "         0.8654007 , 0.79005706],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.47220516,\n",
       "         0.9159484 , 0.7346902 ],\n",
       "        [0.        , 0.        , 0.6991802 , ..., 0.33465004,\n",
       "         0.8997447 , 0.69234216],\n",
       "        [0.39793998, 0.        , 0.5113916 , ..., 0.687572  ,\n",
       "         0.82971567, 0.6766397 ]]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = len(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed, BatchNormalization\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 16, 50)            366600    \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 16, 1782)         90882     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 457,482\n",
      "Trainable params: 457,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_basic = Sequential()\n",
    "model_basic.add(LSTM(units = 50, activation='relu', return_sequences = True, input_shape = (past, number_of_features))) \n",
    "model_basic.add(TimeDistributed(Dense(number_of_features)))\n",
    "model_basic.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "model_basic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 3s 41ms/step - loss: 0.2521 - mae: 0.2521 - val_loss: 0.1389 - val_mae: 0.1389\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.1195 - mae: 0.1195 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 2s 41ms/step - loss: 0.1153 - mae: 0.1153 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.1129 - mae: 0.1129 - val_loss: 0.1259 - val_mae: 0.1259\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.1092 - mae: 0.1092 - val_loss: 0.1216 - val_mae: 0.1216\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 2s 32ms/step - loss: 0.1035 - mae: 0.1035 - val_loss: 0.1191 - val_mae: 0.1191\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.1000 - mae: 0.1000 - val_loss: 0.1174 - val_mae: 0.1174\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0984 - mae: 0.0984 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0965 - mae: 0.0965 - val_loss: 0.1119 - val_mae: 0.1119\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1094 - val_mae: 0.1094\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1074 - val_mae: 0.1074\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1063 - val_mae: 0.1063\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1060 - val_mae: 0.1060\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.0910 - mae: 0.0910 - val_loss: 0.1051 - val_mae: 0.1051\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0904 - mae: 0.0904 - val_loss: 0.1042 - val_mae: 0.1042\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0899 - mae: 0.0899 - val_loss: 0.1032 - val_mae: 0.1032\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 2s 32ms/step - loss: 0.0894 - mae: 0.0894 - val_loss: 0.1024 - val_mae: 0.1024\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0893 - mae: 0.0893 - val_loss: 0.1030 - val_mae: 0.1030\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0887 - mae: 0.0887 - val_loss: 0.1017 - val_mae: 0.1017\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0880 - mae: 0.0880 - val_loss: 0.1017 - val_mae: 0.1017\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0875 - mae: 0.0875 - val_loss: 0.1017 - val_mae: 0.1017\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.0873 - mae: 0.0873 - val_loss: 0.1018 - val_mae: 0.1018\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0869 - mae: 0.0869 - val_loss: 0.1015 - val_mae: 0.1015\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 2s 32ms/step - loss: 0.0868 - mae: 0.0868 - val_loss: 0.1012 - val_mae: 0.1012\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0862 - mae: 0.0862 - val_loss: 0.1014 - val_mae: 0.1014\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0861 - mae: 0.0861 - val_loss: 0.1007 - val_mae: 0.1007\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0856 - mae: 0.0856 - val_loss: 0.1020 - val_mae: 0.1020\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0858 - mae: 0.0858 - val_loss: 0.1016 - val_mae: 0.1016\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0856 - mae: 0.0856 - val_loss: 0.1020 - val_mae: 0.1020\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0852 - mae: 0.0852 - val_loss: 0.1010 - val_mae: 0.1010\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 2s 40ms/step - loss: 0.0848 - mae: 0.0848 - val_loss: 0.1010 - val_mae: 0.1010\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0848 - mae: 0.0848 - val_loss: 0.1028 - val_mae: 0.1028\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0846 - mae: 0.0846 - val_loss: 0.1017 - val_mae: 0.1017\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0843 - mae: 0.0843 - val_loss: 0.1007 - val_mae: 0.1007\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0849 - mae: 0.0849 - val_loss: 0.1021 - val_mae: 0.1021\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0837 - mae: 0.0837 - val_loss: 0.1012 - val_mae: 0.1012\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 2s 42ms/step - loss: 0.0836 - mae: 0.0836 - val_loss: 0.1012 - val_mae: 0.1012\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.0835 - mae: 0.0835 - val_loss: 0.1004 - val_mae: 0.1004\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.0834 - mae: 0.0834 - val_loss: 0.1001 - val_mae: 0.1001\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.0831 - mae: 0.0831 - val_loss: 0.0999 - val_mae: 0.0999\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0828 - mae: 0.0828 - val_loss: 0.1003 - val_mae: 0.1003\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0827 - mae: 0.0827 - val_loss: 0.0996 - val_mae: 0.0996\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0824 - mae: 0.0824 - val_loss: 0.1012 - val_mae: 0.1012\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 2s 32ms/step - loss: 0.0825 - mae: 0.0825 - val_loss: 0.1003 - val_mae: 0.1003\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0821 - mae: 0.0821 - val_loss: 0.0992 - val_mae: 0.0992\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 2s 36ms/step - loss: 0.0820 - mae: 0.0820 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0818 - mae: 0.0818 - val_loss: 0.0998 - val_mae: 0.0998\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.0816 - mae: 0.0816 - val_loss: 0.0993 - val_mae: 0.0993\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.0813 - mae: 0.0813 - val_loss: 0.1016 - val_mae: 0.1016\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0813 - mae: 0.0813 - val_loss: 0.1008 - val_mae: 0.1008\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0818 - mae: 0.0818 - val_loss: 0.0999 - val_mae: 0.0999\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 2s 32ms/step - loss: 0.0817 - mae: 0.0817 - val_loss: 0.0996 - val_mae: 0.0996\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0808 - mae: 0.0808 - val_loss: 0.0999 - val_mae: 0.0999\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0808 - mae: 0.0808 - val_loss: 0.1027 - val_mae: 0.1027\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 2s 36ms/step - loss: 0.0812 - mae: 0.0812 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0806 - mae: 0.0806 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 1s 32ms/step - loss: 0.0806 - mae: 0.0806 - val_loss: 0.0996 - val_mae: 0.0996\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.0805 - mae: 0.0805 - val_loss: 0.0993 - val_mae: 0.0993\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0807 - mae: 0.0807 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0806 - mae: 0.0806 - val_loss: 0.0992 - val_mae: 0.0992\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0804 - mae: 0.0804 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0825 - mae: 0.0825 - val_loss: 0.0993 - val_mae: 0.0993\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 2s 40ms/step - loss: 0.0805 - mae: 0.0805 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.0802 - mae: 0.0802 - val_loss: 0.0998 - val_mae: 0.0998\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0800 - mae: 0.0800 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 2s 41ms/step - loss: 0.0800 - mae: 0.0800 - val_loss: 0.1000 - val_mae: 0.1000\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 0.0800 - mae: 0.0800 - val_loss: 0.0994 - val_mae: 0.0994\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 2s 33ms/step - loss: 0.0800 - mae: 0.0800 - val_loss: 0.0992 - val_mae: 0.0992\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.0989 - val_mae: 0.0989\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.0803 - mae: 0.0803 - val_loss: 0.0992 - val_mae: 0.0992\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.0802 - mae: 0.0802 - val_loss: 0.1000 - val_mae: 0.1000\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.0809 - mae: 0.0809 - val_loss: 0.0994 - val_mae: 0.0994\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 1s 31ms/step - loss: 0.0800 - mae: 0.0800 - val_loss: 0.0986 - val_mae: 0.0986\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 1s 30ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.0991 - val_mae: 0.0991\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.0987 - val_mae: 0.0987\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.0989 - val_mae: 0.0989\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0797 - mae: 0.0797 - val_loss: 0.1001 - val_mae: 0.1001\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0797 - mae: 0.0797 - val_loss: 0.0989 - val_mae: 0.0989\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 2s 40ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 0.0799 - mae: 0.0799 - val_loss: 0.0990 - val_mae: 0.0990\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 2s 36ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.1000 - val_mae: 0.1000\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0795 - mae: 0.0795 - val_loss: 0.0993 - val_mae: 0.0993\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0796 - mae: 0.0796 - val_loss: 0.0997 - val_mae: 0.0997\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 2s 34ms/step - loss: 0.0797 - mae: 0.0797 - val_loss: 0.0990 - val_mae: 0.0990\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.0796 - mae: 0.0796 - val_loss: 0.0994 - val_mae: 0.0994\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 2s 40ms/step - loss: 0.0798 - mae: 0.0798 - val_loss: 0.0993 - val_mae: 0.0993\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.0795 - mae: 0.0795 - val_loss: 0.0986 - val_mae: 0.0986\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.0796 - mae: 0.0796 - val_loss: 0.0987 - val_mae: 0.0987\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0797 - mae: 0.0797 - val_loss: 0.0991 - val_mae: 0.0991\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0795 - mae: 0.0795 - val_loss: 0.0992 - val_mae: 0.0992\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 2s 36ms/step - loss: 0.0795 - mae: 0.0795 - val_loss: 0.0989 - val_mae: 0.0989\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0795 - mae: 0.0795 - val_loss: 0.0998 - val_mae: 0.0998\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0796 - mae: 0.0796 - val_loss: 0.0990 - val_mae: 0.0990\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 2s 42ms/step - loss: 0.0794 - mae: 0.0794 - val_loss: 0.0995 - val_mae: 0.0995\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0796 - mae: 0.0796 - val_loss: 0.0987 - val_mae: 0.0987\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 2s 41ms/step - loss: 0.0794 - mae: 0.0794 - val_loss: 0.0988 - val_mae: 0.0988\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0793 - mae: 0.0793 - val_loss: 0.0992 - val_mae: 0.0992\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0797 - mae: 0.0797 - val_loss: 0.0990 - val_mae: 0.0990\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0793 - mae: 0.0793 - val_loss: 0.0985 - val_mae: 0.0985\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 2s 35ms/step - loss: 0.0791 - mae: 0.0791 - val_loss: 0.0985 - val_mae: 0.0985\n"
     ]
    }
   ],
   "source": [
    "history_model_basic = model_basic.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # summarize history for accuracy\n",
    "    # summarize history for loss\n",
    "    plt.ylim(0, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 16, 256)           2087936   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16, 256)           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 16, 128)           197120    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 16, 64)            49408     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16, 64)            0         \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 16, 1782)         115830    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,452,086\n",
      "Trainable params: 2,451,190\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " \n",
    "model_multi_layers = Sequential()    \n",
    "    \n",
    "    \n",
    "model_multi_layers.add(LSTM(units = 256, activation='relu', return_sequences = True, input_shape = (past, number_of_features))) \n",
    "model_multi_layers.add(BatchNormalization())\n",
    "model_multi_layers.add(Dropout(0.3))\n",
    "        \n",
    "     \n",
    "model_multi_layers.add(LSTM(units = 128,  activation='relu', return_sequences = True))       \n",
    "model_multi_layers.add(BatchNormalization())                             \n",
    "model_multi_layers.add(Dropout(0.2))\n",
    "        \n",
    "    \n",
    "model_multi_layers.add(LSTM(units = 64,  activation='relu', return_sequences = True))  \n",
    "model_multi_layers.add(BatchNormalization())   \n",
    "model_multi_layers.add(Dropout(0.2))\n",
    "\n",
    "model_multi_layers.add(TimeDistributed(Dense(number_of_features)))\n",
    "model_multi_layers.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "model_multi_layers.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi_layers.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "6/6 [==============================] - 7s 546ms/step - loss: 0.4393 - mae: 0.4393 - val_loss: 2419.1946 - val_mae: 2419.1946\n",
      "Epoch 2/800\n",
      "6/6 [==============================] - 3s 439ms/step - loss: 0.3516 - mae: 0.3516 - val_loss: 910.7857 - val_mae: 910.7857\n",
      "Epoch 3/800\n",
      "6/6 [==============================] - 3s 563ms/step - loss: 0.2436 - mae: 0.2436 - val_loss: 106.8340 - val_mae: 106.8340\n",
      "Epoch 4/800\n",
      "6/6 [==============================] - 3s 556ms/step - loss: 0.2219 - mae: 0.2219 - val_loss: 0.6472 - val_mae: 0.6472\n",
      "Epoch 5/800\n",
      "6/6 [==============================] - 3s 525ms/step - loss: 0.1700 - mae: 0.1700 - val_loss: 0.1600 - val_mae: 0.1600\n",
      "Epoch 6/800\n",
      "6/6 [==============================] - 3s 468ms/step - loss: 0.1507 - mae: 0.1507 - val_loss: 0.1351 - val_mae: 0.1351\n",
      "Epoch 7/800\n",
      "6/6 [==============================] - 3s 498ms/step - loss: 0.1399 - mae: 0.1399 - val_loss: 0.1292 - val_mae: 0.1292\n",
      "Epoch 8/800\n",
      "6/6 [==============================] - 3s 525ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.1346 - val_mae: 0.1346\n",
      "Epoch 9/800\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.1359 - mae: 0.1359 - val_loss: 0.1329 - val_mae: 0.1329\n",
      "Epoch 10/800\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.1341 - mae: 0.1341 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 11/800\n",
      "6/6 [==============================] - 3s 493ms/step - loss: 0.1333 - mae: 0.1333 - val_loss: 0.1401 - val_mae: 0.1401\n",
      "Epoch 12/800\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 0.1295 - mae: 0.1295 - val_loss: 0.1329 - val_mae: 0.1329\n",
      "Epoch 13/800\n",
      "6/6 [==============================] - 3s 494ms/step - loss: 0.1344 - mae: 0.1344 - val_loss: 0.1322 - val_mae: 0.1322\n",
      "Epoch 14/800\n",
      "6/6 [==============================] - 3s 523ms/step - loss: 0.1299 - mae: 0.1299 - val_loss: 0.1357 - val_mae: 0.1357\n",
      "Epoch 15/800\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.1264 - mae: 0.1264 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 16/800\n",
      "6/6 [==============================] - 3s 450ms/step - loss: 0.1291 - mae: 0.1291 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 17/800\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.1253 - mae: 0.1253 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 18/800\n",
      "6/6 [==============================] - 3s 457ms/step - loss: 0.1286 - mae: 0.1286 - val_loss: 0.1420 - val_mae: 0.1420\n",
      "Epoch 19/800\n",
      "6/6 [==============================] - 2s 411ms/step - loss: 0.1238 - mae: 0.1238 - val_loss: 0.1385 - val_mae: 0.1385\n",
      "Epoch 20/800\n",
      "6/6 [==============================] - 3s 515ms/step - loss: 0.1215 - mae: 0.1215 - val_loss: 0.1389 - val_mae: 0.1389\n",
      "Epoch 21/800\n",
      "6/6 [==============================] - 3s 505ms/step - loss: 0.1240 - mae: 0.1240 - val_loss: 0.1425 - val_mae: 0.1425\n",
      "Epoch 22/800\n",
      "6/6 [==============================] - 3s 456ms/step - loss: 0.1224 - mae: 0.1224 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 23/800\n",
      "6/6 [==============================] - 3s 510ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.1420 - val_mae: 0.1420\n",
      "Epoch 24/800\n",
      "6/6 [==============================] - 3s 469ms/step - loss: 0.1215 - mae: 0.1215 - val_loss: 0.1421 - val_mae: 0.1421\n",
      "Epoch 25/800\n",
      "6/6 [==============================] - 3s 561ms/step - loss: 0.1208 - mae: 0.1208 - val_loss: 0.1429 - val_mae: 0.1429\n",
      "Epoch 26/800\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.1451 - val_mae: 0.1451\n",
      "Epoch 27/800\n",
      "6/6 [==============================] - 3s 503ms/step - loss: 0.1216 - mae: 0.1216 - val_loss: 0.1418 - val_mae: 0.1418\n",
      "Epoch 28/800\n",
      "6/6 [==============================] - 3s 531ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.1421 - val_mae: 0.1421\n",
      "Epoch 29/800\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 30/800\n",
      "6/6 [==============================] - 3s 461ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.1414 - val_mae: 0.1414\n",
      "Epoch 31/800\n",
      "6/6 [==============================] - 3s 453ms/step - loss: 0.1202 - mae: 0.1202 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 32/800\n",
      "6/6 [==============================] - 4s 618ms/step - loss: 0.1206 - mae: 0.1206 - val_loss: 0.1407 - val_mae: 0.1407\n",
      "Epoch 33/800\n",
      "6/6 [==============================] - 3s 512ms/step - loss: 0.1202 - mae: 0.1202 - val_loss: 0.1403 - val_mae: 0.1403\n",
      "Epoch 34/800\n",
      "6/6 [==============================] - 3s 493ms/step - loss: 0.1192 - mae: 0.1192 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 35/800\n",
      "6/6 [==============================] - 3s 511ms/step - loss: 0.1195 - mae: 0.1195 - val_loss: 0.1401 - val_mae: 0.1401\n",
      "Epoch 36/800\n",
      "6/6 [==============================] - 3s 500ms/step - loss: 0.1187 - mae: 0.1187 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 37/800\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.1187 - mae: 0.1187 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 38/800\n",
      "6/6 [==============================] - 3s 421ms/step - loss: 0.1188 - mae: 0.1188 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 39/800\n",
      "6/6 [==============================] - 2s 412ms/step - loss: 0.1186 - mae: 0.1186 - val_loss: 0.1372 - val_mae: 0.1372\n",
      "Epoch 40/800\n",
      "6/6 [==============================] - 3s 434ms/step - loss: 0.1189 - mae: 0.1189 - val_loss: 0.1386 - val_mae: 0.1386\n",
      "Epoch 41/800\n",
      "6/6 [==============================] - 2s 411ms/step - loss: 0.1191 - mae: 0.1191 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 42/800\n",
      "6/6 [==============================] - 2s 412ms/step - loss: 0.1179 - mae: 0.1179 - val_loss: 0.1395 - val_mae: 0.1395\n",
      "Epoch 43/800\n",
      "6/6 [==============================] - 2s 414ms/step - loss: 0.1179 - mae: 0.1179 - val_loss: 0.1388 - val_mae: 0.1388\n",
      "Epoch 44/800\n",
      "6/6 [==============================] - 2s 405ms/step - loss: 0.1179 - mae: 0.1179 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 45/800\n",
      "6/6 [==============================] - 2s 395ms/step - loss: 0.1174 - mae: 0.1174 - val_loss: 0.1380 - val_mae: 0.1380\n",
      "Epoch 46/800\n",
      "6/6 [==============================] - 2s 423ms/step - loss: 0.1181 - mae: 0.1181 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 47/800\n",
      "6/6 [==============================] - 2s 416ms/step - loss: 0.1172 - mae: 0.1172 - val_loss: 0.1403 - val_mae: 0.1403\n",
      "Epoch 48/800\n",
      "6/6 [==============================] - 2s 392ms/step - loss: 0.1181 - mae: 0.1181 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 49/800\n",
      "6/6 [==============================] - 2s 394ms/step - loss: 0.1171 - mae: 0.1171 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 50/800\n",
      "6/6 [==============================] - 2s 389ms/step - loss: 0.1175 - mae: 0.1175 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 51/800\n",
      "6/6 [==============================] - 2s 389ms/step - loss: 0.1180 - mae: 0.1180 - val_loss: 0.1379 - val_mae: 0.1379\n",
      "Epoch 52/800\n",
      "6/6 [==============================] - 2s 388ms/step - loss: 0.1172 - mae: 0.1172 - val_loss: 0.1379 - val_mae: 0.1379\n",
      "Epoch 53/800\n",
      "6/6 [==============================] - 2s 387ms/step - loss: 0.1174 - mae: 0.1174 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 54/800\n",
      "6/6 [==============================] - 2s 386ms/step - loss: 0.1171 - mae: 0.1171 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 55/800\n",
      "6/6 [==============================] - 2s 388ms/step - loss: 0.1188 - mae: 0.1188 - val_loss: 0.1496 - val_mae: 0.1496\n",
      "Epoch 56/800\n",
      "6/6 [==============================] - 2s 378ms/step - loss: 0.1188 - mae: 0.1188 - val_loss: 0.1478 - val_mae: 0.1478\n",
      "Epoch 57/800\n",
      "6/6 [==============================] - 2s 375ms/step - loss: 0.1185 - mae: 0.1185 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 58/800\n",
      "6/6 [==============================] - 2s 377ms/step - loss: 0.1183 - mae: 0.1183 - val_loss: 0.1492 - val_mae: 0.1492\n",
      "Epoch 59/800\n",
      "6/6 [==============================] - 2s 377ms/step - loss: 0.1180 - mae: 0.1180 - val_loss: 0.1474 - val_mae: 0.1474\n",
      "Epoch 60/800\n",
      "6/6 [==============================] - 2s 390ms/step - loss: 0.1180 - mae: 0.1180 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 61/800\n",
      "6/6 [==============================] - 2s 413ms/step - loss: 0.1178 - mae: 0.1178 - val_loss: 0.1449 - val_mae: 0.1449\n",
      "Epoch 62/800\n",
      "6/6 [==============================] - 2s 396ms/step - loss: 0.1173 - mae: 0.1173 - val_loss: 0.1454 - val_mae: 0.1454\n",
      "Epoch 63/800\n",
      "6/6 [==============================] - 2s 388ms/step - loss: 0.1178 - mae: 0.1178 - val_loss: 0.1424 - val_mae: 0.1424\n",
      "Epoch 64/800\n",
      "6/6 [==============================] - 2s 390ms/step - loss: 0.1171 - mae: 0.1171 - val_loss: 0.1408 - val_mae: 0.1408\n",
      "Epoch 65/800\n",
      "6/6 [==============================] - 2s 408ms/step - loss: 0.1167 - mae: 0.1167 - val_loss: 0.1368 - val_mae: 0.1368\n",
      "Epoch 66/800\n",
      "6/6 [==============================] - 2s 417ms/step - loss: 0.1170 - mae: 0.1170 - val_loss: 0.1336 - val_mae: 0.1336\n",
      "Epoch 67/800\n",
      "6/6 [==============================] - 2s 406ms/step - loss: 0.1165 - mae: 0.1165 - val_loss: 0.1347 - val_mae: 0.1347\n",
      "Epoch 68/800\n",
      "6/6 [==============================] - 2s 408ms/step - loss: 0.1169 - mae: 0.1169 - val_loss: 0.1335 - val_mae: 0.1335\n",
      "Epoch 69/800\n",
      "6/6 [==============================] - 2s 411ms/step - loss: 0.1168 - mae: 0.1168 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 70/800\n",
      "6/6 [==============================] - 2s 407ms/step - loss: 0.1165 - mae: 0.1165 - val_loss: 0.1331 - val_mae: 0.1331\n",
      "Epoch 71/800\n",
      "6/6 [==============================] - 2s 404ms/step - loss: 0.1160 - mae: 0.1160 - val_loss: 0.1320 - val_mae: 0.1320\n",
      "Epoch 72/800\n",
      "6/6 [==============================] - 2s 405ms/step - loss: 0.1163 - mae: 0.1163 - val_loss: 0.1329 - val_mae: 0.1329\n",
      "Epoch 73/800\n",
      "6/6 [==============================] - 2s 401ms/step - loss: 0.1163 - mae: 0.1163 - val_loss: 0.1323 - val_mae: 0.1323\n",
      "Epoch 74/800\n",
      "6/6 [==============================] - 2s 410ms/step - loss: 0.1166 - mae: 0.1166 - val_loss: 0.1330 - val_mae: 0.1330\n",
      "Epoch 75/800\n",
      "6/6 [==============================] - 2s 401ms/step - loss: 0.1161 - mae: 0.1161 - val_loss: 0.1327 - val_mae: 0.1327\n",
      "Epoch 76/800\n",
      "6/6 [==============================] - 2s 406ms/step - loss: 0.1163 - mae: 0.1163 - val_loss: 0.1326 - val_mae: 0.1326\n",
      "Epoch 77/800\n",
      "6/6 [==============================] - 2s 403ms/step - loss: 0.1162 - mae: 0.1162 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 78/800\n",
      "6/6 [==============================] - 2s 402ms/step - loss: 0.1160 - mae: 0.1160 - val_loss: 0.1321 - val_mae: 0.1321\n",
      "Epoch 79/800\n",
      "6/6 [==============================] - 2s 403ms/step - loss: 0.1160 - mae: 0.1160 - val_loss: 0.1322 - val_mae: 0.1322\n",
      "Epoch 80/800\n",
      "6/6 [==============================] - 2s 410ms/step - loss: 0.1161 - mae: 0.1161 - val_loss: 0.1321 - val_mae: 0.1321\n",
      "Epoch 81/800\n",
      "6/6 [==============================] - 2s 401ms/step - loss: 0.1160 - mae: 0.1160 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 82/800\n",
      "6/6 [==============================] - 2s 405ms/step - loss: 0.1157 - mae: 0.1157 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 83/800\n",
      "6/6 [==============================] - 2s 402ms/step - loss: 0.1160 - mae: 0.1160 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 84/800\n",
      "6/6 [==============================] - 2s 413ms/step - loss: 0.1156 - mae: 0.1156 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 85/800\n",
      "6/6 [==============================] - 2s 416ms/step - loss: 0.1156 - mae: 0.1156 - val_loss: 0.1304 - val_mae: 0.1304\n",
      "Epoch 86/800\n",
      "6/6 [==============================] - 3s 418ms/step - loss: 0.1157 - mae: 0.1157 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 87/800\n",
      "6/6 [==============================] - 2s 416ms/step - loss: 0.1155 - mae: 0.1155 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 88/800\n",
      "6/6 [==============================] - 2s 404ms/step - loss: 0.1156 - mae: 0.1156 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 89/800\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 0.1158 - mae: 0.1158 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 90/800\n",
      "6/6 [==============================] - 2s 403ms/step - loss: 0.1154 - mae: 0.1154 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 91/800\n",
      "6/6 [==============================] - 2s 401ms/step - loss: 0.1153 - mae: 0.1153 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 92/800\n",
      "6/6 [==============================] - 2s 405ms/step - loss: 0.1153 - mae: 0.1153 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 93/800\n",
      "6/6 [==============================] - 2s 399ms/step - loss: 0.1154 - mae: 0.1154 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 94/800\n",
      "6/6 [==============================] - 2s 407ms/step - loss: 0.1152 - mae: 0.1152 - val_loss: 0.1315 - val_mae: 0.1315\n",
      "Epoch 95/800\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 0.1152 - mae: 0.1152 - val_loss: 0.1307 - val_mae: 0.1307\n",
      "Epoch 96/800\n",
      "6/6 [==============================] - 2s 403ms/step - loss: 0.1152 - mae: 0.1152 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 97/800\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 0.1151 - mae: 0.1151 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 98/800\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.1150 - mae: 0.1150 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 99/800\n",
      "6/6 [==============================] - 3s 528ms/step - loss: 0.1149 - mae: 0.1149 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 100/800\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.1148 - mae: 0.1148 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 101/800\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.1147 - mae: 0.1147 - val_loss: 0.1304 - val_mae: 0.1304\n",
      "Epoch 102/800\n",
      "6/6 [==============================] - 3s 510ms/step - loss: 0.1146 - mae: 0.1146 - val_loss: 0.1314 - val_mae: 0.1314\n",
      "Epoch 103/800\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.1149 - mae: 0.1149 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 104/800\n",
      "6/6 [==============================] - 4s 679ms/step - loss: 0.1147 - mae: 0.1147 - val_loss: 0.1304 - val_mae: 0.1304\n",
      "Epoch 105/800\n",
      "6/6 [==============================] - 4s 693ms/step - loss: 0.1145 - mae: 0.1145 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 106/800\n",
      "6/6 [==============================] - 4s 656ms/step - loss: 0.1144 - mae: 0.1144 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 107/800\n",
      "6/6 [==============================] - 3s 525ms/step - loss: 0.1148 - mae: 0.1148 - val_loss: 0.1299 - val_mae: 0.1299\n",
      "Epoch 108/800\n",
      "6/6 [==============================] - 3s 551ms/step - loss: 0.1146 - mae: 0.1146 - val_loss: 0.1294 - val_mae: 0.1294\n",
      "Epoch 109/800\n",
      "6/6 [==============================] - 3s 521ms/step - loss: 0.1145 - mae: 0.1145 - val_loss: 0.1287 - val_mae: 0.1287\n",
      "Epoch 110/800\n",
      "6/6 [==============================] - 3s 521ms/step - loss: 0.1143 - mae: 0.1143 - val_loss: 0.1295 - val_mae: 0.1295\n",
      "Epoch 111/800\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 0.1142 - mae: 0.1142 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 112/800\n",
      "6/6 [==============================] - 4s 710ms/step - loss: 0.1140 - mae: 0.1140 - val_loss: 0.1296 - val_mae: 0.1296\n",
      "Epoch 113/800\n",
      "6/6 [==============================] - 5s 878ms/step - loss: 0.1137 - mae: 0.1137 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 114/800\n",
      "6/6 [==============================] - 5s 826ms/step - loss: 0.1137 - mae: 0.1137 - val_loss: 0.1316 - val_mae: 0.1316\n",
      "Epoch 115/800\n",
      "6/6 [==============================] - 5s 804ms/step - loss: 0.1138 - mae: 0.1138 - val_loss: 0.1318 - val_mae: 0.1318\n",
      "Epoch 116/800\n",
      "6/6 [==============================] - 5s 801ms/step - loss: 0.1135 - mae: 0.1135 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 117/800\n",
      "6/6 [==============================] - 5s 715ms/step - loss: 0.1135 - mae: 0.1135 - val_loss: 0.1323 - val_mae: 0.1323\n",
      "Epoch 118/800\n",
      "6/6 [==============================] - 4s 688ms/step - loss: 0.1135 - mae: 0.1135 - val_loss: 0.1317 - val_mae: 0.1317\n",
      "Epoch 119/800\n",
      "6/6 [==============================] - 4s 610ms/step - loss: 0.1134 - mae: 0.1134 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 120/800\n",
      "6/6 [==============================] - 3s 543ms/step - loss: 0.1133 - mae: 0.1133 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 121/800\n",
      "6/6 [==============================] - 3s 508ms/step - loss: 0.1130 - mae: 0.1130 - val_loss: 0.1324 - val_mae: 0.1324\n",
      "Epoch 122/800\n",
      "6/6 [==============================] - 3s 531ms/step - loss: 0.1130 - mae: 0.1130 - val_loss: 0.1316 - val_mae: 0.1316\n",
      "Epoch 123/800\n",
      "6/6 [==============================] - 3s 520ms/step - loss: 0.1132 - mae: 0.1132 - val_loss: 0.1329 - val_mae: 0.1329\n",
      "Epoch 124/800\n",
      "6/6 [==============================] - 3s 528ms/step - loss: 0.1130 - mae: 0.1130 - val_loss: 0.1331 - val_mae: 0.1331\n",
      "Epoch 125/800\n",
      "6/6 [==============================] - 3s 512ms/step - loss: 0.1126 - mae: 0.1126 - val_loss: 0.1327 - val_mae: 0.1327\n",
      "Epoch 126/800\n",
      "6/6 [==============================] - 3s 573ms/step - loss: 0.1126 - mae: 0.1126 - val_loss: 0.1325 - val_mae: 0.1325\n",
      "Epoch 127/800\n",
      "6/6 [==============================] - 3s 529ms/step - loss: 0.1127 - mae: 0.1127 - val_loss: 0.1337 - val_mae: 0.1337\n",
      "Epoch 128/800\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.1126 - mae: 0.1126 - val_loss: 0.1320 - val_mae: 0.1320\n",
      "Epoch 129/800\n",
      "6/6 [==============================] - 5s 810ms/step - loss: 0.1125 - mae: 0.1125 - val_loss: 0.1335 - val_mae: 0.1335\n",
      "Epoch 130/800\n",
      "6/6 [==============================] - 4s 711ms/step - loss: 0.1123 - mae: 0.1123 - val_loss: 0.1327 - val_mae: 0.1327\n",
      "Epoch 131/800\n",
      "6/6 [==============================] - 4s 610ms/step - loss: 0.1120 - mae: 0.1120 - val_loss: 0.1334 - val_mae: 0.1334\n",
      "Epoch 132/800\n",
      "6/6 [==============================] - 4s 615ms/step - loss: 0.1122 - mae: 0.1122 - val_loss: 0.1337 - val_mae: 0.1337\n",
      "Epoch 133/800\n",
      "6/6 [==============================] - 4s 601ms/step - loss: 0.1121 - mae: 0.1121 - val_loss: 0.1339 - val_mae: 0.1339\n",
      "Epoch 134/800\n",
      "6/6 [==============================] - 3s 550ms/step - loss: 0.1118 - mae: 0.1118 - val_loss: 0.1338 - val_mae: 0.1338\n",
      "Epoch 135/800\n",
      "6/6 [==============================] - 4s 696ms/step - loss: 0.1118 - mae: 0.1118 - val_loss: 0.1341 - val_mae: 0.1341\n",
      "Epoch 136/800\n",
      "6/6 [==============================] - 4s 636ms/step - loss: 0.1116 - mae: 0.1116 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 137/800\n",
      "6/6 [==============================] - 4s 597ms/step - loss: 0.1118 - mae: 0.1118 - val_loss: 0.1369 - val_mae: 0.1369\n",
      "Epoch 138/800\n",
      "6/6 [==============================] - 4s 765ms/step - loss: 0.1116 - mae: 0.1116 - val_loss: 0.1433 - val_mae: 0.1433\n",
      "Epoch 139/800\n",
      "6/6 [==============================] - 4s 591ms/step - loss: 0.1130 - mae: 0.1130 - val_loss: 16.2932 - val_mae: 16.2932\n",
      "Epoch 140/800\n",
      "6/6 [==============================] - 4s 601ms/step - loss: 0.1136 - mae: 0.1136 - val_loss: 0.1467 - val_mae: 0.1467\n",
      "Epoch 141/800\n",
      "6/6 [==============================] - 4s 593ms/step - loss: 0.1143 - mae: 0.1143 - val_loss: 0.1445 - val_mae: 0.1445\n",
      "Epoch 142/800\n",
      "6/6 [==============================] - 4s 645ms/step - loss: 0.1138 - mae: 0.1138 - val_loss: 0.1445 - val_mae: 0.1445\n",
      "Epoch 143/800\n",
      "6/6 [==============================] - 4s 602ms/step - loss: 0.1134 - mae: 0.1134 - val_loss: 0.1428 - val_mae: 0.1428\n",
      "Epoch 144/800\n",
      "6/6 [==============================] - 4s 609ms/step - loss: 0.1132 - mae: 0.1132 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 145/800\n",
      "6/6 [==============================] - 3s 540ms/step - loss: 0.1131 - mae: 0.1131 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 146/800\n",
      "6/6 [==============================] - 4s 581ms/step - loss: 0.1129 - mae: 0.1129 - val_loss: 0.1381 - val_mae: 0.1381\n",
      "Epoch 147/800\n",
      "6/6 [==============================] - 4s 633ms/step - loss: 0.1127 - mae: 0.1127 - val_loss: 0.1360 - val_mae: 0.1360\n",
      "Epoch 148/800\n",
      "6/6 [==============================] - 3s 585ms/step - loss: 0.1126 - mae: 0.1126 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 149/800\n",
      "6/6 [==============================] - 3s 580ms/step - loss: 0.1124 - mae: 0.1124 - val_loss: 0.1332 - val_mae: 0.1332\n",
      "Epoch 150/800\n",
      "6/6 [==============================] - 4s 620ms/step - loss: 0.1122 - mae: 0.1122 - val_loss: 0.1316 - val_mae: 0.1316\n",
      "Epoch 151/800\n",
      "6/6 [==============================] - 3s 516ms/step - loss: 0.1120 - mae: 0.1120 - val_loss: 0.1320 - val_mae: 0.1320\n",
      "Epoch 152/800\n",
      "6/6 [==============================] - 3s 495ms/step - loss: 0.1118 - mae: 0.1118 - val_loss: 0.1315 - val_mae: 0.1315\n",
      "Epoch 153/800\n",
      "6/6 [==============================] - 3s 455ms/step - loss: 0.1117 - mae: 0.1117 - val_loss: 0.1314 - val_mae: 0.1314\n",
      "Epoch 154/800\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.1115 - mae: 0.1115 - val_loss: 0.1317 - val_mae: 0.1317\n",
      "Epoch 155/800\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.1114 - mae: 0.1114 - val_loss: 0.1316 - val_mae: 0.1316\n",
      "Epoch 156/800\n",
      "6/6 [==============================] - 3s 521ms/step - loss: 0.1114 - mae: 0.1114 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 157/800\n",
      "6/6 [==============================] - 3s 553ms/step - loss: 0.1113 - mae: 0.1113 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 158/800\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.1112 - mae: 0.1112 - val_loss: 0.1294 - val_mae: 0.1294\n",
      "Epoch 159/800\n",
      "6/6 [==============================] - 3s 510ms/step - loss: 0.1109 - mae: 0.1109 - val_loss: 0.1297 - val_mae: 0.1297\n",
      "Epoch 160/800\n",
      "6/6 [==============================] - 3s 540ms/step - loss: 0.1109 - mae: 0.1109 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 161/800\n",
      "6/6 [==============================] - 4s 642ms/step - loss: 0.1110 - mae: 0.1110 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 162/800\n",
      "6/6 [==============================] - 3s 468ms/step - loss: 0.1107 - mae: 0.1107 - val_loss: 0.1309 - val_mae: 0.1309\n",
      "Epoch 163/800\n",
      "6/6 [==============================] - 3s 523ms/step - loss: 0.1105 - mae: 0.1105 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 164/800\n",
      "6/6 [==============================] - 3s 540ms/step - loss: 0.1104 - mae: 0.1104 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 165/800\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 0.1105 - mae: 0.1105 - val_loss: 0.1303 - val_mae: 0.1303\n",
      "Epoch 166/800\n",
      "6/6 [==============================] - 3s 459ms/step - loss: 0.1105 - mae: 0.1105 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 167/800\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.1106 - mae: 0.1106 - val_loss: 0.1308 - val_mae: 0.1308\n",
      "Epoch 168/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.1103 - mae: 0.1103 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 169/800\n",
      "6/6 [==============================] - 3s 518ms/step - loss: 0.1102 - mae: 0.1102 - val_loss: 0.1304 - val_mae: 0.1304\n",
      "Epoch 170/800\n",
      "6/6 [==============================] - 3s 458ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.1304 - val_mae: 0.1304\n",
      "Epoch 171/800\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.1098 - mae: 0.1098 - val_loss: 0.1306 - val_mae: 0.1306\n",
      "Epoch 172/800\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 173/800\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.1098 - mae: 0.1098 - val_loss: 0.1295 - val_mae: 0.1295\n",
      "Epoch 174/800\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 0.1096 - mae: 0.1096 - val_loss: 0.1298 - val_mae: 0.1298\n",
      "Epoch 175/800\n",
      "6/6 [==============================] - 4s 585ms/step - loss: 0.1097 - mae: 0.1097 - val_loss: 0.1295 - val_mae: 0.1295\n",
      "Epoch 176/800\n",
      "6/6 [==============================] - 3s 503ms/step - loss: 0.1097 - mae: 0.1097 - val_loss: 0.1302 - val_mae: 0.1302\n",
      "Epoch 177/800\n",
      "6/6 [==============================] - 3s 528ms/step - loss: 0.1094 - mae: 0.1094 - val_loss: 0.1292 - val_mae: 0.1292\n",
      "Epoch 178/800\n",
      "6/6 [==============================] - 3s 521ms/step - loss: 0.1095 - mae: 0.1095 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 179/800\n",
      "6/6 [==============================] - 3s 500ms/step - loss: 0.1094 - mae: 0.1094 - val_loss: 0.1291 - val_mae: 0.1291\n",
      "Epoch 180/800\n",
      "6/6 [==============================] - 3s 501ms/step - loss: 0.1091 - mae: 0.1091 - val_loss: 0.1302 - val_mae: 0.1302\n",
      "Epoch 181/800\n",
      "6/6 [==============================] - 3s 502ms/step - loss: 0.1092 - mae: 0.1092 - val_loss: 0.1295 - val_mae: 0.1295\n",
      "Epoch 182/800\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 0.1091 - mae: 0.1091 - val_loss: 0.1296 - val_mae: 0.1296\n",
      "Epoch 183/800\n",
      "6/6 [==============================] - 4s 687ms/step - loss: 0.1089 - mae: 0.1089 - val_loss: 0.1293 - val_mae: 0.1293\n",
      "Epoch 184/800\n",
      "6/6 [==============================] - 3s 518ms/step - loss: 0.1091 - mae: 0.1091 - val_loss: 0.1291 - val_mae: 0.1291\n",
      "Epoch 185/800\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.1088 - mae: 0.1088 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 186/800\n",
      "6/6 [==============================] - 3s 470ms/step - loss: 0.1088 - mae: 0.1088 - val_loss: 0.1289 - val_mae: 0.1289\n",
      "Epoch 187/800\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.1090 - mae: 0.1090 - val_loss: 0.1287 - val_mae: 0.1287\n",
      "Epoch 188/800\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.1086 - mae: 0.1086 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 189/800\n",
      "6/6 [==============================] - 3s 570ms/step - loss: 0.1088 - mae: 0.1088 - val_loss: 0.1285 - val_mae: 0.1285\n",
      "Epoch 190/800\n",
      "6/6 [==============================] - 3s 543ms/step - loss: 0.1088 - mae: 0.1088 - val_loss: 0.1288 - val_mae: 0.1288\n",
      "Epoch 191/800\n",
      "6/6 [==============================] - 3s 550ms/step - loss: 0.1086 - mae: 0.1086 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 192/800\n",
      "6/6 [==============================] - 4s 575ms/step - loss: 0.1102 - mae: 0.1102 - val_loss: 0.1283 - val_mae: 0.1283\n",
      "Epoch 193/800\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.1278 - val_mae: 0.1278\n",
      "Epoch 194/800\n",
      "6/6 [==============================] - 3s 539ms/step - loss: 0.1095 - mae: 0.1095 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 195/800\n",
      "6/6 [==============================] - 3s 596ms/step - loss: 0.1092 - mae: 0.1092 - val_loss: 0.1290 - val_mae: 0.1290\n",
      "Epoch 196/800\n",
      "6/6 [==============================] - 4s 628ms/step - loss: 0.1091 - mae: 0.1091 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 197/800\n",
      "6/6 [==============================] - 4s 607ms/step - loss: 0.1092 - mae: 0.1092 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 198/800\n",
      "6/6 [==============================] - 4s 708ms/step - loss: 0.1089 - mae: 0.1089 - val_loss: 0.1270 - val_mae: 0.1270\n",
      "Epoch 199/800\n",
      "6/6 [==============================] - 4s 755ms/step - loss: 0.1087 - mae: 0.1087 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 200/800\n",
      "6/6 [==============================] - 4s 714ms/step - loss: 0.1086 - mae: 0.1086 - val_loss: 0.1271 - val_mae: 0.1271\n",
      "Epoch 201/800\n",
      "6/6 [==============================] - 4s 723ms/step - loss: 0.1082 - mae: 0.1082 - val_loss: 0.1276 - val_mae: 0.1276\n",
      "Epoch 202/800\n",
      "6/6 [==============================] - 4s 669ms/step - loss: 0.1085 - mae: 0.1085 - val_loss: 0.1278 - val_mae: 0.1278\n",
      "Epoch 203/800\n",
      "6/6 [==============================] - 4s 744ms/step - loss: 0.1082 - mae: 0.1082 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 204/800\n",
      "6/6 [==============================] - 4s 664ms/step - loss: 0.1082 - mae: 0.1082 - val_loss: 0.1268 - val_mae: 0.1268\n",
      "Epoch 205/800\n",
      "6/6 [==============================] - 3s 587ms/step - loss: 0.1079 - mae: 0.1079 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 206/800\n",
      "6/6 [==============================] - 4s 611ms/step - loss: 0.1076 - mae: 0.1076 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 207/800\n",
      "6/6 [==============================] - 3s 547ms/step - loss: 0.1077 - mae: 0.1077 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 208/800\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.1074 - mae: 0.1074 - val_loss: 0.1267 - val_mae: 0.1267\n",
      "Epoch 209/800\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.1074 - mae: 0.1074 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 210/800\n",
      "6/6 [==============================] - 3s 453ms/step - loss: 0.1070 - mae: 0.1070 - val_loss: 0.1271 - val_mae: 0.1271\n",
      "Epoch 211/800\n",
      "6/6 [==============================] - 3s 458ms/step - loss: 0.1072 - mae: 0.1072 - val_loss: 0.1275 - val_mae: 0.1275\n",
      "Epoch 212/800\n",
      "6/6 [==============================] - 3s 432ms/step - loss: 0.1073 - mae: 0.1073 - val_loss: 0.1272 - val_mae: 0.1272\n",
      "Epoch 213/800\n",
      "6/6 [==============================] - 3s 442ms/step - loss: 0.1068 - mae: 0.1068 - val_loss: 0.1270 - val_mae: 0.1270\n",
      "Epoch 214/800\n",
      "6/6 [==============================] - 3s 428ms/step - loss: 0.1065 - mae: 0.1065 - val_loss: 0.1273 - val_mae: 0.1273\n",
      "Epoch 215/800\n",
      "6/6 [==============================] - 3s 431ms/step - loss: 0.1064 - mae: 0.1064 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 216/800\n",
      "6/6 [==============================] - 2s 415ms/step - loss: 0.1064 - mae: 0.1064 - val_loss: 0.1266 - val_mae: 0.1266\n",
      "Epoch 217/800\n",
      "6/6 [==============================] - 2s 419ms/step - loss: 0.1064 - mae: 0.1064 - val_loss: 0.1273 - val_mae: 0.1273\n",
      "Epoch 218/800\n",
      "6/6 [==============================] - 2s 402ms/step - loss: 0.1063 - mae: 0.1063 - val_loss: 0.1274 - val_mae: 0.1274\n",
      "Epoch 219/800\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 0.1061 - mae: 0.1061 - val_loss: 0.1276 - val_mae: 0.1276\n",
      "Epoch 220/800\n",
      "6/6 [==============================] - 2s 393ms/step - loss: 0.1063 - mae: 0.1063 - val_loss: 0.1263 - val_mae: 0.1263\n",
      "Epoch 221/800\n",
      "6/6 [==============================] - 2s 390ms/step - loss: 0.1066 - mae: 0.1066 - val_loss: 0.1268 - val_mae: 0.1268\n",
      "Epoch 222/800\n",
      "6/6 [==============================] - 2s 392ms/step - loss: 0.1061 - mae: 0.1061 - val_loss: 0.1264 - val_mae: 0.1264\n",
      "Epoch 223/800\n",
      "6/6 [==============================] - 2s 392ms/step - loss: 0.1058 - mae: 0.1058 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 224/800\n",
      "6/6 [==============================] - 2s 406ms/step - loss: 0.1058 - mae: 0.1058 - val_loss: 0.1270 - val_mae: 0.1270\n",
      "Epoch 225/800\n",
      "6/6 [==============================] - 2s 384ms/step - loss: 0.1056 - mae: 0.1056 - val_loss: 0.1265 - val_mae: 0.1265\n",
      "Epoch 226/800\n",
      "6/6 [==============================] - 2s 402ms/step - loss: 0.1055 - mae: 0.1055 - val_loss: 0.1273 - val_mae: 0.1273\n",
      "Epoch 227/800\n",
      "6/6 [==============================] - 2s 379ms/step - loss: 0.1054 - mae: 0.1054 - val_loss: 0.1263 - val_mae: 0.1263\n",
      "Epoch 228/800\n",
      "6/6 [==============================] - 2s 381ms/step - loss: 0.1054 - mae: 0.1054 - val_loss: 0.1271 - val_mae: 0.1271\n",
      "Epoch 229/800\n",
      "6/6 [==============================] - 2s 383ms/step - loss: 0.1052 - mae: 0.1052 - val_loss: 0.1273 - val_mae: 0.1273\n",
      "Epoch 230/800\n",
      "6/6 [==============================] - 2s 394ms/step - loss: 0.1051 - mae: 0.1051 - val_loss: 0.1260 - val_mae: 0.1260\n",
      "Epoch 231/800\n",
      "6/6 [==============================] - 2s 399ms/step - loss: 0.1050 - mae: 0.1050 - val_loss: 0.1259 - val_mae: 0.1259\n",
      "Epoch 232/800\n",
      "6/6 [==============================] - 2s 406ms/step - loss: 0.1054 - mae: 0.1054 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 233/800\n",
      "6/6 [==============================] - 2s 404ms/step - loss: 0.1052 - mae: 0.1052 - val_loss: 0.1258 - val_mae: 0.1258\n",
      "Epoch 234/800\n",
      "6/6 [==============================] - 2s 416ms/step - loss: 0.1050 - mae: 0.1050 - val_loss: 0.1254 - val_mae: 0.1254\n",
      "Epoch 235/800\n",
      "6/6 [==============================] - 3s 425ms/step - loss: 0.1050 - mae: 0.1050 - val_loss: 0.1249 - val_mae: 0.1249\n",
      "Epoch 236/800\n",
      "6/6 [==============================] - 3s 427ms/step - loss: 0.1047 - mae: 0.1047 - val_loss: 0.1251 - val_mae: 0.1251\n",
      "Epoch 237/800\n",
      "6/6 [==============================] - 3s 429ms/step - loss: 0.1048 - mae: 0.1048 - val_loss: 0.1249 - val_mae: 0.1249\n",
      "Epoch 238/800\n",
      "6/6 [==============================] - 3s 452ms/step - loss: 0.1048 - mae: 0.1048 - val_loss: 0.1242 - val_mae: 0.1242\n",
      "Epoch 239/800\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.1047 - mae: 0.1047 - val_loss: 0.1227 - val_mae: 0.1227\n",
      "Epoch 240/800\n",
      "6/6 [==============================] - 3s 510ms/step - loss: 0.1045 - mae: 0.1045 - val_loss: 0.1242 - val_mae: 0.1242\n",
      "Epoch 241/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.1045 - mae: 0.1045 - val_loss: 0.1236 - val_mae: 0.1236\n",
      "Epoch 242/800\n",
      "6/6 [==============================] - 3s 427ms/step - loss: 0.1042 - mae: 0.1042 - val_loss: 0.1242 - val_mae: 0.1242\n",
      "Epoch 243/800\n",
      "6/6 [==============================] - 3s 429ms/step - loss: 0.1042 - mae: 0.1042 - val_loss: 0.1247 - val_mae: 0.1247\n",
      "Epoch 244/800\n",
      "6/6 [==============================] - 3s 440ms/step - loss: 0.1043 - mae: 0.1043 - val_loss: 0.1239 - val_mae: 0.1239\n",
      "Epoch 245/800\n",
      "6/6 [==============================] - 3s 443ms/step - loss: 0.1042 - mae: 0.1042 - val_loss: 0.1250 - val_mae: 0.1250\n",
      "Epoch 246/800\n",
      "6/6 [==============================] - 3s 434ms/step - loss: 0.1042 - mae: 0.1042 - val_loss: 0.1244 - val_mae: 0.1244\n",
      "Epoch 247/800\n",
      "6/6 [==============================] - 3s 433ms/step - loss: 0.1042 - mae: 0.1042 - val_loss: 0.1222 - val_mae: 0.1222\n",
      "Epoch 248/800\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.1040 - mae: 0.1040 - val_loss: 0.1258 - val_mae: 0.1258\n",
      "Epoch 249/800\n",
      "6/6 [==============================] - 3s 431ms/step - loss: 0.1042 - mae: 0.1042 - val_loss: 0.1222 - val_mae: 0.1222\n",
      "Epoch 250/800\n",
      "6/6 [==============================] - 3s 430ms/step - loss: 0.1039 - mae: 0.1039 - val_loss: 0.1230 - val_mae: 0.1230\n",
      "Epoch 251/800\n",
      "6/6 [==============================] - 3s 421ms/step - loss: 0.1039 - mae: 0.1039 - val_loss: 0.1252 - val_mae: 0.1252\n",
      "Epoch 252/800\n",
      "6/6 [==============================] - 3s 436ms/step - loss: 0.1038 - mae: 0.1038 - val_loss: 0.1228 - val_mae: 0.1228\n",
      "Epoch 253/800\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.1037 - mae: 0.1037 - val_loss: 0.1221 - val_mae: 0.1221\n",
      "Epoch 254/800\n",
      "6/6 [==============================] - 3s 445ms/step - loss: 0.1037 - mae: 0.1037 - val_loss: 0.1230 - val_mae: 0.1230\n",
      "Epoch 255/800\n",
      "6/6 [==============================] - 3s 455ms/step - loss: 0.1033 - mae: 0.1033 - val_loss: 0.1214 - val_mae: 0.1214\n",
      "Epoch 256/800\n",
      "6/6 [==============================] - 3s 442ms/step - loss: 0.1032 - mae: 0.1032 - val_loss: 0.1209 - val_mae: 0.1209\n",
      "Epoch 257/800\n",
      "6/6 [==============================] - 3s 541ms/step - loss: 0.1036 - mae: 0.1036 - val_loss: 0.1213 - val_mae: 0.1213\n",
      "Epoch 258/800\n",
      "6/6 [==============================] - 3s 463ms/step - loss: 0.1036 - mae: 0.1036 - val_loss: 0.1208 - val_mae: 0.1208\n",
      "Epoch 259/800\n",
      "6/6 [==============================] - 3s 433ms/step - loss: 0.1034 - mae: 0.1034 - val_loss: 0.1200 - val_mae: 0.1200\n",
      "Epoch 260/800\n",
      "6/6 [==============================] - 3s 428ms/step - loss: 0.1032 - mae: 0.1032 - val_loss: 0.1205 - val_mae: 0.1205\n",
      "Epoch 261/800\n",
      "6/6 [==============================] - 3s 422ms/step - loss: 0.1031 - mae: 0.1031 - val_loss: 0.1211 - val_mae: 0.1211\n",
      "Epoch 262/800\n",
      "6/6 [==============================] - 3s 468ms/step - loss: 0.1028 - mae: 0.1028 - val_loss: 0.1207 - val_mae: 0.1207\n",
      "Epoch 263/800\n",
      "6/6 [==============================] - 3s 440ms/step - loss: 0.1029 - mae: 0.1029 - val_loss: 0.1211 - val_mae: 0.1211\n",
      "Epoch 264/800\n",
      "6/6 [==============================] - 3s 516ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.1215 - val_mae: 0.1215\n",
      "Epoch 265/800\n",
      "6/6 [==============================] - 3s 456ms/step - loss: 0.1028 - mae: 0.1028 - val_loss: 0.1199 - val_mae: 0.1199\n",
      "Epoch 266/800\n",
      "6/6 [==============================] - 3s 482ms/step - loss: 0.1030 - mae: 0.1030 - val_loss: 0.1193 - val_mae: 0.1193\n",
      "Epoch 267/800\n",
      "6/6 [==============================] - 3s 543ms/step - loss: 0.1028 - mae: 0.1028 - val_loss: 0.1207 - val_mae: 0.1207\n",
      "Epoch 268/800\n",
      "6/6 [==============================] - 3s 581ms/step - loss: 0.1027 - mae: 0.1027 - val_loss: 0.1202 - val_mae: 0.1202\n",
      "Epoch 269/800\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.1202 - val_mae: 0.1202\n",
      "Epoch 270/800\n",
      "6/6 [==============================] - 3s 588ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.1207 - val_mae: 0.1207\n",
      "Epoch 271/800\n",
      "6/6 [==============================] - 4s 573ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.1210 - val_mae: 0.1210\n",
      "Epoch 272/800\n",
      "6/6 [==============================] - 3s 469ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.1188 - val_mae: 0.1188\n",
      "Epoch 273/800\n",
      "6/6 [==============================] - 3s 486ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.1193 - val_mae: 0.1193\n",
      "Epoch 274/800\n",
      "6/6 [==============================] - 3s 474ms/step - loss: 0.1024 - mae: 0.1024 - val_loss: 0.1205 - val_mae: 0.1205\n",
      "Epoch 275/800\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 0.1024 - mae: 0.1024 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 276/800\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.1021 - mae: 0.1021 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 277/800\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.1024 - mae: 0.1024 - val_loss: 0.1194 - val_mae: 0.1194\n",
      "Epoch 278/800\n",
      "6/6 [==============================] - 3s 468ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 279/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.1029 - mae: 0.1029 - val_loss: 0.1213 - val_mae: 0.1213\n",
      "Epoch 280/800\n",
      "6/6 [==============================] - 3s 460ms/step - loss: 0.1030 - mae: 0.1030 - val_loss: 0.1175 - val_mae: 0.1175\n",
      "Epoch 281/800\n",
      "6/6 [==============================] - 3s 464ms/step - loss: 0.1027 - mae: 0.1027 - val_loss: 0.1191 - val_mae: 0.1191\n",
      "Epoch 282/800\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.1029 - mae: 0.1029 - val_loss: 0.1151 - val_mae: 0.1151\n",
      "Epoch 283/800\n",
      "6/6 [==============================] - 3s 516ms/step - loss: 0.1028 - mae: 0.1028 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 284/800\n",
      "6/6 [==============================] - 3s 514ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 285/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.1024 - mae: 0.1024 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 286/800\n",
      "6/6 [==============================] - 3s 494ms/step - loss: 0.1027 - mae: 0.1027 - val_loss: 0.1154 - val_mae: 0.1154\n",
      "Epoch 287/800\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.1024 - mae: 0.1024 - val_loss: 0.1151 - val_mae: 0.1151\n",
      "Epoch 288/800\n",
      "6/6 [==============================] - 3s 500ms/step - loss: 0.1022 - mae: 0.1022 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 289/800\n",
      "6/6 [==============================] - 3s 506ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.1163 - val_mae: 0.1163\n",
      "Epoch 290/800\n",
      "6/6 [==============================] - 3s 494ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.1193 - val_mae: 0.1193\n",
      "Epoch 291/800\n",
      "6/6 [==============================] - 3s 507ms/step - loss: 0.1024 - mae: 0.1024 - val_loss: 0.1223 - val_mae: 0.1223\n",
      "Epoch 292/800\n",
      "6/6 [==============================] - 3s 499ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.1181 - val_mae: 0.1181\n",
      "Epoch 293/800\n",
      "6/6 [==============================] - 3s 480ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.1171 - val_mae: 0.1171\n",
      "Epoch 294/800\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.1033 - mae: 0.1033 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 295/800\n",
      "6/6 [==============================] - 3s 505ms/step - loss: 0.1020 - mae: 0.1020 - val_loss: 0.1190 - val_mae: 0.1190\n",
      "Epoch 296/800\n",
      "6/6 [==============================] - 3s 504ms/step - loss: 0.1031 - mae: 0.1031 - val_loss: 0.1164 - val_mae: 0.1164\n",
      "Epoch 297/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.1019 - mae: 0.1019 - val_loss: 0.1202 - val_mae: 0.1202\n",
      "Epoch 298/800\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.1018 - mae: 0.1018 - val_loss: 0.1167 - val_mae: 0.1167\n",
      "Epoch 299/800\n",
      "6/6 [==============================] - 3s 464ms/step - loss: 0.1028 - mae: 0.1028 - val_loss: 0.1195 - val_mae: 0.1195\n",
      "Epoch 300/800\n",
      "6/6 [==============================] - 3s 504ms/step - loss: 0.1035 - mae: 0.1035 - val_loss: 0.1201 - val_mae: 0.1201\n",
      "Epoch 301/800\n",
      "6/6 [==============================] - 3s 463ms/step - loss: 0.1035 - mae: 0.1035 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 302/800\n",
      "6/6 [==============================] - 3s 493ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.1285 - val_mae: 0.1285\n",
      "Epoch 303/800\n",
      "6/6 [==============================] - 3s 502ms/step - loss: 0.1023 - mae: 0.1023 - val_loss: 0.1305 - val_mae: 0.1305\n",
      "Epoch 304/800\n",
      "6/6 [==============================] - 3s 494ms/step - loss: 0.1022 - mae: 0.1022 - val_loss: 0.1287 - val_mae: 0.1287\n",
      "Epoch 305/800\n",
      "6/6 [==============================] - 3s 562ms/step - loss: 0.1018 - mae: 0.1018 - val_loss: 0.1254 - val_mae: 0.1254\n",
      "Epoch 306/800\n",
      "6/6 [==============================] - 3s 573ms/step - loss: 0.1016 - mae: 0.1016 - val_loss: 0.1234 - val_mae: 0.1234\n",
      "Epoch 307/800\n",
      "6/6 [==============================] - 3s 482ms/step - loss: 0.1013 - mae: 0.1013 - val_loss: 0.1211 - val_mae: 0.1211\n",
      "Epoch 308/800\n",
      "6/6 [==============================] - 3s 459ms/step - loss: 0.1013 - mae: 0.1013 - val_loss: 0.1199 - val_mae: 0.1199\n",
      "Epoch 309/800\n",
      "6/6 [==============================] - 3s 504ms/step - loss: 0.1013 - mae: 0.1013 - val_loss: 0.1208 - val_mae: 0.1208\n",
      "Epoch 310/800\n",
      "6/6 [==============================] - 3s 501ms/step - loss: 0.1012 - mae: 0.1012 - val_loss: 0.1192 - val_mae: 0.1192\n",
      "Epoch 311/800\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.1012 - mae: 0.1012 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 312/800\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.1013 - mae: 0.1013 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 313/800\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.1014 - mae: 0.1014 - val_loss: 0.1174 - val_mae: 0.1174\n",
      "Epoch 314/800\n",
      "6/6 [==============================] - 4s 670ms/step - loss: 0.1010 - mae: 0.1010 - val_loss: 0.1151 - val_mae: 0.1151\n",
      "Epoch 315/800\n",
      "6/6 [==============================] - 3s 513ms/step - loss: 0.1011 - mae: 0.1011 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 316/800\n",
      "6/6 [==============================] - 3s 539ms/step - loss: 0.1007 - mae: 0.1007 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 317/800\n",
      "6/6 [==============================] - 3s 564ms/step - loss: 0.1007 - mae: 0.1007 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 318/800\n",
      "6/6 [==============================] - 3s 562ms/step - loss: 0.1008 - mae: 0.1008 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 319/800\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 0.1005 - mae: 0.1005 - val_loss: 0.1163 - val_mae: 0.1163\n",
      "Epoch 320/800\n",
      "6/6 [==============================] - 3s 474ms/step - loss: 0.1009 - mae: 0.1009 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 321/800\n",
      "6/6 [==============================] - 3s 554ms/step - loss: 0.1005 - mae: 0.1005 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 322/800\n",
      "6/6 [==============================] - 3s 565ms/step - loss: 0.1004 - mae: 0.1004 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 323/800\n",
      "6/6 [==============================] - 3s 511ms/step - loss: 0.1004 - mae: 0.1004 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 324/800\n",
      "6/6 [==============================] - 3s 512ms/step - loss: 0.1007 - mae: 0.1007 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 325/800\n",
      "6/6 [==============================] - 3s 530ms/step - loss: 0.1005 - mae: 0.1005 - val_loss: 0.1178 - val_mae: 0.1178\n",
      "Epoch 326/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.1012 - mae: 0.1012 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 327/800\n",
      "6/6 [==============================] - 3s 449ms/step - loss: 0.1009 - mae: 0.1009 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 328/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.1005 - mae: 0.1005 - val_loss: 0.1164 - val_mae: 0.1164\n",
      "Epoch 329/800\n",
      "6/6 [==============================] - 3s 529ms/step - loss: 0.1007 - mae: 0.1007 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 330/800\n",
      "6/6 [==============================] - 3s 482ms/step - loss: 0.1010 - mae: 0.1010 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 331/800\n",
      "6/6 [==============================] - 3s 577ms/step - loss: 0.1009 - mae: 0.1009 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 332/800\n",
      "6/6 [==============================] - 3s 529ms/step - loss: 0.1004 - mae: 0.1004 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 333/800\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.1005 - mae: 0.1005 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 334/800\n",
      "6/6 [==============================] - 4s 617ms/step - loss: 0.1005 - mae: 0.1005 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 335/800\n",
      "6/6 [==============================] - 3s 523ms/step - loss: 0.1005 - mae: 0.1005 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 336/800\n",
      "6/6 [==============================] - 3s 501ms/step - loss: 0.1004 - mae: 0.1004 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 337/800\n",
      "6/6 [==============================] - 3s 515ms/step - loss: 0.1006 - mae: 0.1006 - val_loss: 0.1151 - val_mae: 0.1151\n",
      "Epoch 338/800\n",
      "6/6 [==============================] - 3s 503ms/step - loss: 0.1008 - mae: 0.1008 - val_loss: 0.1164 - val_mae: 0.1164\n",
      "Epoch 339/800\n",
      "6/6 [==============================] - 3s 493ms/step - loss: 0.1002 - mae: 0.1002 - val_loss: 0.1167 - val_mae: 0.1167\n",
      "Epoch 340/800\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.1001 - mae: 0.1001 - val_loss: 0.1142 - val_mae: 0.1142\n",
      "Epoch 341/800\n",
      "6/6 [==============================] - 3s 474ms/step - loss: 0.1003 - mae: 0.1003 - val_loss: 0.1143 - val_mae: 0.1143\n",
      "Epoch 342/800\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.1002 - mae: 0.1002 - val_loss: 0.1140 - val_mae: 0.1140\n",
      "Epoch 343/800\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0999 - mae: 0.0999 - val_loss: 0.1146 - val_mae: 0.1146\n",
      "Epoch 344/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.1000 - mae: 0.1000 - val_loss: 0.1149 - val_mae: 0.1149\n",
      "Epoch 345/800\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0995 - mae: 0.0995 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 346/800\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.1000 - mae: 0.1000 - val_loss: 0.1189 - val_mae: 0.1189\n",
      "Epoch 347/800\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.0999 - mae: 0.0999 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 348/800\n",
      "6/6 [==============================] - 3s 548ms/step - loss: 0.0998 - mae: 0.0998 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 349/800\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.0997 - mae: 0.0997 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 350/800\n",
      "6/6 [==============================] - 3s 525ms/step - loss: 0.0994 - mae: 0.0994 - val_loss: 0.1149 - val_mae: 0.1149\n",
      "Epoch 351/800\n",
      "6/6 [==============================] - 3s 487ms/step - loss: 0.0997 - mae: 0.0997 - val_loss: 0.1139 - val_mae: 0.1139\n",
      "Epoch 352/800\n",
      "6/6 [==============================] - 3s 456ms/step - loss: 0.0993 - mae: 0.0993 - val_loss: 0.1143 - val_mae: 0.1143\n",
      "Epoch 353/800\n",
      "6/6 [==============================] - 3s 467ms/step - loss: 0.0996 - mae: 0.0996 - val_loss: 0.1143 - val_mae: 0.1143\n",
      "Epoch 354/800\n",
      "6/6 [==============================] - 3s 491ms/step - loss: 0.0995 - mae: 0.0995 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 355/800\n",
      "6/6 [==============================] - 3s 491ms/step - loss: 0.0996 - mae: 0.0996 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 356/800\n",
      "6/6 [==============================] - 3s 486ms/step - loss: 0.0995 - mae: 0.0995 - val_loss: 0.1142 - val_mae: 0.1142\n",
      "Epoch 357/800\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 0.0991 - mae: 0.0991 - val_loss: 0.1151 - val_mae: 0.1151\n",
      "Epoch 358/800\n",
      "6/6 [==============================] - 3s 507ms/step - loss: 0.0996 - mae: 0.0996 - val_loss: 0.1138 - val_mae: 0.1138\n",
      "Epoch 359/800\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.0993 - mae: 0.0993 - val_loss: 0.1154 - val_mae: 0.1154\n",
      "Epoch 360/800\n",
      "6/6 [==============================] - 3s 525ms/step - loss: 0.0991 - mae: 0.0991 - val_loss: 0.1130 - val_mae: 0.1130\n",
      "Epoch 361/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.0992 - mae: 0.0992 - val_loss: 0.1142 - val_mae: 0.1142\n",
      "Epoch 362/800\n",
      "6/6 [==============================] - 4s 625ms/step - loss: 0.0995 - mae: 0.0995 - val_loss: 0.1136 - val_mae: 0.1136\n",
      "Epoch 363/800\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.0992 - mae: 0.0992 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 364/800\n",
      "6/6 [==============================] - 3s 511ms/step - loss: 0.0991 - mae: 0.0991 - val_loss: 0.1138 - val_mae: 0.1138\n",
      "Epoch 365/800\n",
      "6/6 [==============================] - 3s 546ms/step - loss: 0.1002 - mae: 0.1002 - val_loss: 0.1145 - val_mae: 0.1145\n",
      "Epoch 366/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.0997 - mae: 0.0997 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 367/800\n",
      "6/6 [==============================] - 3s 467ms/step - loss: 0.0993 - mae: 0.0993 - val_loss: 0.1196 - val_mae: 0.1196\n",
      "Epoch 368/800\n",
      "6/6 [==============================] - 3s 532ms/step - loss: 0.0992 - mae: 0.0992 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 369/800\n",
      "6/6 [==============================] - 3s 570ms/step - loss: 0.0994 - mae: 0.0994 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 370/800\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 0.0992 - mae: 0.0992 - val_loss: 0.1136 - val_mae: 0.1136\n",
      "Epoch 371/800\n",
      "6/6 [==============================] - 3s 515ms/step - loss: 0.0988 - mae: 0.0988 - val_loss: 0.1203 - val_mae: 0.1203\n",
      "Epoch 372/800\n",
      "6/6 [==============================] - 3s 528ms/step - loss: 0.0988 - mae: 0.0988 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 373/800\n",
      "6/6 [==============================] - 3s 572ms/step - loss: 0.0988 - mae: 0.0988 - val_loss: 0.1137 - val_mae: 0.1137\n",
      "Epoch 374/800\n",
      "6/6 [==============================] - 3s 557ms/step - loss: 0.0991 - mae: 0.0991 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 375/800\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.0994 - mae: 0.0994 - val_loss: 0.1140 - val_mae: 0.1140\n",
      "Epoch 376/800\n",
      "6/6 [==============================] - 3s 530ms/step - loss: 0.0999 - mae: 0.0999 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 377/800\n",
      "6/6 [==============================] - 4s 644ms/step - loss: 0.0992 - mae: 0.0992 - val_loss: 0.1163 - val_mae: 0.1163\n",
      "Epoch 378/800\n",
      "6/6 [==============================] - 4s 620ms/step - loss: 0.0989 - mae: 0.0989 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 379/800\n",
      "6/6 [==============================] - 3s 549ms/step - loss: 0.0987 - mae: 0.0987 - val_loss: 0.1132 - val_mae: 0.1132\n",
      "Epoch 380/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.0990 - mae: 0.0990 - val_loss: 0.1134 - val_mae: 0.1134\n",
      "Epoch 381/800\n",
      "6/6 [==============================] - 3s 520ms/step - loss: 0.0990 - mae: 0.0990 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 382/800\n",
      "6/6 [==============================] - 3s 530ms/step - loss: 0.0984 - mae: 0.0984 - val_loss: 0.1135 - val_mae: 0.1135\n",
      "Epoch 383/800\n",
      "6/6 [==============================] - 3s 539ms/step - loss: 0.0988 - mae: 0.0988 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 384/800\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 0.0988 - mae: 0.0988 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 385/800\n",
      "6/6 [==============================] - 3s 550ms/step - loss: 0.0987 - mae: 0.0987 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 386/800\n",
      "6/6 [==============================] - 3s 547ms/step - loss: 0.0985 - mae: 0.0985 - val_loss: 0.1139 - val_mae: 0.1139\n",
      "Epoch 387/800\n",
      "6/6 [==============================] - 3s 508ms/step - loss: 0.0987 - mae: 0.0987 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 388/800\n",
      "6/6 [==============================] - 3s 539ms/step - loss: 0.0985 - mae: 0.0985 - val_loss: 0.1139 - val_mae: 0.1139\n",
      "Epoch 389/800\n",
      "6/6 [==============================] - 3s 569ms/step - loss: 0.0986 - mae: 0.0986 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 390/800\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 0.0985 - mae: 0.0985 - val_loss: 0.1146 - val_mae: 0.1146\n",
      "Epoch 391/800\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.0984 - mae: 0.0984 - val_loss: 0.1137 - val_mae: 0.1137\n",
      "Epoch 392/800\n",
      "6/6 [==============================] - 3s 456ms/step - loss: 0.0982 - mae: 0.0982 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 393/800\n",
      "6/6 [==============================] - 3s 455ms/step - loss: 0.0983 - mae: 0.0983 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 394/800\n",
      "6/6 [==============================] - 3s 459ms/step - loss: 0.0986 - mae: 0.0986 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 395/800\n",
      "6/6 [==============================] - 3s 447ms/step - loss: 0.0986 - mae: 0.0986 - val_loss: 0.1136 - val_mae: 0.1136\n",
      "Epoch 396/800\n",
      "6/6 [==============================] - 3s 441ms/step - loss: 0.0983 - mae: 0.0983 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 397/800\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.0983 - mae: 0.0983 - val_loss: 0.1142 - val_mae: 0.1142\n",
      "Epoch 398/800\n",
      "6/6 [==============================] - 3s 465ms/step - loss: 0.0984 - mae: 0.0984 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 399/800\n",
      "6/6 [==============================] - 3s 415ms/step - loss: 0.0981 - mae: 0.0981 - val_loss: 0.1154 - val_mae: 0.1154\n",
      "Epoch 400/800\n",
      "6/6 [==============================] - 2s 418ms/step - loss: 0.0981 - mae: 0.0981 - val_loss: 0.1138 - val_mae: 0.1138\n",
      "Epoch 401/800\n",
      "6/6 [==============================] - 3s 459ms/step - loss: 0.0980 - mae: 0.0980 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 402/800\n",
      "6/6 [==============================] - 3s 458ms/step - loss: 0.0982 - mae: 0.0982 - val_loss: 0.1140 - val_mae: 0.1140\n",
      "Epoch 403/800\n",
      "6/6 [==============================] - 3s 402ms/step - loss: 0.0978 - mae: 0.0978 - val_loss: 0.1139 - val_mae: 0.1139\n",
      "Epoch 404/800\n",
      "6/6 [==============================] - 3s 482ms/step - loss: 0.0982 - mae: 0.0982 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 405/800\n",
      "6/6 [==============================] - 3s 442ms/step - loss: 0.0979 - mae: 0.0979 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 406/800\n",
      "6/6 [==============================] - 3s 466ms/step - loss: 0.0978 - mae: 0.0978 - val_loss: 0.1164 - val_mae: 0.1164\n",
      "Epoch 407/800\n",
      "6/6 [==============================] - 3s 495ms/step - loss: 0.0977 - mae: 0.0977 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 408/800\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.0978 - mae: 0.0978 - val_loss: 0.1136 - val_mae: 0.1136\n",
      "Epoch 409/800\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 0.0980 - mae: 0.0980 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 410/800\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 0.0996 - mae: 0.0996 - val_loss: 0.1173 - val_mae: 0.1173\n",
      "Epoch 411/800\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 0.0998 - mae: 0.0998 - val_loss: 0.1224 - val_mae: 0.1224\n",
      "Epoch 412/800\n",
      "6/6 [==============================] - 3s 574ms/step - loss: 0.0993 - mae: 0.0993 - val_loss: 0.1243 - val_mae: 0.1243\n",
      "Epoch 413/800\n",
      "6/6 [==============================] - 4s 629ms/step - loss: 0.0986 - mae: 0.0986 - val_loss: 0.1290 - val_mae: 0.1290\n",
      "Epoch 414/800\n",
      "6/6 [==============================] - 3s 572ms/step - loss: 0.0985 - mae: 0.0985 - val_loss: 0.1259 - val_mae: 0.1259\n",
      "Epoch 415/800\n",
      "6/6 [==============================] - 4s 722ms/step - loss: 0.0983 - mae: 0.0983 - val_loss: 0.1241 - val_mae: 0.1241\n",
      "Epoch 416/800\n",
      "6/6 [==============================] - 3s 568ms/step - loss: 0.0980 - mae: 0.0980 - val_loss: 0.1209 - val_mae: 0.1209\n",
      "Epoch 417/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.0982 - mae: 0.0982 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 418/800\n",
      "6/6 [==============================] - 3s 510ms/step - loss: 0.0979 - mae: 0.0979 - val_loss: 0.1230 - val_mae: 0.1230\n",
      "Epoch 419/800\n",
      "6/6 [==============================] - 3s 489ms/step - loss: 0.0977 - mae: 0.0977 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 420/800\n",
      "6/6 [==============================] - 3s 436ms/step - loss: 0.0975 - mae: 0.0975 - val_loss: 0.1174 - val_mae: 0.1174\n",
      "Epoch 421/800\n",
      "6/6 [==============================] - 3s 486ms/step - loss: 0.0972 - mae: 0.0972 - val_loss: 0.1167 - val_mae: 0.1167\n",
      "Epoch 422/800\n",
      "6/6 [==============================] - 3s 453ms/step - loss: 0.0970 - mae: 0.0970 - val_loss: 0.1162 - val_mae: 0.1162\n",
      "Epoch 423/800\n",
      "6/6 [==============================] - 3s 463ms/step - loss: 0.0968 - mae: 0.0968 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 424/800\n",
      "6/6 [==============================] - 3s 442ms/step - loss: 0.0967 - mae: 0.0967 - val_loss: 0.1161 - val_mae: 0.1161\n",
      "Epoch 425/800\n",
      "6/6 [==============================] - 3s 424ms/step - loss: 0.0970 - mae: 0.0970 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 426/800\n",
      "6/6 [==============================] - 2s 408ms/step - loss: 0.0967 - mae: 0.0967 - val_loss: 0.1162 - val_mae: 0.1162\n",
      "Epoch 427/800\n",
      "6/6 [==============================] - 3s 486ms/step - loss: 0.0968 - mae: 0.0968 - val_loss: 0.1203 - val_mae: 0.1203\n",
      "Epoch 428/800\n",
      "6/6 [==============================] - 3s 507ms/step - loss: 0.0966 - mae: 0.0966 - val_loss: 0.1174 - val_mae: 0.1174\n",
      "Epoch 429/800\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.0965 - mae: 0.0965 - val_loss: 0.1178 - val_mae: 0.1178\n",
      "Epoch 430/800\n",
      "6/6 [==============================] - 3s 532ms/step - loss: 0.0967 - mae: 0.0967 - val_loss: 0.1178 - val_mae: 0.1178\n",
      "Epoch 431/800\n",
      "6/6 [==============================] - 3s 570ms/step - loss: 0.0966 - mae: 0.0966 - val_loss: 0.1162 - val_mae: 0.1162\n",
      "Epoch 432/800\n",
      "6/6 [==============================] - 3s 489ms/step - loss: 0.0966 - mae: 0.0966 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 433/800\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.0965 - mae: 0.0965 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 434/800\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.0964 - mae: 0.0964 - val_loss: 0.1173 - val_mae: 0.1173\n",
      "Epoch 435/800\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0964 - mae: 0.0964 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 436/800\n",
      "6/6 [==============================] - 3s 553ms/step - loss: 0.0962 - mae: 0.0962 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 437/800\n",
      "6/6 [==============================] - 3s 556ms/step - loss: 0.0963 - mae: 0.0963 - val_loss: 0.1192 - val_mae: 0.1192\n",
      "Epoch 438/800\n",
      "6/6 [==============================] - 3s 507ms/step - loss: 0.0962 - mae: 0.0962 - val_loss: 0.1155 - val_mae: 0.1155\n",
      "Epoch 439/800\n",
      "6/6 [==============================] - 3s 511ms/step - loss: 0.0963 - mae: 0.0963 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 440/800\n",
      "6/6 [==============================] - 3s 525ms/step - loss: 0.0962 - mae: 0.0962 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 441/800\n",
      "6/6 [==============================] - 3s 482ms/step - loss: 0.0959 - mae: 0.0959 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 442/800\n",
      "6/6 [==============================] - 3s 458ms/step - loss: 0.0961 - mae: 0.0961 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 443/800\n",
      "6/6 [==============================] - 3s 512ms/step - loss: 0.0959 - mae: 0.0959 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 444/800\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 0.0960 - mae: 0.0960 - val_loss: 0.1161 - val_mae: 0.1161\n",
      "Epoch 445/800\n",
      "6/6 [==============================] - 4s 582ms/step - loss: 0.0960 - mae: 0.0960 - val_loss: 0.1170 - val_mae: 0.1170\n",
      "Epoch 446/800\n",
      "6/6 [==============================] - 3s 529ms/step - loss: 0.0959 - mae: 0.0959 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 447/800\n",
      "6/6 [==============================] - 3s 548ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.1167 - val_mae: 0.1167\n",
      "Epoch 448/800\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.1173 - val_mae: 0.1173\n",
      "Epoch 449/800\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 450/800\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 451/800\n",
      "6/6 [==============================] - 3s 489ms/step - loss: 0.0962 - mae: 0.0962 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 452/800\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.0957 - mae: 0.0957 - val_loss: 0.1181 - val_mae: 0.1181\n",
      "Epoch 453/800\n",
      "6/6 [==============================] - 3s 499ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.1186 - val_mae: 0.1186\n",
      "Epoch 454/800\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.1175 - val_mae: 0.1175\n",
      "Epoch 455/800\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 456/800\n",
      "6/6 [==============================] - 3s 494ms/step - loss: 0.0956 - mae: 0.0956 - val_loss: 0.1173 - val_mae: 0.1173\n",
      "Epoch 457/800\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.0957 - mae: 0.0957 - val_loss: 0.1170 - val_mae: 0.1170\n",
      "Epoch 458/800\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.0955 - mae: 0.0955 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 459/800\n",
      "6/6 [==============================] - 3s 494ms/step - loss: 0.0957 - mae: 0.0957 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 460/800\n",
      "6/6 [==============================] - 3s 500ms/step - loss: 0.0957 - mae: 0.0957 - val_loss: 0.1171 - val_mae: 0.1171\n",
      "Epoch 461/800\n",
      "6/6 [==============================] - 3s 469ms/step - loss: 0.0955 - mae: 0.0955 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 462/800\n",
      "6/6 [==============================] - 3s 453ms/step - loss: 0.0957 - mae: 0.0957 - val_loss: 0.1167 - val_mae: 0.1167\n",
      "Epoch 463/800\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.0954 - mae: 0.0954 - val_loss: 0.1188 - val_mae: 0.1188\n",
      "Epoch 464/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 465/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.0954 - mae: 0.0954 - val_loss: 0.1167 - val_mae: 0.1167\n",
      "Epoch 466/800\n",
      "6/6 [==============================] - 3s 515ms/step - loss: 0.0956 - mae: 0.0956 - val_loss: 0.1191 - val_mae: 0.1191\n",
      "Epoch 467/800\n",
      "6/6 [==============================] - 3s 520ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1193 - val_mae: 0.1193\n",
      "Epoch 468/800\n",
      "6/6 [==============================] - 3s 510ms/step - loss: 0.0954 - mae: 0.0954 - val_loss: 0.1175 - val_mae: 0.1175\n",
      "Epoch 469/800\n",
      "6/6 [==============================] - 3s 500ms/step - loss: 0.0954 - mae: 0.0954 - val_loss: 0.1174 - val_mae: 0.1174\n",
      "Epoch 470/800\n",
      "6/6 [==============================] - 3s 438ms/step - loss: 0.0954 - mae: 0.0954 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 471/800\n",
      "6/6 [==============================] - 3s 441ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 472/800\n",
      "6/6 [==============================] - 3s 451ms/step - loss: 0.0954 - mae: 0.0954 - val_loss: 0.1181 - val_mae: 0.1181\n",
      "Epoch 473/800\n",
      "6/6 [==============================] - 3s 435ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 474/800\n",
      "6/6 [==============================] - 3s 425ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 475/800\n",
      "6/6 [==============================] - 3s 448ms/step - loss: 0.0951 - mae: 0.0951 - val_loss: 0.1186 - val_mae: 0.1186\n",
      "Epoch 476/800\n",
      "6/6 [==============================] - 3s 445ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1172 - val_mae: 0.1172\n",
      "Epoch 477/800\n",
      "6/6 [==============================] - 3s 452ms/step - loss: 0.0951 - mae: 0.0951 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 478/800\n",
      "6/6 [==============================] - 3s 539ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1171 - val_mae: 0.1171\n",
      "Epoch 479/800\n",
      "6/6 [==============================] - 3s 559ms/step - loss: 0.0949 - mae: 0.0949 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 480/800\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 481/800\n",
      "6/6 [==============================] - 3s 515ms/step - loss: 0.0952 - mae: 0.0952 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 482/800\n",
      "6/6 [==============================] - 3s 501ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1181 - val_mae: 0.1181\n",
      "Epoch 483/800\n",
      "6/6 [==============================] - 3s 455ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 484/800\n",
      "6/6 [==============================] - 3s 448ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 485/800\n",
      "6/6 [==============================] - 3s 449ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 486/800\n",
      "6/6 [==============================] - 3s 446ms/step - loss: 0.0952 - mae: 0.0952 - val_loss: 0.1183 - val_mae: 0.1183\n",
      "Epoch 487/800\n",
      "6/6 [==============================] - 3s 465ms/step - loss: 0.0951 - mae: 0.0951 - val_loss: 0.1189 - val_mae: 0.1189\n",
      "Epoch 488/800\n",
      "6/6 [==============================] - 3s 550ms/step - loss: 0.0949 - mae: 0.0949 - val_loss: 0.1181 - val_mae: 0.1181\n",
      "Epoch 489/800\n",
      "6/6 [==============================] - 3s 467ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 490/800\n",
      "6/6 [==============================] - 3s 464ms/step - loss: 0.0949 - mae: 0.0949 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 491/800\n",
      "6/6 [==============================] - 3s 463ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1181 - val_mae: 0.1181\n",
      "Epoch 492/800\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1181 - val_mae: 0.1181\n",
      "Epoch 493/800\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1185 - val_mae: 0.1185\n",
      "Epoch 494/800\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 495/800\n",
      "6/6 [==============================] - 3s 508ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 496/800\n",
      "6/6 [==============================] - 3s 554ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 497/800\n",
      "6/6 [==============================] - 3s 511ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1185 - val_mae: 0.1185\n",
      "Epoch 498/800\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1180 - val_mae: 0.1180\n",
      "Epoch 499/800\n",
      "6/6 [==============================] - 3s 561ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1187 - val_mae: 0.1187\n",
      "Epoch 500/800\n",
      "6/6 [==============================] - 3s 537ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 501/800\n",
      "6/6 [==============================] - 3s 520ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1206 - val_mae: 0.1206\n",
      "Epoch 502/800\n",
      "6/6 [==============================] - 3s 491ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 503/800\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 504/800\n",
      "6/6 [==============================] - 3s 563ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1190 - val_mae: 0.1190\n",
      "Epoch 505/800\n",
      "6/6 [==============================] - 3s 587ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1182 - val_mae: 0.1182\n",
      "Epoch 506/800\n",
      "6/6 [==============================] - 3s 589ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1188 - val_mae: 0.1188\n",
      "Epoch 507/800\n",
      "6/6 [==============================] - 3s 506ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1185 - val_mae: 0.1185\n",
      "Epoch 508/800\n",
      "6/6 [==============================] - 3s 520ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1190 - val_mae: 0.1190\n",
      "Epoch 509/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1191 - val_mae: 0.1191\n",
      "Epoch 510/800\n",
      "6/6 [==============================] - 3s 513ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 511/800\n",
      "6/6 [==============================] - 3s 521ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 512/800\n",
      "6/6 [==============================] - 3s 527ms/step - loss: 0.0944 - mae: 0.0944 - val_loss: 0.1189 - val_mae: 0.1189\n",
      "Epoch 513/800\n",
      "6/6 [==============================] - 3s 549ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 514/800\n",
      "6/6 [==============================] - 3s 487ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1202 - val_mae: 0.1202\n",
      "Epoch 515/800\n",
      "6/6 [==============================] - 3s 466ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1188 - val_mae: 0.1188\n",
      "Epoch 516/800\n",
      "6/6 [==============================] - 3s 467ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1194 - val_mae: 0.1194\n",
      "Epoch 517/800\n",
      "6/6 [==============================] - 3s 592ms/step - loss: 0.0944 - mae: 0.0944 - val_loss: 0.1186 - val_mae: 0.1186\n",
      "Epoch 518/800\n",
      "6/6 [==============================] - 3s 565ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1195 - val_mae: 0.1195\n",
      "Epoch 519/800\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1188 - val_mae: 0.1188\n",
      "Epoch 520/800\n",
      "6/6 [==============================] - 3s 435ms/step - loss: 0.0943 - mae: 0.0943 - val_loss: 0.1180 - val_mae: 0.1180\n",
      "Epoch 521/800\n",
      "6/6 [==============================] - 3s 450ms/step - loss: 0.0944 - mae: 0.0944 - val_loss: 0.1194 - val_mae: 0.1194\n",
      "Epoch 522/800\n",
      "6/6 [==============================] - 3s 501ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 523/800\n",
      "6/6 [==============================] - 3s 425ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1192 - val_mae: 0.1192\n",
      "Epoch 524/800\n",
      "6/6 [==============================] - 3s 438ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.1183 - val_mae: 0.1183\n",
      "Epoch 525/800\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.0952 - mae: 0.0952 - val_loss: 0.1385 - val_mae: 0.1385\n",
      "Epoch 526/800\n",
      "6/6 [==============================] - 3s 551ms/step - loss: 0.1022 - mae: 0.1022 - val_loss: 0.2096 - val_mae: 0.2096\n",
      "Epoch 527/800\n",
      "6/6 [==============================] - 3s 491ms/step - loss: 0.1046 - mae: 0.1046 - val_loss: 0.3546 - val_mae: 0.3546\n",
      "Epoch 528/800\n",
      "6/6 [==============================] - 3s 500ms/step - loss: 0.1070 - mae: 0.1070 - val_loss: 0.1673 - val_mae: 0.1673\n",
      "Epoch 529/800\n",
      "6/6 [==============================] - 3s 460ms/step - loss: 0.1059 - mae: 0.1059 - val_loss: 0.1369 - val_mae: 0.1369\n",
      "Epoch 530/800\n",
      "6/6 [==============================] - 3s 463ms/step - loss: 0.1035 - mae: 0.1035 - val_loss: 0.1319 - val_mae: 0.1319\n",
      "Epoch 531/800\n",
      "6/6 [==============================] - 3s 451ms/step - loss: 0.1023 - mae: 0.1023 - val_loss: 0.1341 - val_mae: 0.1341\n",
      "Epoch 532/800\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.1013 - mae: 0.1013 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 533/800\n",
      "6/6 [==============================] - 3s 494ms/step - loss: 0.1010 - mae: 0.1010 - val_loss: 0.1296 - val_mae: 0.1296\n",
      "Epoch 534/800\n",
      "6/6 [==============================] - 3s 604ms/step - loss: 0.1001 - mae: 0.1001 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 535/800\n",
      "6/6 [==============================] - 3s 539ms/step - loss: 0.0996 - mae: 0.0996 - val_loss: 0.1290 - val_mae: 0.1290\n",
      "Epoch 536/800\n",
      "6/6 [==============================] - 3s 555ms/step - loss: 0.0993 - mae: 0.0993 - val_loss: 0.1280 - val_mae: 0.1280\n",
      "Epoch 537/800\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.0990 - mae: 0.0990 - val_loss: 0.1284 - val_mae: 0.1284\n",
      "Epoch 538/800\n",
      "6/6 [==============================] - 3s 483ms/step - loss: 0.0984 - mae: 0.0984 - val_loss: 0.1257 - val_mae: 0.1257\n",
      "Epoch 539/800\n",
      "6/6 [==============================] - 3s 503ms/step - loss: 0.0981 - mae: 0.0981 - val_loss: 0.1270 - val_mae: 0.1270\n",
      "Epoch 540/800\n",
      "6/6 [==============================] - 3s 476ms/step - loss: 0.0980 - mae: 0.0980 - val_loss: 0.1256 - val_mae: 0.1256\n",
      "Epoch 541/800\n",
      "6/6 [==============================] - 3s 533ms/step - loss: 0.0981 - mae: 0.0981 - val_loss: 0.1240 - val_mae: 0.1240\n",
      "Epoch 542/800\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 0.0971 - mae: 0.0971 - val_loss: 0.1247 - val_mae: 0.1247\n",
      "Epoch 543/800\n",
      "6/6 [==============================] - 3s 552ms/step - loss: 0.0973 - mae: 0.0973 - val_loss: 0.1212 - val_mae: 0.1212\n",
      "Epoch 544/800\n",
      "6/6 [==============================] - 3s 568ms/step - loss: 0.0968 - mae: 0.0968 - val_loss: 0.1202 - val_mae: 0.1202\n",
      "Epoch 545/800\n",
      "6/6 [==============================] - 3s 580ms/step - loss: 0.0964 - mae: 0.0964 - val_loss: 0.1216 - val_mae: 0.1216\n",
      "Epoch 546/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.0963 - mae: 0.0963 - val_loss: 0.1236 - val_mae: 0.1236\n",
      "Epoch 547/800\n",
      "6/6 [==============================] - 3s 568ms/step - loss: 0.0961 - mae: 0.0961 - val_loss: 0.1227 - val_mae: 0.1227\n",
      "Epoch 548/800\n",
      "6/6 [==============================] - 3s 549ms/step - loss: 0.0959 - mae: 0.0959 - val_loss: 0.1221 - val_mae: 0.1221\n",
      "Epoch 549/800\n",
      "6/6 [==============================] - 3s 514ms/step - loss: 0.0955 - mae: 0.0955 - val_loss: 0.1226 - val_mae: 0.1226\n",
      "Epoch 550/800\n",
      "6/6 [==============================] - 3s 537ms/step - loss: 0.0956 - mae: 0.0956 - val_loss: 0.1243 - val_mae: 0.1243\n",
      "Epoch 551/800\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 0.0954 - mae: 0.0954 - val_loss: 0.1232 - val_mae: 0.1232\n",
      "Epoch 552/800\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 0.0955 - mae: 0.0955 - val_loss: 0.1232 - val_mae: 0.1232\n",
      "Epoch 553/800\n",
      "6/6 [==============================] - 3s 552ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1239 - val_mae: 0.1239\n",
      "Epoch 554/800\n",
      "6/6 [==============================] - 3s 554ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1246 - val_mae: 0.1246\n",
      "Epoch 555/800\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1235 - val_mae: 0.1235\n",
      "Epoch 556/800\n",
      "6/6 [==============================] - 3s 502ms/step - loss: 0.0952 - mae: 0.0952 - val_loss: 0.1231 - val_mae: 0.1231\n",
      "Epoch 557/800\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.0953 - mae: 0.0953 - val_loss: 0.1227 - val_mae: 0.1227\n",
      "Epoch 558/800\n",
      "6/6 [==============================] - 3s 506ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1228 - val_mae: 0.1228\n",
      "Epoch 559/800\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1220 - val_mae: 0.1220\n",
      "Epoch 560/800\n",
      "6/6 [==============================] - 3s 521ms/step - loss: 0.0951 - mae: 0.0951 - val_loss: 0.1216 - val_mae: 0.1216\n",
      "Epoch 561/800\n",
      "6/6 [==============================] - 3s 464ms/step - loss: 0.0952 - mae: 0.0952 - val_loss: 0.1218 - val_mae: 0.1218\n",
      "Epoch 562/800\n",
      "6/6 [==============================] - 3s 462ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.1221 - val_mae: 0.1221\n",
      "Epoch 563/800\n",
      "6/6 [==============================] - 3s 505ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1221 - val_mae: 0.1221\n",
      "Epoch 564/800\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.0949 - mae: 0.0949 - val_loss: 0.1213 - val_mae: 0.1213\n",
      "Epoch 565/800\n",
      "6/6 [==============================] - 3s 503ms/step - loss: 0.0948 - mae: 0.0948 - val_loss: 0.1213 - val_mae: 0.1213\n",
      "Epoch 566/800\n",
      "6/6 [==============================] - 3s 469ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1229 - val_mae: 0.1229\n",
      "Epoch 567/800\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1208 - val_mae: 0.1208\n",
      "Epoch 568/800\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1208 - val_mae: 0.1208\n",
      "Epoch 569/800\n",
      "6/6 [==============================] - 3s 528ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1198 - val_mae: 0.1198\n",
      "Epoch 570/800\n",
      "6/6 [==============================] - 3s 579ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1199 - val_mae: 0.1199\n",
      "Epoch 571/800\n",
      "6/6 [==============================] - 4s 629ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1214 - val_mae: 0.1214\n",
      "Epoch 572/800\n",
      "6/6 [==============================] - 4s 638ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.1199 - val_mae: 0.1199\n",
      "Epoch 573/800\n",
      "6/6 [==============================] - 4s 592ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1192 - val_mae: 0.1192\n",
      "Epoch 574/800\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 0.0944 - mae: 0.0944 - val_loss: 0.1189 - val_mae: 0.1189\n",
      "Epoch 575/800\n",
      "6/6 [==============================] - 3s 513ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 576/800\n",
      "6/6 [==============================] - 4s 620ms/step - loss: 0.0946 - mae: 0.0946 - val_loss: 0.1208 - val_mae: 0.1208\n",
      "Epoch 577/800\n",
      "6/6 [==============================] - 4s 656ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1207 - val_mae: 0.1207\n",
      "Epoch 578/800\n",
      "6/6 [==============================] - 3s 553ms/step - loss: 0.0944 - mae: 0.0944 - val_loss: 0.1189 - val_mae: 0.1189\n",
      "Epoch 579/800\n",
      "6/6 [==============================] - 4s 667ms/step - loss: 0.0941 - mae: 0.0941 - val_loss: 0.1180 - val_mae: 0.1180\n",
      "Epoch 580/800\n",
      "6/6 [==============================] - 4s 613ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1191 - val_mae: 0.1191\n",
      "Epoch 581/800\n",
      "6/6 [==============================] - 4s 640ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 582/800\n",
      "6/6 [==============================] - 3s 573ms/step - loss: 0.0943 - mae: 0.0943 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 583/800\n",
      "6/6 [==============================] - 3s 558ms/step - loss: 0.0944 - mae: 0.0944 - val_loss: 0.1172 - val_mae: 0.1172\n",
      "Epoch 584/800\n",
      "6/6 [==============================] - 4s 677ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.1173 - val_mae: 0.1173\n",
      "Epoch 585/800\n",
      "6/6 [==============================] - 3s 527ms/step - loss: 0.0945 - mae: 0.0945 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 586/800\n",
      "6/6 [==============================] - 3s 549ms/step - loss: 0.0941 - mae: 0.0941 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 587/800\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.1175 - val_mae: 0.1175\n",
      "Epoch 588/800\n",
      "6/6 [==============================] - 3s 506ms/step - loss: 0.0943 - mae: 0.0943 - val_loss: 0.1171 - val_mae: 0.1171\n",
      "Epoch 589/800\n",
      "6/6 [==============================] - 4s 605ms/step - loss: 0.0940 - mae: 0.0940 - val_loss: 0.1175 - val_mae: 0.1175\n",
      "Epoch 590/800\n",
      "6/6 [==============================] - 3s 523ms/step - loss: 0.0943 - mae: 0.0943 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 591/800\n",
      "6/6 [==============================] - 3s 555ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.1184 - val_mae: 0.1184\n",
      "Epoch 592/800\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.0944 - mae: 0.0944 - val_loss: 0.1179 - val_mae: 0.1179\n",
      "Epoch 593/800\n",
      "6/6 [==============================] - 3s 564ms/step - loss: 0.0940 - mae: 0.0940 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 594/800\n",
      "6/6 [==============================] - 4s 601ms/step - loss: 0.0939 - mae: 0.0939 - val_loss: 0.1163 - val_mae: 0.1163\n",
      "Epoch 595/800\n",
      "6/6 [==============================] - 4s 577ms/step - loss: 0.0940 - mae: 0.0940 - val_loss: 0.1164 - val_mae: 0.1164\n",
      "Epoch 596/800\n",
      "6/6 [==============================] - 4s 601ms/step - loss: 0.0941 - mae: 0.0941 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 597/800\n",
      "6/6 [==============================] - 4s 618ms/step - loss: 0.0940 - mae: 0.0940 - val_loss: 0.1161 - val_mae: 0.1161\n",
      "Epoch 598/800\n",
      "6/6 [==============================] - 4s 607ms/step - loss: 0.0942 - mae: 0.0942 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 599/800\n",
      "6/6 [==============================] - 4s 586ms/step - loss: 0.0939 - mae: 0.0939 - val_loss: 0.1173 - val_mae: 0.1173\n",
      "Epoch 600/800\n",
      "6/6 [==============================] - 4s 613ms/step - loss: 0.0939 - mae: 0.0939 - val_loss: 0.1161 - val_mae: 0.1161\n",
      "Epoch 601/800\n",
      "6/6 [==============================] - 4s 590ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 602/800\n",
      "6/6 [==============================] - 3s 566ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 603/800\n",
      "6/6 [==============================] - 3s 575ms/step - loss: 0.0940 - mae: 0.0940 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 604/800\n",
      "6/6 [==============================] - 3s 554ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1163 - val_mae: 0.1163\n",
      "Epoch 605/800\n",
      "6/6 [==============================] - 4s 642ms/step - loss: 0.0939 - mae: 0.0939 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 606/800\n",
      "6/6 [==============================] - 3s 561ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1170 - val_mae: 0.1170\n",
      "Epoch 607/800\n",
      "6/6 [==============================] - 4s 605ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1162 - val_mae: 0.1162\n",
      "Epoch 608/800\n",
      "6/6 [==============================] - 4s 611ms/step - loss: 0.0939 - mae: 0.0939 - val_loss: 0.1176 - val_mae: 0.1176\n",
      "Epoch 609/800\n",
      "6/6 [==============================] - 4s 683ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1161 - val_mae: 0.1161\n",
      "Epoch 610/800\n",
      "6/6 [==============================] - 4s 625ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 611/800\n",
      "6/6 [==============================] - 4s 674ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 612/800\n",
      "6/6 [==============================] - 4s 665ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 613/800\n",
      "6/6 [==============================] - 4s 667ms/step - loss: 0.0941 - mae: 0.0941 - val_loss: 0.1154 - val_mae: 0.1154\n",
      "Epoch 614/800\n",
      "6/6 [==============================] - 4s 654ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 615/800\n",
      "6/6 [==============================] - 4s 674ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 616/800\n",
      "6/6 [==============================] - 4s 596ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 617/800\n",
      "6/6 [==============================] - 4s 685ms/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 618/800\n",
      "6/6 [==============================] - 4s 664ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1154 - val_mae: 0.1154\n",
      "Epoch 619/800\n",
      "6/6 [==============================] - 3s 537ms/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 620/800\n",
      "6/6 [==============================] - 3s 565ms/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 621/800\n",
      "6/6 [==============================] - 4s 704ms/step - loss: 0.0939 - mae: 0.0939 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 622/800\n",
      "6/6 [==============================] - 3s 574ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 623/800\n",
      "6/6 [==============================] - 3s 588ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 624/800\n",
      "6/6 [==============================] - 4s 666ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 625/800\n",
      "6/6 [==============================] - 4s 608ms/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 626/800\n",
      "6/6 [==============================] - 4s 627ms/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.1168 - val_mae: 0.1168\n",
      "Epoch 627/800\n",
      "6/6 [==============================] - 3s 542ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 628/800\n",
      "6/6 [==============================] - 3s 593ms/step - loss: 0.0936 - mae: 0.0936 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 629/800\n",
      "6/6 [==============================] - 3s 555ms/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 630/800\n",
      "6/6 [==============================] - 3s 560ms/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 631/800\n",
      "6/6 [==============================] - 4s 609ms/step - loss: 0.0932 - mae: 0.0932 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 632/800\n",
      "6/6 [==============================] - 4s 671ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 633/800\n",
      "6/6 [==============================] - 4s 668ms/step - loss: 0.0934 - mae: 0.0934 - val_loss: 0.1155 - val_mae: 0.1155\n",
      "Epoch 634/800\n",
      "6/6 [==============================] - 4s 716ms/step - loss: 0.0936 - mae: 0.0936 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 635/800\n",
      "6/6 [==============================] - 4s 659ms/step - loss: 0.0934 - mae: 0.0934 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 636/800\n",
      "6/6 [==============================] - 4s 640ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.1155 - val_mae: 0.1155\n",
      "Epoch 637/800\n",
      "6/6 [==============================] - 4s 636ms/step - loss: 0.0936 - mae: 0.0936 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 638/800\n",
      "6/6 [==============================] - 4s 681ms/step - loss: 0.0932 - mae: 0.0932 - val_loss: 0.1155 - val_mae: 0.1155\n",
      "Epoch 639/800\n",
      "6/6 [==============================] - 3s 553ms/step - loss: 0.0934 - mae: 0.0934 - val_loss: 0.1169 - val_mae: 0.1169\n",
      "Epoch 640/800\n",
      "6/6 [==============================] - 3s 550ms/step - loss: 0.0931 - mae: 0.0931 - val_loss: 0.1154 - val_mae: 0.1154\n",
      "Epoch 641/800\n",
      "6/6 [==============================] - 4s 599ms/step - loss: 0.0932 - mae: 0.0932 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 642/800\n",
      "6/6 [==============================] - 3s 531ms/step - loss: 0.0934 - mae: 0.0934 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 643/800\n",
      "6/6 [==============================] - 3s 511ms/step - loss: 0.0930 - mae: 0.0930 - val_loss: 0.1161 - val_mae: 0.1161\n",
      "Epoch 644/800\n",
      "6/6 [==============================] - 3s 505ms/step - loss: 0.0934 - mae: 0.0934 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 645/800\n",
      "6/6 [==============================] - 3s 524ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.1161 - val_mae: 0.1161\n",
      "Epoch 646/800\n",
      "6/6 [==============================] - 3s 507ms/step - loss: 0.0932 - mae: 0.0932 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 647/800\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.0930 - mae: 0.0930 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 648/800\n",
      "6/6 [==============================] - 3s 556ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 649/800\n",
      "6/6 [==============================] - 3s 513ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 650/800\n",
      "6/6 [==============================] - 3s 586ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 651/800\n",
      "6/6 [==============================] - 3s 540ms/step - loss: 0.0931 - mae: 0.0931 - val_loss: 0.1162 - val_mae: 0.1162\n",
      "Epoch 652/800\n",
      "6/6 [==============================] - 4s 599ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 653/800\n",
      "6/6 [==============================] - 3s 528ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 654/800\n",
      "6/6 [==============================] - 3s 545ms/step - loss: 0.0931 - mae: 0.0931 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 655/800\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.0931 - mae: 0.0931 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 656/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.0932 - mae: 0.0932 - val_loss: 0.1166 - val_mae: 0.1166\n",
      "Epoch 657/800\n",
      "6/6 [==============================] - 3s 524ms/step - loss: 0.0931 - mae: 0.0931 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 658/800\n",
      "6/6 [==============================] - 3s 560ms/step - loss: 0.0930 - mae: 0.0930 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 659/800\n",
      "6/6 [==============================] - 4s 629ms/step - loss: 0.0931 - mae: 0.0931 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 660/800\n",
      "6/6 [==============================] - 4s 645ms/step - loss: 0.0930 - mae: 0.0930 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 661/800\n",
      "6/6 [==============================] - 3s 570ms/step - loss: 0.0931 - mae: 0.0931 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 662/800\n",
      "6/6 [==============================] - 3s 515ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1155 - val_mae: 0.1155\n",
      "Epoch 663/800\n",
      "6/6 [==============================] - 3s 527ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 664/800\n",
      "6/6 [==============================] - 3s 536ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 665/800\n",
      "6/6 [==============================] - 3s 508ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 666/800\n",
      "6/6 [==============================] - 3s 498ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 667/800\n",
      "6/6 [==============================] - 3s 487ms/step - loss: 0.0931 - mae: 0.0931 - val_loss: 0.1162 - val_mae: 0.1162\n",
      "Epoch 668/800\n",
      "6/6 [==============================] - 3s 560ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 669/800\n",
      "6/6 [==============================] - 3s 527ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 670/800\n",
      "6/6 [==============================] - 3s 520ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 671/800\n",
      "6/6 [==============================] - 3s 541ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 672/800\n",
      "6/6 [==============================] - 4s 629ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1158 - val_mae: 0.1158\n",
      "Epoch 673/800\n",
      "6/6 [==============================] - 4s 624ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 674/800\n",
      "6/6 [==============================] - 4s 573ms/step - loss: 0.0930 - mae: 0.0930 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 675/800\n",
      "6/6 [==============================] - 3s 499ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1160 - val_mae: 0.1160\n",
      "Epoch 676/800\n",
      "6/6 [==============================] - 3s 570ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1159 - val_mae: 0.1159\n",
      "Epoch 677/800\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 678/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 679/800\n",
      "6/6 [==============================] - 3s 565ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 680/800\n",
      "6/6 [==============================] - 3s 521ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 681/800\n",
      "6/6 [==============================] - 4s 661ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1167 - val_mae: 0.1167\n",
      "Epoch 682/800\n",
      "6/6 [==============================] - 5s 792ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 683/800\n",
      "6/6 [==============================] - 4s 727ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1146 - val_mae: 0.1146\n",
      "Epoch 684/800\n",
      "6/6 [==============================] - 5s 752ms/step - loss: 0.0930 - mae: 0.0930 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 685/800\n",
      "6/6 [==============================] - 4s 756ms/step - loss: 0.0926 - mae: 0.0926 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 686/800\n",
      "6/6 [==============================] - 5s 742ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 687/800\n",
      "6/6 [==============================] - 4s 754ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.1152 - val_mae: 0.1152\n",
      "Epoch 688/800\n",
      "6/6 [==============================] - 4s 682ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 689/800\n",
      "6/6 [==============================] - 4s 717ms/step - loss: 0.0926 - mae: 0.0926 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 690/800\n",
      "6/6 [==============================] - 4s 697ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 691/800\n",
      "6/6 [==============================] - 4s 600ms/step - loss: 0.0926 - mae: 0.0926 - val_loss: 0.1146 - val_mae: 0.1146\n",
      "Epoch 692/800\n",
      "6/6 [==============================] - 4s 694ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 693/800\n",
      "6/6 [==============================] - 3s 568ms/step - loss: 0.0929 - mae: 0.0929 - val_loss: 0.1156 - val_mae: 0.1156\n",
      "Epoch 694/800\n",
      "6/6 [==============================] - 3s 512ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 695/800\n",
      "6/6 [==============================] - 3s 521ms/step - loss: 0.0926 - mae: 0.0926 - val_loss: 0.1145 - val_mae: 0.1145\n",
      "Epoch 696/800\n",
      "6/6 [==============================] - 3s 517ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1145 - val_mae: 0.1145\n",
      "Epoch 697/800\n",
      "6/6 [==============================] - 3s 507ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 698/800\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.0923 - mae: 0.0923 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 699/800\n",
      "6/6 [==============================] - 3s 500ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 700/800\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1154 - val_mae: 0.1154\n",
      "Epoch 701/800\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1165 - val_mae: 0.1165\n",
      "Epoch 702/800\n",
      "6/6 [==============================] - 3s 468ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1151 - val_mae: 0.1151\n",
      "Epoch 703/800\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.1145 - val_mae: 0.1145\n",
      "Epoch 704/800\n",
      "6/6 [==============================] - 3s 423ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 705/800\n",
      "6/6 [==============================] - 3s 453ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1143 - val_mae: 0.1143\n",
      "Epoch 706/800\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1146 - val_mae: 0.1146\n",
      "Epoch 707/800\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 708/800\n",
      "6/6 [==============================] - 3s 443ms/step - loss: 0.0926 - mae: 0.0926 - val_loss: 0.1142 - val_mae: 0.1142\n",
      "Epoch 709/800\n",
      "6/6 [==============================] - 3s 467ms/step - loss: 0.0925 - mae: 0.0925 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 710/800\n",
      "6/6 [==============================] - 3s 438ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1148 - val_mae: 0.1148\n",
      "Epoch 711/800\n",
      "6/6 [==============================] - 3s 459ms/step - loss: 0.0924 - mae: 0.0924 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 712/800\n",
      "6/6 [==============================] - 3s 530ms/step - loss: 0.0923 - mae: 0.0923 - val_loss: 0.1138 - val_mae: 0.1138\n",
      "Epoch 713/800\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0924 - mae: 0.0924 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 714/800\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.0923 - mae: 0.0923 - val_loss: 0.1147 - val_mae: 0.1147\n",
      "Epoch 715/800\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.0924 - mae: 0.0924 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 716/800\n",
      "6/6 [==============================] - 3s 470ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1143 - val_mae: 0.1143\n",
      "Epoch 717/800\n",
      "6/6 [==============================] - 3s 462ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1144 - val_mae: 0.1144\n",
      "Epoch 718/800\n",
      "6/6 [==============================] - 3s 454ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1135 - val_mae: 0.1135\n",
      "Epoch 719/800\n",
      "6/6 [==============================] - 3s 470ms/step - loss: 0.0923 - mae: 0.0923 - val_loss: 0.1145 - val_mae: 0.1145\n",
      "Epoch 720/800\n",
      "6/6 [==============================] - 3s 454ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1140 - val_mae: 0.1140\n",
      "Epoch 721/800\n",
      "6/6 [==============================] - 3s 474ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1142 - val_mae: 0.1142\n",
      "Epoch 722/800\n",
      "6/6 [==============================] - 4s 611ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1150 - val_mae: 0.1150\n",
      "Epoch 723/800\n",
      "6/6 [==============================] - 3s 487ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1153 - val_mae: 0.1153\n",
      "Epoch 724/800\n",
      "6/6 [==============================] - 3s 513ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1139 - val_mae: 0.1139\n",
      "Epoch 725/800\n",
      "6/6 [==============================] - 3s 513ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1142 - val_mae: 0.1142\n",
      "Epoch 726/800\n",
      "6/6 [==============================] - 3s 498ms/step - loss: 0.0926 - mae: 0.0926 - val_loss: 0.1134 - val_mae: 0.1134\n",
      "Epoch 727/800\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0924 - mae: 0.0924 - val_loss: 0.1142 - val_mae: 0.1142\n",
      "Epoch 728/800\n",
      "6/6 [==============================] - 4s 611ms/step - loss: 0.0924 - mae: 0.0924 - val_loss: 0.1138 - val_mae: 0.1138\n",
      "Epoch 729/800\n",
      "6/6 [==============================] - 3s 499ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1128 - val_mae: 0.1128\n",
      "Epoch 730/800\n",
      "6/6 [==============================] - 4s 614ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 731/800\n",
      "6/6 [==============================] - 3s 574ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1133 - val_mae: 0.1133\n",
      "Epoch 732/800\n",
      "6/6 [==============================] - 3s 555ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1137 - val_mae: 0.1137\n",
      "Epoch 733/800\n",
      "6/6 [==============================] - 4s 621ms/step - loss: 0.0923 - mae: 0.0923 - val_loss: 0.1133 - val_mae: 0.1133\n",
      "Epoch 734/800\n",
      "6/6 [==============================] - 4s 612ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1124 - val_mae: 0.1124\n",
      "Epoch 735/800\n",
      "6/6 [==============================] - 4s 587ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1135 - val_mae: 0.1135\n",
      "Epoch 736/800\n",
      "6/6 [==============================] - 4s 691ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1122 - val_mae: 0.1122\n",
      "Epoch 737/800\n",
      "6/6 [==============================] - 4s 616ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1136 - val_mae: 0.1136\n",
      "Epoch 738/800\n",
      "6/6 [==============================] - 3s 553ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1126 - val_mae: 0.1126\n",
      "Epoch 739/800\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1132 - val_mae: 0.1132\n",
      "Epoch 740/800\n",
      "6/6 [==============================] - 3s 540ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1132 - val_mae: 0.1132\n",
      "Epoch 741/800\n",
      "6/6 [==============================] - 3s 526ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1125 - val_mae: 0.1125\n",
      "Epoch 742/800\n",
      "6/6 [==============================] - 3s 499ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1125 - val_mae: 0.1125\n",
      "Epoch 743/800\n",
      "6/6 [==============================] - 3s 556ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1141 - val_mae: 0.1141\n",
      "Epoch 744/800\n",
      "6/6 [==============================] - 3s 534ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1130 - val_mae: 0.1130\n",
      "Epoch 745/800\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1123 - val_mae: 0.1123\n",
      "Epoch 746/800\n",
      "6/6 [==============================] - 3s 483ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1128 - val_mae: 0.1128\n",
      "Epoch 747/800\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1132 - val_mae: 0.1132\n",
      "Epoch 748/800\n",
      "6/6 [==============================] - 3s 464ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1125 - val_mae: 0.1125\n",
      "Epoch 749/800\n",
      "6/6 [==============================] - 3s 450ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1126 - val_mae: 0.1126\n",
      "Epoch 750/800\n",
      "6/6 [==============================] - 3s 440ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1117 - val_mae: 0.1117\n",
      "Epoch 751/800\n",
      "6/6 [==============================] - 3s 439ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1119 - val_mae: 0.1119\n",
      "Epoch 752/800\n",
      "6/6 [==============================] - 3s 509ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1122 - val_mae: 0.1122\n",
      "Epoch 753/800\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1122 - val_mae: 0.1122\n",
      "Epoch 754/800\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1122 - val_mae: 0.1122\n",
      "Epoch 755/800\n",
      "6/6 [==============================] - 3s 468ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1130 - val_mae: 0.1130\n",
      "Epoch 756/800\n",
      "6/6 [==============================] - 3s 442ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.1122 - val_mae: 0.1122\n",
      "Epoch 757/800\n",
      "6/6 [==============================] - 3s 464ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.1116 - val_mae: 0.1116\n",
      "Epoch 758/800\n",
      "6/6 [==============================] - 3s 457ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1124 - val_mae: 0.1124\n",
      "Epoch 759/800\n",
      "6/6 [==============================] - 3s 468ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1124 - val_mae: 0.1124\n",
      "Epoch 760/800\n",
      "6/6 [==============================] - 3s 453ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1125 - val_mae: 0.1125\n",
      "Epoch 761/800\n",
      "6/6 [==============================] - 3s 451ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1138 - val_mae: 0.1138\n",
      "Epoch 762/800\n",
      "6/6 [==============================] - 3s 452ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1118 - val_mae: 0.1118\n",
      "Epoch 763/800\n",
      "6/6 [==============================] - 3s 528ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1118 - val_mae: 0.1118\n",
      "Epoch 764/800\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1115 - val_mae: 0.1115\n",
      "Epoch 765/800\n",
      "6/6 [==============================] - 3s 446ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1123 - val_mae: 0.1123\n",
      "Epoch 766/800\n",
      "6/6 [==============================] - 3s 423ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1151 - val_mae: 0.1151\n",
      "Epoch 767/800\n",
      "6/6 [==============================] - 3s 431ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1128 - val_mae: 0.1128\n",
      "Epoch 768/800\n",
      "6/6 [==============================] - 3s 423ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1113 - val_mae: 0.1113\n",
      "Epoch 769/800\n",
      "6/6 [==============================] - 3s 440ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1122 - val_mae: 0.1122\n",
      "Epoch 770/800\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1124 - val_mae: 0.1124\n",
      "Epoch 771/800\n",
      "6/6 [==============================] - 3s 519ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1117 - val_mae: 0.1117\n",
      "Epoch 772/800\n",
      "6/6 [==============================] - 3s 431ms/step - loss: 0.0919 - mae: 0.0919 - val_loss: 0.1122 - val_mae: 0.1122\n",
      "Epoch 773/800\n",
      "6/6 [==============================] - 3s 440ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1118 - val_mae: 0.1118\n",
      "Epoch 774/800\n",
      "6/6 [==============================] - 3s 443ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1110 - val_mae: 0.1110\n",
      "Epoch 775/800\n",
      "6/6 [==============================] - 3s 462ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1116 - val_mae: 0.1116\n",
      "Epoch 776/800\n",
      "6/6 [==============================] - 3s 510ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1113 - val_mae: 0.1113\n",
      "Epoch 777/800\n",
      "6/6 [==============================] - 3s 466ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1121 - val_mae: 0.1121\n",
      "Epoch 778/800\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1113 - val_mae: 0.1113\n",
      "Epoch 779/800\n",
      "6/6 [==============================] - 3s 435ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1116 - val_mae: 0.1116\n",
      "Epoch 780/800\n",
      "6/6 [==============================] - 3s 455ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1108 - val_mae: 0.1108\n",
      "Epoch 781/800\n",
      "6/6 [==============================] - 3s 435ms/step - loss: 0.0916 - mae: 0.0916 - val_loss: 0.1122 - val_mae: 0.1122\n",
      "Epoch 782/800\n",
      "6/6 [==============================] - 3s 428ms/step - loss: 0.0913 - mae: 0.0913 - val_loss: 0.1114 - val_mae: 0.1114\n",
      "Epoch 783/800\n",
      "6/6 [==============================] - 3s 433ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.1128 - val_mae: 0.1128\n",
      "Epoch 784/800\n",
      "6/6 [==============================] - 3s 455ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.1135 - val_mae: 0.1135\n",
      "Epoch 785/800\n",
      "6/6 [==============================] - 3s 440ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1114 - val_mae: 0.1114\n",
      "Epoch 786/800\n",
      "6/6 [==============================] - 3s 433ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1117 - val_mae: 0.1117\n",
      "Epoch 787/800\n",
      "6/6 [==============================] - 3s 452ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1123 - val_mae: 0.1123\n",
      "Epoch 788/800\n",
      "6/6 [==============================] - 3s 430ms/step - loss: 0.0912 - mae: 0.0912 - val_loss: 0.1119 - val_mae: 0.1119\n",
      "Epoch 789/800\n",
      "6/6 [==============================] - 3s 429ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1117 - val_mae: 0.1117\n",
      "Epoch 790/800\n",
      "6/6 [==============================] - 3s 432ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1104 - val_mae: 0.1104\n",
      "Epoch 791/800\n",
      "6/6 [==============================] - 3s 428ms/step - loss: 0.0918 - mae: 0.0918 - val_loss: 0.1177 - val_mae: 0.1177\n",
      "Epoch 792/800\n",
      "6/6 [==============================] - 3s 430ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1109 - val_mae: 0.1109\n",
      "Epoch 793/800\n",
      "6/6 [==============================] - 3s 428ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.1128 - val_mae: 0.1128\n",
      "Epoch 794/800\n",
      "6/6 [==============================] - 3s 430ms/step - loss: 0.0913 - mae: 0.0913 - val_loss: 0.1108 - val_mae: 0.1108\n",
      "Epoch 795/800\n",
      "6/6 [==============================] - 3s 438ms/step - loss: 0.0912 - mae: 0.0912 - val_loss: 0.1117 - val_mae: 0.1117\n",
      "Epoch 796/800\n",
      "6/6 [==============================] - 3s 453ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1101 - val_mae: 0.1101\n",
      "Epoch 797/800\n",
      "6/6 [==============================] - 3s 451ms/step - loss: 0.0917 - mae: 0.0917 - val_loss: 0.1124 - val_mae: 0.1124\n",
      "Epoch 798/800\n",
      "6/6 [==============================] - 3s 427ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.1108 - val_mae: 0.1108\n",
      "Epoch 799/800\n",
      "6/6 [==============================] - 2s 412ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.1101 - val_mae: 0.1101\n",
      "Epoch 800/800\n",
      "6/6 [==============================] - 2s 411ms/step - loss: 0.0912 - mae: 0.0912 - val_loss: 0.1095 - val_mae: 0.1095\n"
     ]
    }
   ],
   "source": [
    "history_model_multi_layers = model_multi_layers.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=256, epochs=800, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history_model_multi_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_model_multi_layers.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 16, 256)           2087936   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16, 256)           0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 16, 128)           197120    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 16, 1782)         229878    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,516,470\n",
      "Trainable params: 2,515,702\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=256, return_sequences=True,input_shape=[16, number_of_features]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "#TimeDistributed layer\n",
    "model.add(TimeDistributed(Dense(number_of_features)))\n",
    "\n",
    "model.compile(loss=\"mae\", optimizer=optimizer, metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi_layers.save('lstm_800_e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_all_np[-past:,:].reshape((1, past, number_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.6532125 , 0.        , 0.3868528 , ..., 0.4059596 ,\n",
       "         0.69828653, 0.6029426 ],\n",
       "        [0.47712123, 0.        , 0.5113916 , ..., 0.70009804,\n",
       "         0.91850716, 0.7255932 ],\n",
       "        [0.39793998, 0.        , 0.22629434, ..., 0.32810736,\n",
       "         0.8654007 , 0.79005706],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.47220516,\n",
       "         0.9159484 , 0.7346902 ],\n",
       "        [0.        , 0.        , 0.6991802 , ..., 0.33465004,\n",
       "         0.8997447 , 0.69234216],\n",
       "        [0.39793998, 0.        , 0.5113916 , ..., 0.687572  ,\n",
       "         0.82971567, 0.6766397 ]]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict = model_multi_layers.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3.6965591e-01,  1.7389012e-04,  3.6921644e-01, ...,\n",
       "          3.3915070e-01,  2.5919470e-01,  6.4794302e-01],\n",
       "        [ 3.6864752e-01,  6.8431080e-05,  3.7982821e-01, ...,\n",
       "          3.0671164e-01,  2.2939387e-01,  6.4670593e-01],\n",
       "        [ 3.9716944e-01,  3.7386999e-04,  3.9325941e-01, ...,\n",
       "          3.0071294e-01,  2.2309616e-01,  6.1994559e-01],\n",
       "        ...,\n",
       "        [ 4.1059250e-01,  5.4166809e-05,  3.9696515e-01, ...,\n",
       "          5.7578158e-01,  2.5335494e-01,  6.3128698e-01],\n",
       "        [ 3.8927209e-01, -1.7339834e-04,  3.9541209e-01, ...,\n",
       "          2.9224074e-01,  2.4553096e-01,  6.1766315e-01],\n",
       "        [ 3.3109090e-01, -1.6189988e-04,  3.7474293e-01, ...,\n",
       "          2.8168780e-01,  2.2700517e-01,  6.4108032e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.6965591e-01,  1.7389012e-04,  3.6921644e-01, ...,\n",
       "         3.3915070e-01,  2.5919470e-01,  6.4794302e-01],\n",
       "       [ 3.6864752e-01,  6.8431080e-05,  3.7982821e-01, ...,\n",
       "         3.0671164e-01,  2.2939387e-01,  6.4670593e-01],\n",
       "       [ 3.9716944e-01,  3.7386999e-04,  3.9325941e-01, ...,\n",
       "         3.0071294e-01,  2.2309616e-01,  6.1994559e-01],\n",
       "       ...,\n",
       "       [ 4.1059250e-01,  5.4166809e-05,  3.9696515e-01, ...,\n",
       "         5.7578158e-01,  2.5335494e-01,  6.3128698e-01],\n",
       "       [ 3.8927209e-01, -1.7339834e-04,  3.9541209e-01, ...,\n",
       "         2.9224074e-01,  2.4553096e-01,  6.1766315e-01],\n",
       "       [ 3.3109090e-01, -1.6189988e-04,  3.7474293e-01, ...,\n",
       "         2.8168780e-01,  2.2700517e-01,  6.4108032e-01]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict.reshape((16, number_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 1782)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_inversed = minmax.inverse_transform(Predict.reshape((16, number_of_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1782)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict_inversed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform from the previous min max scaler\n",
    "y_predict = pd.DataFrame(Predict_inversed,columns=X_pivoted.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.544311</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.354694</td>\n",
       "      <td>7.675069</td>\n",
       "      <td>0.187262</td>\n",
       "      <td>6.038983</td>\n",
       "      <td>2.800738</td>\n",
       "      <td>6.613937</td>\n",
       "      <td>6.656946</td>\n",
       "      <td>4.957291</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279410</td>\n",
       "      <td>5.889663</td>\n",
       "      <td>6.053737</td>\n",
       "      <td>1.770713</td>\n",
       "      <td>2.292630</td>\n",
       "      <td>6.050762</td>\n",
       "      <td>4.519764</td>\n",
       "      <td>7.214887</td>\n",
       "      <td>1.500727</td>\n",
       "      <td>2.728755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.541989</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>1.373708</td>\n",
       "      <td>7.704771</td>\n",
       "      <td>0.253827</td>\n",
       "      <td>6.059268</td>\n",
       "      <td>2.935014</td>\n",
       "      <td>6.644652</td>\n",
       "      <td>6.659185</td>\n",
       "      <td>4.955846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298907</td>\n",
       "      <td>5.938157</td>\n",
       "      <td>5.998296</td>\n",
       "      <td>1.764273</td>\n",
       "      <td>2.233401</td>\n",
       "      <td>5.990381</td>\n",
       "      <td>4.515714</td>\n",
       "      <td>7.161172</td>\n",
       "      <td>1.328181</td>\n",
       "      <td>2.724252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.607664</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>1.397774</td>\n",
       "      <td>7.779405</td>\n",
       "      <td>0.216840</td>\n",
       "      <td>6.063324</td>\n",
       "      <td>3.088867</td>\n",
       "      <td>6.633666</td>\n",
       "      <td>6.719116</td>\n",
       "      <td>5.111925</td>\n",
       "      <td>...</td>\n",
       "      <td>1.441533</td>\n",
       "      <td>5.749404</td>\n",
       "      <td>5.958526</td>\n",
       "      <td>1.777012</td>\n",
       "      <td>2.273731</td>\n",
       "      <td>6.111696</td>\n",
       "      <td>4.538804</td>\n",
       "      <td>7.151239</td>\n",
       "      <td>1.291718</td>\n",
       "      <td>2.626842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.630347</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>1.401060</td>\n",
       "      <td>7.748850</td>\n",
       "      <td>0.144777</td>\n",
       "      <td>5.976876</td>\n",
       "      <td>2.707307</td>\n",
       "      <td>6.459964</td>\n",
       "      <td>6.675728</td>\n",
       "      <td>4.921675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757240</td>\n",
       "      <td>6.066064</td>\n",
       "      <td>6.473705</td>\n",
       "      <td>2.149848</td>\n",
       "      <td>2.700736</td>\n",
       "      <td>6.377760</td>\n",
       "      <td>4.914499</td>\n",
       "      <td>7.541142</td>\n",
       "      <td>1.627911</td>\n",
       "      <td>3.103156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.128470</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>1.136662</td>\n",
       "      <td>7.042006</td>\n",
       "      <td>0.088563</td>\n",
       "      <td>5.227509</td>\n",
       "      <td>1.766250</td>\n",
       "      <td>5.750853</td>\n",
       "      <td>6.008966</td>\n",
       "      <td>4.212395</td>\n",
       "      <td>...</td>\n",
       "      <td>1.804818</td>\n",
       "      <td>6.192298</td>\n",
       "      <td>6.627496</td>\n",
       "      <td>2.321419</td>\n",
       "      <td>2.887187</td>\n",
       "      <td>6.534098</td>\n",
       "      <td>4.966452</td>\n",
       "      <td>7.777387</td>\n",
       "      <td>1.873662</td>\n",
       "      <td>3.276714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.510883</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1.429281</td>\n",
       "      <td>7.708746</td>\n",
       "      <td>0.090520</td>\n",
       "      <td>6.078387</td>\n",
       "      <td>2.615857</td>\n",
       "      <td>6.621103</td>\n",
       "      <td>6.682580</td>\n",
       "      <td>5.004357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.317408</td>\n",
       "      <td>5.968786</td>\n",
       "      <td>6.214417</td>\n",
       "      <td>1.804887</td>\n",
       "      <td>2.396450</td>\n",
       "      <td>6.096796</td>\n",
       "      <td>4.576283</td>\n",
       "      <td>7.335397</td>\n",
       "      <td>1.512545</td>\n",
       "      <td>2.744983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.640509</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1.412816</td>\n",
       "      <td>7.663773</td>\n",
       "      <td>0.100966</td>\n",
       "      <td>6.010575</td>\n",
       "      <td>2.727686</td>\n",
       "      <td>6.624913</td>\n",
       "      <td>6.645810</td>\n",
       "      <td>4.943985</td>\n",
       "      <td>...</td>\n",
       "      <td>1.317631</td>\n",
       "      <td>5.904322</td>\n",
       "      <td>6.143366</td>\n",
       "      <td>1.838949</td>\n",
       "      <td>2.322069</td>\n",
       "      <td>6.006927</td>\n",
       "      <td>4.591448</td>\n",
       "      <td>7.653942</td>\n",
       "      <td>1.436067</td>\n",
       "      <td>2.685885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.617059</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>1.408826</td>\n",
       "      <td>7.778501</td>\n",
       "      <td>0.105265</td>\n",
       "      <td>6.166919</td>\n",
       "      <td>2.858568</td>\n",
       "      <td>6.755140</td>\n",
       "      <td>6.805826</td>\n",
       "      <td>5.007392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245019</td>\n",
       "      <td>5.809328</td>\n",
       "      <td>6.011681</td>\n",
       "      <td>1.845341</td>\n",
       "      <td>2.246353</td>\n",
       "      <td>5.874268</td>\n",
       "      <td>4.522798</td>\n",
       "      <td>7.161857</td>\n",
       "      <td>1.402145</td>\n",
       "      <td>2.603014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.454713</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>1.374101</td>\n",
       "      <td>7.605061</td>\n",
       "      <td>0.085257</td>\n",
       "      <td>6.004877</td>\n",
       "      <td>2.927638</td>\n",
       "      <td>6.576681</td>\n",
       "      <td>6.576608</td>\n",
       "      <td>4.853169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.292236</td>\n",
       "      <td>6.102261</td>\n",
       "      <td>5.977831</td>\n",
       "      <td>1.746603</td>\n",
       "      <td>2.256940</td>\n",
       "      <td>5.960946</td>\n",
       "      <td>4.544698</td>\n",
       "      <td>7.147408</td>\n",
       "      <td>1.296952</td>\n",
       "      <td>2.719792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.608418</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>1.387649</td>\n",
       "      <td>7.738834</td>\n",
       "      <td>0.090577</td>\n",
       "      <td>6.062274</td>\n",
       "      <td>3.120891</td>\n",
       "      <td>6.641581</td>\n",
       "      <td>6.700318</td>\n",
       "      <td>5.098921</td>\n",
       "      <td>...</td>\n",
       "      <td>1.369653</td>\n",
       "      <td>5.712239</td>\n",
       "      <td>5.895419</td>\n",
       "      <td>1.755864</td>\n",
       "      <td>2.211735</td>\n",
       "      <td>6.076587</td>\n",
       "      <td>4.490592</td>\n",
       "      <td>7.083200</td>\n",
       "      <td>1.273910</td>\n",
       "      <td>2.571661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.634046</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>1.391902</td>\n",
       "      <td>7.749573</td>\n",
       "      <td>0.082269</td>\n",
       "      <td>5.985116</td>\n",
       "      <td>2.725450</td>\n",
       "      <td>6.455650</td>\n",
       "      <td>6.684869</td>\n",
       "      <td>4.931094</td>\n",
       "      <td>...</td>\n",
       "      <td>1.746996</td>\n",
       "      <td>6.040757</td>\n",
       "      <td>6.418585</td>\n",
       "      <td>2.125207</td>\n",
       "      <td>2.657028</td>\n",
       "      <td>6.344469</td>\n",
       "      <td>4.893250</td>\n",
       "      <td>7.514663</td>\n",
       "      <td>1.663441</td>\n",
       "      <td>3.084283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.145507</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>1.136423</td>\n",
       "      <td>7.031901</td>\n",
       "      <td>0.075631</td>\n",
       "      <td>5.243078</td>\n",
       "      <td>1.723283</td>\n",
       "      <td>5.697551</td>\n",
       "      <td>6.002352</td>\n",
       "      <td>4.218275</td>\n",
       "      <td>...</td>\n",
       "      <td>1.732129</td>\n",
       "      <td>6.144797</td>\n",
       "      <td>6.532306</td>\n",
       "      <td>2.274240</td>\n",
       "      <td>2.816232</td>\n",
       "      <td>6.491646</td>\n",
       "      <td>4.957728</td>\n",
       "      <td>7.733036</td>\n",
       "      <td>1.970467</td>\n",
       "      <td>3.263561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.511519</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>1.418056</td>\n",
       "      <td>7.691638</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>6.065864</td>\n",
       "      <td>2.611160</td>\n",
       "      <td>6.576155</td>\n",
       "      <td>6.665757</td>\n",
       "      <td>4.991392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.271601</td>\n",
       "      <td>5.927308</td>\n",
       "      <td>6.110182</td>\n",
       "      <td>1.753562</td>\n",
       "      <td>2.322988</td>\n",
       "      <td>6.039637</td>\n",
       "      <td>4.559003</td>\n",
       "      <td>7.280850</td>\n",
       "      <td>1.541014</td>\n",
       "      <td>2.713312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.638571</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.404413</td>\n",
       "      <td>7.646572</td>\n",
       "      <td>0.099340</td>\n",
       "      <td>5.999320</td>\n",
       "      <td>2.732496</td>\n",
       "      <td>6.574751</td>\n",
       "      <td>6.622676</td>\n",
       "      <td>4.932505</td>\n",
       "      <td>...</td>\n",
       "      <td>1.274324</td>\n",
       "      <td>5.884755</td>\n",
       "      <td>6.040225</td>\n",
       "      <td>1.779293</td>\n",
       "      <td>2.251918</td>\n",
       "      <td>5.952786</td>\n",
       "      <td>4.580960</td>\n",
       "      <td>7.606714</td>\n",
       "      <td>1.466915</td>\n",
       "      <td>2.668125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.589479</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>1.401631</td>\n",
       "      <td>7.754391</td>\n",
       "      <td>0.098794</td>\n",
       "      <td>6.145217</td>\n",
       "      <td>2.854315</td>\n",
       "      <td>6.701745</td>\n",
       "      <td>6.773626</td>\n",
       "      <td>4.985250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.233662</td>\n",
       "      <td>5.813873</td>\n",
       "      <td>5.953893</td>\n",
       "      <td>1.807901</td>\n",
       "      <td>2.218297</td>\n",
       "      <td>5.851734</td>\n",
       "      <td>4.532488</td>\n",
       "      <td>7.137210</td>\n",
       "      <td>1.421615</td>\n",
       "      <td>2.618533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.455512</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>1.364596</td>\n",
       "      <td>7.589417</td>\n",
       "      <td>0.088662</td>\n",
       "      <td>5.989234</td>\n",
       "      <td>2.928596</td>\n",
       "      <td>6.539692</td>\n",
       "      <td>6.555883</td>\n",
       "      <td>4.829197</td>\n",
       "      <td>...</td>\n",
       "      <td>1.283941</td>\n",
       "      <td>6.104760</td>\n",
       "      <td>5.920385</td>\n",
       "      <td>1.728786</td>\n",
       "      <td>2.223454</td>\n",
       "      <td>5.921436</td>\n",
       "      <td>4.552744</td>\n",
       "      <td>7.119736</td>\n",
       "      <td>1.314351</td>\n",
       "      <td>2.703774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "store_nbr         1                                                    \\\n",
       "family           0         1         2         3         4         5    \n",
       "0          1.544311  0.000174  1.354694  7.675069  0.187262  6.038983   \n",
       "1          1.541989  0.000068  1.373708  7.704771  0.253827  6.059268   \n",
       "2          1.607664  0.000374  1.397774  7.779405  0.216840  6.063324   \n",
       "3          1.630347  0.001112  1.401060  7.748850  0.144777  5.976876   \n",
       "4          1.128470  0.001172  1.136662  7.042006  0.088563  5.227509   \n",
       "5          1.510883  0.000373  1.429281  7.708746  0.090520  6.078387   \n",
       "6          1.640509  0.000251  1.412816  7.663773  0.100966  6.010575   \n",
       "7          1.617059 -0.000062  1.408826  7.778501  0.105265  6.166919   \n",
       "8          1.454713 -0.000052  1.374101  7.605061  0.085257  6.004877   \n",
       "9          1.608418  0.000211  1.387649  7.738834  0.090577  6.062274   \n",
       "10         1.634046  0.001034  1.391902  7.749573  0.082269  5.985116   \n",
       "11         1.145507  0.001064  1.136423  7.031901  0.075631  5.243078   \n",
       "12         1.511519  0.000181  1.418056  7.691638  0.091241  6.065864   \n",
       "13         1.638571  0.000054  1.404413  7.646572  0.099340  5.999320   \n",
       "14         1.589479 -0.000173  1.401631  7.754391  0.098794  6.145217   \n",
       "15         1.455512 -0.000162  1.364596  7.589417  0.088662  5.989234   \n",
       "\n",
       "store_nbr                                          ...         9            \\\n",
       "family           6         7         8         9   ...        23        24   \n",
       "0          2.800738  6.613937  6.656946  4.957291  ...  1.279410  5.889663   \n",
       "1          2.935014  6.644652  6.659185  4.955846  ...  1.298907  5.938157   \n",
       "2          3.088867  6.633666  6.719116  5.111925  ...  1.441533  5.749404   \n",
       "3          2.707307  6.459964  6.675728  4.921675  ...  1.757240  6.066064   \n",
       "4          1.766250  5.750853  6.008966  4.212395  ...  1.804818  6.192298   \n",
       "5          2.615857  6.621103  6.682580  5.004357  ...  1.317408  5.968786   \n",
       "6          2.727686  6.624913  6.645810  4.943985  ...  1.317631  5.904322   \n",
       "7          2.858568  6.755140  6.805826  5.007392  ...  1.245019  5.809328   \n",
       "8          2.927638  6.576681  6.576608  4.853169  ...  1.292236  6.102261   \n",
       "9          3.120891  6.641581  6.700318  5.098921  ...  1.369653  5.712239   \n",
       "10         2.725450  6.455650  6.684869  4.931094  ...  1.746996  6.040757   \n",
       "11         1.723283  5.697551  6.002352  4.218275  ...  1.732129  6.144797   \n",
       "12         2.611160  6.576155  6.665757  4.991392  ...  1.271601  5.927308   \n",
       "13         2.732496  6.574751  6.622676  4.932505  ...  1.274324  5.884755   \n",
       "14         2.854315  6.701745  6.773626  4.985250  ...  1.233662  5.813873   \n",
       "15         2.928596  6.539692  6.555883  4.829197  ...  1.283941  6.104760   \n",
       "\n",
       "store_nbr                                                              \\\n",
       "family           25        26        27        28        29        30   \n",
       "0          6.053737  1.770713  2.292630  6.050762  4.519764  7.214887   \n",
       "1          5.998296  1.764273  2.233401  5.990381  4.515714  7.161172   \n",
       "2          5.958526  1.777012  2.273731  6.111696  4.538804  7.151239   \n",
       "3          6.473705  2.149848  2.700736  6.377760  4.914499  7.541142   \n",
       "4          6.627496  2.321419  2.887187  6.534098  4.966452  7.777387   \n",
       "5          6.214417  1.804887  2.396450  6.096796  4.576283  7.335397   \n",
       "6          6.143366  1.838949  2.322069  6.006927  4.591448  7.653942   \n",
       "7          6.011681  1.845341  2.246353  5.874268  4.522798  7.161857   \n",
       "8          5.977831  1.746603  2.256940  5.960946  4.544698  7.147408   \n",
       "9          5.895419  1.755864  2.211735  6.076587  4.490592  7.083200   \n",
       "10         6.418585  2.125207  2.657028  6.344469  4.893250  7.514663   \n",
       "11         6.532306  2.274240  2.816232  6.491646  4.957728  7.733036   \n",
       "12         6.110182  1.753562  2.322988  6.039637  4.559003  7.280850   \n",
       "13         6.040225  1.779293  2.251918  5.952786  4.580960  7.606714   \n",
       "14         5.953893  1.807901  2.218297  5.851734  4.532488  7.137210   \n",
       "15         5.920385  1.728786  2.223454  5.921436  4.552744  7.119736   \n",
       "\n",
       "store_nbr                      \n",
       "family           31        32  \n",
       "0          1.500727  2.728755  \n",
       "1          1.328181  2.724252  \n",
       "2          1.291718  2.626842  \n",
       "3          1.627911  3.103156  \n",
       "4          1.873662  3.276714  \n",
       "5          1.512545  2.744983  \n",
       "6          1.436067  2.685885  \n",
       "7          1.402145  2.603014  \n",
       "8          1.296952  2.719792  \n",
       "9          1.273910  2.571661  \n",
       "10         1.663441  3.084283  \n",
       "11         1.970467  3.263561  \n",
       "12         1.541014  2.713312  \n",
       "13         1.466915  2.668125  \n",
       "14         1.421615  2.618533  \n",
       "15         1.314351  2.703774  \n",
       "\n",
       "[16 rows x 1782 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3008016</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008017</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008018</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008019</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008020</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036523</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036524</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036525</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036526</th>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036527</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         store_nbr  family        date\n",
       "3008016          1       0  2017-08-16\n",
       "3008017          1       1  2017-08-16\n",
       "3008018          1       2  2017-08-16\n",
       "3008019          1       3  2017-08-16\n",
       "3008020          1       4  2017-08-16\n",
       "...            ...     ...         ...\n",
       "3036523          9      28  2017-08-31\n",
       "3036524          9      29  2017-08-31\n",
       "3036525          9      30  2017-08-31\n",
       "3036526          9      31  2017-08-31\n",
       "3036527          9      32  2017-08-31\n",
       "\n",
       "[28512 rows x 3 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_filtered = X_test[[\"store_nbr\", \"family\", \"date\"]]\n",
    "X_test_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3008016</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008017</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008018</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008019</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008020</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036523</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036524</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036525</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036526</th>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036527</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         store_nbr  family        date\n",
       "3008016          1       0  2017-08-16\n",
       "3008017          1       1  2017-08-16\n",
       "3008018          1       2  2017-08-16\n",
       "3008019          1       3  2017-08-16\n",
       "3008020          1       4  2017-08-16\n",
       "...            ...     ...         ...\n",
       "3036523          9      28  2017-08-31\n",
       "3036524          9      29  2017-08-31\n",
       "3036525          9      30  2017-08-31\n",
       "3036526          9      31  2017-08-31\n",
       "3036527          9      32  2017-08-31\n",
       "\n",
       "[28512 rows x 3 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in y_predict.iterrows():\n",
    "    #print(row)\n",
    "    (X_test_pivoted.iloc[index]) = (y_predict.iloc[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sales                                      ...                      \\\n",
       "store_nbr      1                                      ...   9                   \n",
       "family        0   1   2   3   4   5   6   7   8   9   ...  23  24  25  26  27   \n",
       "date                                                  ...                       \n",
       "2017-08-16   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-17   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-18   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-19   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-20   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-21   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-22   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-23   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-24   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-25   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-26   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-27   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-28   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-29   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-30   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "2017-08-31   NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN NaN   \n",
       "\n",
       "                                \n",
       "store_nbr                       \n",
       "family      28  29  30  31  32  \n",
       "date                            \n",
       "2017-08-16 NaN NaN NaN NaN NaN  \n",
       "2017-08-17 NaN NaN NaN NaN NaN  \n",
       "2017-08-18 NaN NaN NaN NaN NaN  \n",
       "2017-08-19 NaN NaN NaN NaN NaN  \n",
       "2017-08-20 NaN NaN NaN NaN NaN  \n",
       "2017-08-21 NaN NaN NaN NaN NaN  \n",
       "2017-08-22 NaN NaN NaN NaN NaN  \n",
       "2017-08-23 NaN NaN NaN NaN NaN  \n",
       "2017-08-24 NaN NaN NaN NaN NaN  \n",
       "2017-08-25 NaN NaN NaN NaN NaN  \n",
       "2017-08-26 NaN NaN NaN NaN NaN  \n",
       "2017-08-27 NaN NaN NaN NaN NaN  \n",
       "2017-08-28 NaN NaN NaN NaN NaN  \n",
       "2017-08-29 NaN NaN NaN NaN NaN  \n",
       "2017-08-30 NaN NaN NaN NaN NaN  \n",
       "2017-08-31 NaN NaN NaN NaN NaN  \n",
       "\n",
       "[16 rows x 1782 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_filtered.pivot(index=['date'], columns=['store_nbr', 'family'], values=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1.544311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>1.541989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>1.607664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>1.630347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>1.128470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>3.263561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>2.713312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>2.668125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>2.618533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>2.703774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store_nbr  family        date     sales\n",
       "0              1       0  2017-08-16  1.544311\n",
       "1              1       0  2017-08-17  1.541989\n",
       "2              1       0  2017-08-18  1.607664\n",
       "3              1       0  2017-08-19  1.630347\n",
       "4              1       0  2017-08-20  1.128470\n",
       "...          ...     ...         ...       ...\n",
       "28507          9      32  2017-08-27  3.263561\n",
       "28508          9      32  2017-08-28  2.713312\n",
       "28509          9      32  2017-08-29  2.668125\n",
       "28510          9      32  2017-08-30  2.618533\n",
       "28511          9      32  2017-08-31  2.703774\n",
       "\n",
       "[28512 rows x 4 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pivoted.unstack().reset_index(name='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(X_test_filtered, X_test_pivoted.unstack().reset_index(name='sales'), how='outer', on=['store_nbr', 'family', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1.544311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1.354694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>7.675069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>0.187262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>5.921436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>4.552744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>7.119736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>1.314351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>2.703774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store_nbr  family        date     sales\n",
       "0              1       0  2017-08-16  1.544311\n",
       "1              1       1  2017-08-16  0.000174\n",
       "2              1       2  2017-08-16  1.354694\n",
       "3              1       3  2017-08-16  7.675069\n",
       "4              1       4  2017-08-16  0.187262\n",
       "...          ...     ...         ...       ...\n",
       "28507          9      28  2017-08-31  5.921436\n",
       "28508          9      29  2017-08-31  4.552744\n",
       "28509          9      30  2017-08-31  7.119736\n",
       "28510          9      31  2017-08-31  1.314351\n",
       "28511          9      32  2017-08-31  2.703774\n",
       "\n",
       "[28512 rows x 4 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1.544311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1.354694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>7.675069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>0.187262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>5.921436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>4.552744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>7.119736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>1.314351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>2.703774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store_nbr  family        date     sales\n",
       "index                                         \n",
       "0              1       0  2017-08-16  1.544311\n",
       "1              1       1  2017-08-16  0.000174\n",
       "2              1       2  2017-08-16  1.354694\n",
       "3              1       3  2017-08-16  7.675069\n",
       "4              1       4  2017-08-16  0.187262\n",
       "...          ...     ...         ...       ...\n",
       "28507          9      28  2017-08-31  5.921436\n",
       "28508          9      29  2017-08-31  4.552744\n",
       "28509          9      30  2017-08-31  7.119736\n",
       "28510          9      31  2017-08-31  1.314351\n",
       "28511          9      32  2017-08-31  2.703774\n",
       "\n",
       "[28512 rows x 4 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.reset_index().merge(X_test_filtered, how=\"left\").set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/cjnnn8695qx8mqcc36hww0y80000gp/T/ipykernel_28079/3451258969.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_filtered['id'] = X_test_filtered.index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3008016</td>\n",
       "      <td>1.544311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3008017</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3008018</td>\n",
       "      <td>1.354694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3008019</td>\n",
       "      <td>7.675069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3008020</td>\n",
       "      <td>0.187262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>3036523</td>\n",
       "      <td>5.921436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>3036524</td>\n",
       "      <td>4.552744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>3036525</td>\n",
       "      <td>7.119736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>3036526</td>\n",
       "      <td>1.314351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>3036527</td>\n",
       "      <td>2.703774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     sales\n",
       "0      3008016  1.544311\n",
       "1      3008017  0.000174\n",
       "2      3008018  1.354694\n",
       "3      3008019  7.675069\n",
       "4      3008020  0.187262\n",
       "...        ...       ...\n",
       "28507  3036523  5.921436\n",
       "28508  3036524  4.552744\n",
       "28509  3036525  7.119736\n",
       "28510  3036526  1.314351\n",
       "28511  3036527  2.703774\n",
       "\n",
       "[28512 rows x 2 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_filtered['id'] = X_test_filtered.index\n",
    "submission = X_test_filtered.merge(result, how='left')[['id', 'sales']]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
