{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-20T21:42:39.19589Z",
     "iopub.status.busy": "2022-11-20T21:42:39.195291Z",
     "iopub.status.idle": "2022-11-20T21:42:41.191513Z",
     "shell.execute_reply": "2022-11-20T21:42:41.190364Z",
     "shell.execute_reply.started": "2022-11-20T21:42:39.195769Z"
    },
    "id": "wIgQxMc3H0qU"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import xgboost\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from xgboost import XGBRegressor\n",
    "#import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv = pd.read_csv('/Users/spartan/Downloads/store-sales-forecasting-main/cleaned.csv',\n",
    "                 dtype = {\n",
    "                     'store_nbr' : 'category',\n",
    "                     'family' : 'category',\n",
    "                     'sales': 'float',\n",
    "                     'city': 'category',\n",
    "                     'state': 'category',\n",
    "                     'type': 'category',\n",
    "                     'holiday_type': 'category',\n",
    "                     'holiday_transferred': 'category'\n",
    "                 },\n",
    "                  parse_dates=['date'])\n",
    "all_csv['date'] = pd.to_datetime(all_csv['date']).dt.to_period('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = all_csv.copy()  # we can start experimenting from here without reloading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for experimentation\n",
    "\n",
    "filter_by_stores = None  # note: please use string here (unlike Mine.ipynb)\n",
    "filter_by_family = None\n",
    "filter_by_dates = None\n",
    "\n",
    "#filter_by_stores = ['1', '2']  # note: please use string here (unlike Mine.ipynb)\n",
    "#filter_by_family = ['DAIRY', 'PRODUCE']\n",
    "#filter_by_family = ['']\n",
    "#filter_by_dates = '2014-06-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_by_dates == None:\n",
    "    train_start_date = '2013-01-01'\n",
    "else:\n",
    "    train_start_date = filter_by_dates\n",
    "train_end_date = '2017-08-15'\n",
    "test_start_date = '2017-08-16'\n",
    "test_end_date = '2017-08-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_by_family != None:\n",
    "    all = all[all['family'].isin(filter_by_family)]\n",
    "if filter_by_stores != None:\n",
    "    all = all[all['store_nbr'].isin(filter_by_stores)]\n",
    "if filter_by_dates != None:\n",
    "    all = all[all['date'] >= filter_by_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3036528 entries, 0 to 3036527\n",
      "Data columns (total 38 columns):\n",
      " #   Column               Dtype    \n",
      "---  ------               -----    \n",
      " 0   date                 period[D]\n",
      " 1   store_nbr            category \n",
      " 2   family               category \n",
      " 3   sales                float64  \n",
      " 4   onpromotion          int64    \n",
      " 5   sales_lag_01         float64  \n",
      " 6   sales_lag_02         float64  \n",
      " 7   sales_lag_03         float64  \n",
      " 8   sales_lag_04         float64  \n",
      " 9   sales_lag_05         float64  \n",
      " 10  sales_lag_06         float64  \n",
      " 11  sales_lag_07         float64  \n",
      " 12  sales_lag_08         float64  \n",
      " 13  sales_lag_09         float64  \n",
      " 14  sales_lag_10         float64  \n",
      " 15  sales_lag_11         float64  \n",
      " 16  sales_lag_12         float64  \n",
      " 17  sales_lag_13         float64  \n",
      " 18  sales_lag_14         float64  \n",
      " 19  sales_lag_15         float64  \n",
      " 20  sales_lag_16         float64  \n",
      " 21  sales_lag_17         float64  \n",
      " 22  sales_lag_18         float64  \n",
      " 23  sales_lag_19         float64  \n",
      " 24  sales_lag_20         float64  \n",
      " 25  city                 category \n",
      " 26  state                category \n",
      " 27  type                 category \n",
      " 28  cluster              int64    \n",
      " 29  month                int64    \n",
      " 30  day_of_month         int64    \n",
      " 31  day_of_year          int64    \n",
      " 32  week_of_year         int64    \n",
      " 33  day_of_week          int64    \n",
      " 34  weekday              int64    \n",
      " 35  year                 int64    \n",
      " 36  holiday_type         category \n",
      " 37  holiday_transferred  category \n",
      "dtypes: category(7), float64(21), int64(9), period[D](1)\n",
      "memory usage: 738.4 MB\n"
     ]
    }
   ],
   "source": [
    "all.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    return pd.get_dummies(data=df, columns=['store_nbr', 'family', 'city', 'state', 'type',\n",
    "                                     'cluster', 'holiday_type', 'holiday_transferred', 'weekday'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ohe = one_hot_encode(all)\n",
    "all_ohe = all_ohe.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))  # remove bad char in column names\n",
    "\n",
    "X = all_ohe[all_ohe['date'] <= train_end_date]\n",
    "X = X.drop(['sales'], axis=1)\n",
    "y = all_ohe[['date', 'sales']][all_ohe['date'] <= train_end_date]\n",
    "y.set_index('date', inplace=True)\n",
    "\n",
    "X_test = all_ohe[all_ohe['date'] >= test_start_date]\n",
    "X_test = X_test.drop(['sales'], axis=1)\n",
    "\n",
    "X.drop('date', axis=1, inplace=True)\n",
    "X_test.drop('date', axis=1, inplace=True)\n",
    "y.set_index(X.index, inplace=True)\n",
    "X.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sales'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=150)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents)\n",
    "principalDf['day_of_month'] = X['day_of_month']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(principalDf, y, random_state=1)\n",
    "\n",
    "X_train.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    75168\n",
       "9     75086\n",
       "1     75066\n",
       "4     74974\n",
       "2     74918\n",
       "12    74911\n",
       "15    74897\n",
       "14    74871\n",
       "5     74800\n",
       "6     74797\n",
       "11    74751\n",
       "13    74742\n",
       "7     74741\n",
       "8     74692\n",
       "3     74568\n",
       "28    73704\n",
       "23    73683\n",
       "27    73622\n",
       "18    73562\n",
       "21    73537\n",
       "25    73511\n",
       "20    73484\n",
       "16    73483\n",
       "17    73480\n",
       "24    73416\n",
       "19    73375\n",
       "22    73344\n",
       "26    73330\n",
       "29    68216\n",
       "30    66654\n",
       "31    42629\n",
       "Name: day_of_month, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['day_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1198478</th>\n",
       "      <td>135.592885</td>\n",
       "      <td>-10.015295</td>\n",
       "      <td>9.476951</td>\n",
       "      <td>-12.823888</td>\n",
       "      <td>0.368836</td>\n",
       "      <td>-2.006899</td>\n",
       "      <td>0.562564</td>\n",
       "      <td>-0.628737</td>\n",
       "      <td>0.440030</td>\n",
       "      <td>0.235081</td>\n",
       "      <td>...</td>\n",
       "      <td>2.228957e-15</td>\n",
       "      <td>1.951890e-15</td>\n",
       "      <td>-2.742138e-16</td>\n",
       "      <td>-2.492552e-15</td>\n",
       "      <td>-2.823452e-15</td>\n",
       "      <td>-9.586653e-16</td>\n",
       "      <td>1.979330e-15</td>\n",
       "      <td>2.563934e-15</td>\n",
       "      <td>3.444848e-16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649869</th>\n",
       "      <td>22.473936</td>\n",
       "      <td>-10.872151</td>\n",
       "      <td>11.456803</td>\n",
       "      <td>-0.950868</td>\n",
       "      <td>0.576632</td>\n",
       "      <td>-1.009578</td>\n",
       "      <td>-0.212883</td>\n",
       "      <td>-0.417954</td>\n",
       "      <td>-0.087567</td>\n",
       "      <td>0.109136</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.592875e-15</td>\n",
       "      <td>-1.753002e-16</td>\n",
       "      <td>2.749658e-15</td>\n",
       "      <td>-2.194168e-15</td>\n",
       "      <td>-1.735113e-15</td>\n",
       "      <td>-1.730487e-15</td>\n",
       "      <td>-4.728794e-16</td>\n",
       "      <td>-1.937153e-16</td>\n",
       "      <td>-2.614478e-15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615038</th>\n",
       "      <td>173.993823</td>\n",
       "      <td>-10.728431</td>\n",
       "      <td>10.330419</td>\n",
       "      <td>-5.115483</td>\n",
       "      <td>0.563089</td>\n",
       "      <td>-0.080648</td>\n",
       "      <td>1.486487</td>\n",
       "      <td>-0.632651</td>\n",
       "      <td>0.230683</td>\n",
       "      <td>-0.164606</td>\n",
       "      <td>...</td>\n",
       "      <td>3.850906e-16</td>\n",
       "      <td>1.311421e-15</td>\n",
       "      <td>-1.756780e-15</td>\n",
       "      <td>3.039522e-15</td>\n",
       "      <td>-4.633274e-15</td>\n",
       "      <td>-2.168064e-15</td>\n",
       "      <td>-2.377412e-15</td>\n",
       "      <td>-1.970937e-15</td>\n",
       "      <td>5.396037e-15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413595</th>\n",
       "      <td>59.866926</td>\n",
       "      <td>-5.603041</td>\n",
       "      <td>3.334956</td>\n",
       "      <td>4.827683</td>\n",
       "      <td>0.759999</td>\n",
       "      <td>-1.136873</td>\n",
       "      <td>1.687880</td>\n",
       "      <td>-0.567452</td>\n",
       "      <td>-0.646616</td>\n",
       "      <td>0.557999</td>\n",
       "      <td>...</td>\n",
       "      <td>4.529140e-15</td>\n",
       "      <td>1.168374e-16</td>\n",
       "      <td>-2.746171e-16</td>\n",
       "      <td>-2.022751e-15</td>\n",
       "      <td>-3.501123e-16</td>\n",
       "      <td>-9.687222e-16</td>\n",
       "      <td>3.653849e-17</td>\n",
       "      <td>2.310413e-15</td>\n",
       "      <td>4.911112e-15</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398041</th>\n",
       "      <td>-119.955189</td>\n",
       "      <td>-3.461478</td>\n",
       "      <td>1.191805</td>\n",
       "      <td>9.243761</td>\n",
       "      <td>0.662329</td>\n",
       "      <td>-2.068293</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>-1.034461</td>\n",
       "      <td>-0.144230</td>\n",
       "      <td>-0.706314</td>\n",
       "      <td>...</td>\n",
       "      <td>3.281796e-15</td>\n",
       "      <td>3.159497e-16</td>\n",
       "      <td>4.916253e-16</td>\n",
       "      <td>-1.413712e-15</td>\n",
       "      <td>-5.601481e-17</td>\n",
       "      <td>-1.276532e-15</td>\n",
       "      <td>-1.228001e-15</td>\n",
       "      <td>1.035787e-15</td>\n",
       "      <td>1.365768e-15</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1          2          3         4         5  \\\n",
       "1198478  135.592885 -10.015295   9.476951 -12.823888  0.368836 -2.006899   \n",
       "1649869   22.473936 -10.872151  11.456803  -0.950868  0.576632 -1.009578   \n",
       "615038   173.993823 -10.728431  10.330419  -5.115483  0.563089 -0.080648   \n",
       "413595    59.866926  -5.603041   3.334956   4.827683  0.759999 -1.136873   \n",
       "1398041 -119.955189  -3.461478   1.191805   9.243761  0.662329 -2.068293   \n",
       "\n",
       "                6         7         8         9  ...           141  \\\n",
       "1198478  0.562564 -0.628737  0.440030  0.235081  ...  2.228957e-15   \n",
       "1649869 -0.212883 -0.417954 -0.087567  0.109136  ... -2.592875e-15   \n",
       "615038   1.486487 -0.632651  0.230683 -0.164606  ...  3.850906e-16   \n",
       "413595   1.687880 -0.567452 -0.646616  0.557999  ...  4.529140e-15   \n",
       "1398041  0.012483 -1.034461 -0.144230 -0.706314  ...  3.281796e-15   \n",
       "\n",
       "                  142           143           144           145           146  \\\n",
       "1198478  1.951890e-15 -2.742138e-16 -2.492552e-15 -2.823452e-15 -9.586653e-16   \n",
       "1649869 -1.753002e-16  2.749658e-15 -2.194168e-15 -1.735113e-15 -1.730487e-15   \n",
       "615038   1.311421e-15 -1.756780e-15  3.039522e-15 -4.633274e-15 -2.168064e-15   \n",
       "413595   1.168374e-16 -2.746171e-16 -2.022751e-15 -3.501123e-16 -9.687222e-16   \n",
       "1398041  3.159497e-16  4.916253e-16 -1.413712e-15 -5.601481e-17 -1.276532e-15   \n",
       "\n",
       "                  147           148           149  day_of_month  \n",
       "1198478  1.979330e-15  2.563934e-15  3.444848e-16             4  \n",
       "1649869 -4.728794e-16 -1.937153e-16 -2.614478e-15            15  \n",
       "615038  -2.377412e-15 -1.970937e-15  5.396037e-15            12  \n",
       "413595   3.653849e-17  2.310413e-15  4.911112e-15            21  \n",
       "1398041 -1.228001e-15  1.035787e-15  1.365768e-15            24  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_month = X_test['day_of_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3008016    16\n",
       "3008017    16\n",
       "3008018    16\n",
       "3008019    16\n",
       "3008020    16\n",
       "Name: day_of_month, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_of_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onpromotion         0\n",
       "sales_lag_01    26730\n",
       "sales_lag_02    24948\n",
       "sales_lag_03    23166\n",
       "sales_lag_04    21384\n",
       "                ...  \n",
       "weekday_2           0\n",
       "weekday_3           0\n",
       "weekday_4           0\n",
       "weekday_5           0\n",
       "weekday_6           0\n",
       "Length: 190, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5417280"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onpromotion     0\n",
       "sales_lag_01    0\n",
       "sales_lag_02    0\n",
       "sales_lag_03    0\n",
       "sales_lag_04    0\n",
       "               ..\n",
       "weekday_2       0\n",
       "weekday_3       0\n",
       "weekday_4       0\n",
       "weekday_5       0\n",
       "weekday_6       0\n",
       "Length: 190, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000095"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales_lag_01</th>\n",
       "      <th>sales_lag_02</th>\n",
       "      <th>sales_lag_03</th>\n",
       "      <th>sales_lag_04</th>\n",
       "      <th>sales_lag_05</th>\n",
       "      <th>sales_lag_06</th>\n",
       "      <th>sales_lag_07</th>\n",
       "      <th>sales_lag_08</th>\n",
       "      <th>sales_lag_09</th>\n",
       "      <th>...</th>\n",
       "      <th>holiday_type_Bridge</th>\n",
       "      <th>holiday_transferred_False</th>\n",
       "      <th>holiday_transferred_True</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3008016</th>\n",
       "      <td>0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008017</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008018</th>\n",
       "      <td>2</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008019</th>\n",
       "      <td>20</td>\n",
       "      <td>7.571988</td>\n",
       "      <td>7.697121</td>\n",
       "      <td>6.689599</td>\n",
       "      <td>7.414573</td>\n",
       "      <td>6.914731</td>\n",
       "      <td>7.774015</td>\n",
       "      <td>7.745868</td>\n",
       "      <td>7.791110</td>\n",
       "      <td>7.643483</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008020</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         onpromotion  sales_lag_01  sales_lag_02  sales_lag_03  sales_lag_04  \\\n",
       "3008016            0      1.609438      0.693147      0.693147      1.945910   \n",
       "3008017            0      0.000000      0.000000      0.000000      0.000000   \n",
       "3008018            2      1.609438      1.945910      0.693147      1.386294   \n",
       "3008019           20      7.571988      7.697121      6.689599      7.414573   \n",
       "3008020            0      0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "         sales_lag_05  sales_lag_06  sales_lag_07  sales_lag_08  sales_lag_09  \\\n",
       "3008016      0.693147      2.302585      2.079442      1.609438      2.079442   \n",
       "3008017      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "3008018      0.693147      2.397895      1.609438      1.098612      1.791759   \n",
       "3008019      6.914731      7.774015      7.745868      7.791110      7.643483   \n",
       "3008020      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "         ...  holiday_type_Bridge  holiday_transferred_False  \\\n",
       "3008016  ...                    0                          0   \n",
       "3008017  ...                    0                          0   \n",
       "3008018  ...                    0                          0   \n",
       "3008019  ...                    0                          0   \n",
       "3008020  ...                    0                          0   \n",
       "\n",
       "         holiday_transferred_True  weekday_0  weekday_1  weekday_2  weekday_3  \\\n",
       "3008016                         0          0          0          1          0   \n",
       "3008017                         0          0          0          1          0   \n",
       "3008018                         0          0          0          1          0   \n",
       "3008019                         0          0          0          1          0   \n",
       "3008020                         0          0          0          1          0   \n",
       "\n",
       "         weekday_4  weekday_5  weekday_6  \n",
       "3008016          0          0          0  \n",
       "3008017          0          0          0  \n",
       "3008018          0          0          0  \n",
       "3008019          0          0          0  \n",
       "3008020          0          0          0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.735016</td>\n",
       "      <td>-6.821420</td>\n",
       "      <td>5.321452</td>\n",
       "      <td>-0.121539</td>\n",
       "      <td>0.187416</td>\n",
       "      <td>-0.897372</td>\n",
       "      <td>-2.291834</td>\n",
       "      <td>1.178392</td>\n",
       "      <td>-0.646932</td>\n",
       "      <td>-0.396290</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179612e-15</td>\n",
       "      <td>7.060325e-16</td>\n",
       "      <td>-8.595555e-16</td>\n",
       "      <td>-7.627362e-16</td>\n",
       "      <td>-1.020017e-15</td>\n",
       "      <td>7.615436e-16</td>\n",
       "      <td>-1.099381e-15</td>\n",
       "      <td>1.465841e-15</td>\n",
       "      <td>4.753142e-16</td>\n",
       "      <td>5.204170e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.738457</td>\n",
       "      <td>-10.901443</td>\n",
       "      <td>11.417594</td>\n",
       "      <td>-0.174549</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>-1.004832</td>\n",
       "      <td>-2.272362</td>\n",
       "      <td>1.291243</td>\n",
       "      <td>-0.184776</td>\n",
       "      <td>0.090314</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.359224e-16</td>\n",
       "      <td>1.025222e-15</td>\n",
       "      <td>-8.317999e-16</td>\n",
       "      <td>-1.104802e-16</td>\n",
       "      <td>-5.620504e-16</td>\n",
       "      <td>1.066855e-15</td>\n",
       "      <td>-4.466913e-17</td>\n",
       "      <td>7.441964e-16</td>\n",
       "      <td>2.255141e-16</td>\n",
       "      <td>3.382711e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.741884</td>\n",
       "      <td>-5.762823</td>\n",
       "      <td>7.334577</td>\n",
       "      <td>-0.143222</td>\n",
       "      <td>0.198285</td>\n",
       "      <td>-0.977237</td>\n",
       "      <td>-2.248057</td>\n",
       "      <td>1.234142</td>\n",
       "      <td>0.227470</td>\n",
       "      <td>-0.067357</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.800116e-16</td>\n",
       "      <td>1.344411e-15</td>\n",
       "      <td>-8.040443e-16</td>\n",
       "      <td>9.768662e-17</td>\n",
       "      <td>-7.424616e-16</td>\n",
       "      <td>6.782769e-16</td>\n",
       "      <td>9.410875e-17</td>\n",
       "      <td>8.829742e-16</td>\n",
       "      <td>7.251144e-16</td>\n",
       "      <td>3.660267e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.783501</td>\n",
       "      <td>24.485242</td>\n",
       "      <td>-5.499398</td>\n",
       "      <td>-0.015502</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>-0.890922</td>\n",
       "      <td>-1.898497</td>\n",
       "      <td>0.905668</td>\n",
       "      <td>-0.373819</td>\n",
       "      <td>-0.738310</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.187895e-16</td>\n",
       "      <td>1.191755e-15</td>\n",
       "      <td>-9.705778e-16</td>\n",
       "      <td>-2.631359e-16</td>\n",
       "      <td>4.857226e-17</td>\n",
       "      <td>1.344411e-15</td>\n",
       "      <td>-3.777360e-16</td>\n",
       "      <td>4.388850e-16</td>\n",
       "      <td>1.307982e-15</td>\n",
       "      <td>-3.139849e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.738325</td>\n",
       "      <td>-10.815425</td>\n",
       "      <td>11.288670</td>\n",
       "      <td>-0.172892</td>\n",
       "      <td>0.199916</td>\n",
       "      <td>-1.038345</td>\n",
       "      <td>-2.272757</td>\n",
       "      <td>1.286362</td>\n",
       "      <td>-0.228206</td>\n",
       "      <td>-0.121589</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.747003e-16</td>\n",
       "      <td>9.558326e-16</td>\n",
       "      <td>-3.044440e-16</td>\n",
       "      <td>-1.243580e-16</td>\n",
       "      <td>-2.151057e-16</td>\n",
       "      <td>9.003215e-16</td>\n",
       "      <td>-4.054916e-16</td>\n",
       "      <td>9.384854e-16</td>\n",
       "      <td>1.144917e-16</td>\n",
       "      <td>5.204170e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2         3         4         5         6    \\\n",
       "0  54.735016  -6.821420   5.321452 -0.121539  0.187416 -0.897372 -2.291834   \n",
       "1  54.738457 -10.901443  11.417594 -0.174549  0.200042 -1.004832 -2.272362   \n",
       "2  54.741884  -5.762823   7.334577 -0.143222  0.198285 -0.977237 -2.248057   \n",
       "3  54.783501  24.485242  -5.499398 -0.015502  0.232918 -0.890922 -1.898497   \n",
       "4  54.738325 -10.815425  11.288670 -0.172892  0.199916 -1.038345 -2.272757   \n",
       "\n",
       "        7         8         9    ...           140           141  \\\n",
       "0  1.178392 -0.646932 -0.396290  ... -1.179612e-15  7.060325e-16   \n",
       "1  1.291243 -0.184776  0.090314  ... -2.359224e-16  1.025222e-15   \n",
       "2  1.234142  0.227470 -0.067357  ... -6.800116e-16  1.344411e-15   \n",
       "3  0.905668 -0.373819 -0.738310  ... -8.187895e-16  1.191755e-15   \n",
       "4  1.286362 -0.228206 -0.121589  ... -3.747003e-16  9.558326e-16   \n",
       "\n",
       "            142           143           144           145           146  \\\n",
       "0 -8.595555e-16 -7.627362e-16 -1.020017e-15  7.615436e-16 -1.099381e-15   \n",
       "1 -8.317999e-16 -1.104802e-16 -5.620504e-16  1.066855e-15 -4.466913e-17   \n",
       "2 -8.040443e-16  9.768662e-17 -7.424616e-16  6.782769e-16  9.410875e-17   \n",
       "3 -9.705778e-16 -2.631359e-16  4.857226e-17  1.344411e-15 -3.777360e-16   \n",
       "4 -3.044440e-16 -1.243580e-16 -2.151057e-16  9.003215e-16 -4.054916e-16   \n",
       "\n",
       "            147           148           149  \n",
       "0  1.465841e-15  4.753142e-16  5.204170e-18  \n",
       "1  7.441964e-16  2.255141e-16  3.382711e-16  \n",
       "2  8.829742e-16  7.251144e-16  3.660267e-16  \n",
       "3  4.388850e-16  1.307982e-15 -3.139849e-16  \n",
       "4  9.384854e-16  1.144917e-16  5.204170e-18  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['day_of_month'] = day_of_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_of_month.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28512"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['day_of_month'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.735016</td>\n",
       "      <td>-6.821420</td>\n",
       "      <td>5.321452</td>\n",
       "      <td>-0.121539</td>\n",
       "      <td>0.187416</td>\n",
       "      <td>-0.897372</td>\n",
       "      <td>-2.291834</td>\n",
       "      <td>1.178392</td>\n",
       "      <td>-0.646932</td>\n",
       "      <td>-0.396290</td>\n",
       "      <td>...</td>\n",
       "      <td>7.060325e-16</td>\n",
       "      <td>-8.595555e-16</td>\n",
       "      <td>-7.627362e-16</td>\n",
       "      <td>-1.020017e-15</td>\n",
       "      <td>7.615436e-16</td>\n",
       "      <td>-1.099381e-15</td>\n",
       "      <td>1.465841e-15</td>\n",
       "      <td>4.753142e-16</td>\n",
       "      <td>5.204170e-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.738457</td>\n",
       "      <td>-10.901443</td>\n",
       "      <td>11.417594</td>\n",
       "      <td>-0.174549</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>-1.004832</td>\n",
       "      <td>-2.272362</td>\n",
       "      <td>1.291243</td>\n",
       "      <td>-0.184776</td>\n",
       "      <td>0.090314</td>\n",
       "      <td>...</td>\n",
       "      <td>1.025222e-15</td>\n",
       "      <td>-8.317999e-16</td>\n",
       "      <td>-1.104802e-16</td>\n",
       "      <td>-5.620504e-16</td>\n",
       "      <td>1.066855e-15</td>\n",
       "      <td>-4.466913e-17</td>\n",
       "      <td>7.441964e-16</td>\n",
       "      <td>2.255141e-16</td>\n",
       "      <td>3.382711e-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.741884</td>\n",
       "      <td>-5.762823</td>\n",
       "      <td>7.334577</td>\n",
       "      <td>-0.143222</td>\n",
       "      <td>0.198285</td>\n",
       "      <td>-0.977237</td>\n",
       "      <td>-2.248057</td>\n",
       "      <td>1.234142</td>\n",
       "      <td>0.227470</td>\n",
       "      <td>-0.067357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.344411e-15</td>\n",
       "      <td>-8.040443e-16</td>\n",
       "      <td>9.768662e-17</td>\n",
       "      <td>-7.424616e-16</td>\n",
       "      <td>6.782769e-16</td>\n",
       "      <td>9.410875e-17</td>\n",
       "      <td>8.829742e-16</td>\n",
       "      <td>7.251144e-16</td>\n",
       "      <td>3.660267e-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.783501</td>\n",
       "      <td>24.485242</td>\n",
       "      <td>-5.499398</td>\n",
       "      <td>-0.015502</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>-0.890922</td>\n",
       "      <td>-1.898497</td>\n",
       "      <td>0.905668</td>\n",
       "      <td>-0.373819</td>\n",
       "      <td>-0.738310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.191755e-15</td>\n",
       "      <td>-9.705778e-16</td>\n",
       "      <td>-2.631359e-16</td>\n",
       "      <td>4.857226e-17</td>\n",
       "      <td>1.344411e-15</td>\n",
       "      <td>-3.777360e-16</td>\n",
       "      <td>4.388850e-16</td>\n",
       "      <td>1.307982e-15</td>\n",
       "      <td>-3.139849e-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.738325</td>\n",
       "      <td>-10.815425</td>\n",
       "      <td>11.288670</td>\n",
       "      <td>-0.172892</td>\n",
       "      <td>0.199916</td>\n",
       "      <td>-1.038345</td>\n",
       "      <td>-2.272757</td>\n",
       "      <td>1.286362</td>\n",
       "      <td>-0.228206</td>\n",
       "      <td>-0.121589</td>\n",
       "      <td>...</td>\n",
       "      <td>9.558326e-16</td>\n",
       "      <td>-3.044440e-16</td>\n",
       "      <td>-1.243580e-16</td>\n",
       "      <td>-2.151057e-16</td>\n",
       "      <td>9.003215e-16</td>\n",
       "      <td>-4.054916e-16</td>\n",
       "      <td>9.384854e-16</td>\n",
       "      <td>1.144917e-16</td>\n",
       "      <td>5.204170e-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3         4         5         6  \\\n",
       "0  54.735016  -6.821420   5.321452 -0.121539  0.187416 -0.897372 -2.291834   \n",
       "1  54.738457 -10.901443  11.417594 -0.174549  0.200042 -1.004832 -2.272362   \n",
       "2  54.741884  -5.762823   7.334577 -0.143222  0.198285 -0.977237 -2.248057   \n",
       "3  54.783501  24.485242  -5.499398 -0.015502  0.232918 -0.890922 -1.898497   \n",
       "4  54.738325 -10.815425  11.288670 -0.172892  0.199916 -1.038345 -2.272757   \n",
       "\n",
       "          7         8         9  ...           141           142  \\\n",
       "0  1.178392 -0.646932 -0.396290  ...  7.060325e-16 -8.595555e-16   \n",
       "1  1.291243 -0.184776  0.090314  ...  1.025222e-15 -8.317999e-16   \n",
       "2  1.234142  0.227470 -0.067357  ...  1.344411e-15 -8.040443e-16   \n",
       "3  0.905668 -0.373819 -0.738310  ...  1.191755e-15 -9.705778e-16   \n",
       "4  1.286362 -0.228206 -0.121589  ...  9.558326e-16 -3.044440e-16   \n",
       "\n",
       "            143           144           145           146           147  \\\n",
       "0 -7.627362e-16 -1.020017e-15  7.615436e-16 -1.099381e-15  1.465841e-15   \n",
       "1 -1.104802e-16 -5.620504e-16  1.066855e-15 -4.466913e-17  7.441964e-16   \n",
       "2  9.768662e-17 -7.424616e-16  6.782769e-16  9.410875e-17  8.829742e-16   \n",
       "3 -2.631359e-16  4.857226e-17  1.344411e-15 -3.777360e-16  4.388850e-16   \n",
       "4 -1.243580e-16 -2.151057e-16  9.003215e-16 -4.054916e-16  9.384854e-16   \n",
       "\n",
       "            148           149  day_of_month  \n",
       "0  4.753142e-16  5.204170e-18           NaN  \n",
       "1  2.255141e-16  3.382711e-16           NaN  \n",
       "2  7.251144e-16  3.660267e-16           NaN  \n",
       "3  1.307982e-15 -3.139849e-16           NaN  \n",
       "4  1.144917e-16  5.204170e-18           NaN  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop([\"day_of_month\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.735016</td>\n",
       "      <td>-6.821420</td>\n",
       "      <td>5.321452</td>\n",
       "      <td>-0.121539</td>\n",
       "      <td>0.187416</td>\n",
       "      <td>-0.897372</td>\n",
       "      <td>-2.291834</td>\n",
       "      <td>1.178392</td>\n",
       "      <td>-0.646932</td>\n",
       "      <td>-0.396290</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179612e-15</td>\n",
       "      <td>7.060325e-16</td>\n",
       "      <td>-8.595555e-16</td>\n",
       "      <td>-7.627362e-16</td>\n",
       "      <td>-1.020017e-15</td>\n",
       "      <td>7.615436e-16</td>\n",
       "      <td>-1.099381e-15</td>\n",
       "      <td>1.465841e-15</td>\n",
       "      <td>4.753142e-16</td>\n",
       "      <td>5.204170e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.738457</td>\n",
       "      <td>-10.901443</td>\n",
       "      <td>11.417594</td>\n",
       "      <td>-0.174549</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>-1.004832</td>\n",
       "      <td>-2.272362</td>\n",
       "      <td>1.291243</td>\n",
       "      <td>-0.184776</td>\n",
       "      <td>0.090314</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.359224e-16</td>\n",
       "      <td>1.025222e-15</td>\n",
       "      <td>-8.317999e-16</td>\n",
       "      <td>-1.104802e-16</td>\n",
       "      <td>-5.620504e-16</td>\n",
       "      <td>1.066855e-15</td>\n",
       "      <td>-4.466913e-17</td>\n",
       "      <td>7.441964e-16</td>\n",
       "      <td>2.255141e-16</td>\n",
       "      <td>3.382711e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.741884</td>\n",
       "      <td>-5.762823</td>\n",
       "      <td>7.334577</td>\n",
       "      <td>-0.143222</td>\n",
       "      <td>0.198285</td>\n",
       "      <td>-0.977237</td>\n",
       "      <td>-2.248057</td>\n",
       "      <td>1.234142</td>\n",
       "      <td>0.227470</td>\n",
       "      <td>-0.067357</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.800116e-16</td>\n",
       "      <td>1.344411e-15</td>\n",
       "      <td>-8.040443e-16</td>\n",
       "      <td>9.768662e-17</td>\n",
       "      <td>-7.424616e-16</td>\n",
       "      <td>6.782769e-16</td>\n",
       "      <td>9.410875e-17</td>\n",
       "      <td>8.829742e-16</td>\n",
       "      <td>7.251144e-16</td>\n",
       "      <td>3.660267e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.783501</td>\n",
       "      <td>24.485242</td>\n",
       "      <td>-5.499398</td>\n",
       "      <td>-0.015502</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>-0.890922</td>\n",
       "      <td>-1.898497</td>\n",
       "      <td>0.905668</td>\n",
       "      <td>-0.373819</td>\n",
       "      <td>-0.738310</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.187895e-16</td>\n",
       "      <td>1.191755e-15</td>\n",
       "      <td>-9.705778e-16</td>\n",
       "      <td>-2.631359e-16</td>\n",
       "      <td>4.857226e-17</td>\n",
       "      <td>1.344411e-15</td>\n",
       "      <td>-3.777360e-16</td>\n",
       "      <td>4.388850e-16</td>\n",
       "      <td>1.307982e-15</td>\n",
       "      <td>-3.139849e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.738325</td>\n",
       "      <td>-10.815425</td>\n",
       "      <td>11.288670</td>\n",
       "      <td>-0.172892</td>\n",
       "      <td>0.199916</td>\n",
       "      <td>-1.038345</td>\n",
       "      <td>-2.272757</td>\n",
       "      <td>1.286362</td>\n",
       "      <td>-0.228206</td>\n",
       "      <td>-0.121589</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.747003e-16</td>\n",
       "      <td>9.558326e-16</td>\n",
       "      <td>-3.044440e-16</td>\n",
       "      <td>-1.243580e-16</td>\n",
       "      <td>-2.151057e-16</td>\n",
       "      <td>9.003215e-16</td>\n",
       "      <td>-4.054916e-16</td>\n",
       "      <td>9.384854e-16</td>\n",
       "      <td>1.144917e-16</td>\n",
       "      <td>5.204170e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2         3         4         5         6    \\\n",
       "0  54.735016  -6.821420   5.321452 -0.121539  0.187416 -0.897372 -2.291834   \n",
       "1  54.738457 -10.901443  11.417594 -0.174549  0.200042 -1.004832 -2.272362   \n",
       "2  54.741884  -5.762823   7.334577 -0.143222  0.198285 -0.977237 -2.248057   \n",
       "3  54.783501  24.485242  -5.499398 -0.015502  0.232918 -0.890922 -1.898497   \n",
       "4  54.738325 -10.815425  11.288670 -0.172892  0.199916 -1.038345 -2.272757   \n",
       "\n",
       "        7         8         9    ...           140           141  \\\n",
       "0  1.178392 -0.646932 -0.396290  ... -1.179612e-15  7.060325e-16   \n",
       "1  1.291243 -0.184776  0.090314  ... -2.359224e-16  1.025222e-15   \n",
       "2  1.234142  0.227470 -0.067357  ... -6.800116e-16  1.344411e-15   \n",
       "3  0.905668 -0.373819 -0.738310  ... -8.187895e-16  1.191755e-15   \n",
       "4  1.286362 -0.228206 -0.121589  ... -3.747003e-16  9.558326e-16   \n",
       "\n",
       "            142           143           144           145           146  \\\n",
       "0 -8.595555e-16 -7.627362e-16 -1.020017e-15  7.615436e-16 -1.099381e-15   \n",
       "1 -8.317999e-16 -1.104802e-16 -5.620504e-16  1.066855e-15 -4.466913e-17   \n",
       "2 -8.040443e-16  9.768662e-17 -7.424616e-16  6.782769e-16  9.410875e-17   \n",
       "3 -9.705778e-16 -2.631359e-16  4.857226e-17  1.344411e-15 -3.777360e-16   \n",
       "4 -3.044440e-16 -1.243580e-16 -2.151057e-16  9.003215e-16 -4.054916e-16   \n",
       "\n",
       "            147           148           149  \n",
       "0  1.465841e-15  4.753142e-16  5.204170e-18  \n",
       "1  7.441964e-16  2.255141e-16  3.382711e-16  \n",
       "2  8.829742e-16  7.251144e-16  3.660267e-16  \n",
       "3  4.388850e-16  1.307982e-15 -3.139849e-16  \n",
       "4  9.384854e-16  1.144917e-16  5.204170e-18  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_month = day_of_month.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3008016</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008017</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008018</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008019</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008020</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         day_of_month\n",
       "3008016            16\n",
       "3008017            16\n",
       "3008018            16\n",
       "3008019            16\n",
       "3008020            16"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_of_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_of_month    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_of_month.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28512, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_of_month.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28512, 150)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['day_of_month'] = day_of_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.insert(150, \"day_of_month\", day_of_month, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.735016</td>\n",
       "      <td>-6.821420</td>\n",
       "      <td>5.321452</td>\n",
       "      <td>-0.121539</td>\n",
       "      <td>0.187416</td>\n",
       "      <td>-0.897372</td>\n",
       "      <td>-2.291834</td>\n",
       "      <td>1.178392</td>\n",
       "      <td>-0.646932</td>\n",
       "      <td>-0.396290</td>\n",
       "      <td>...</td>\n",
       "      <td>7.060325e-16</td>\n",
       "      <td>-8.595555e-16</td>\n",
       "      <td>-7.627362e-16</td>\n",
       "      <td>-1.020017e-15</td>\n",
       "      <td>7.615436e-16</td>\n",
       "      <td>-1.099381e-15</td>\n",
       "      <td>1.465841e-15</td>\n",
       "      <td>4.753142e-16</td>\n",
       "      <td>5.204170e-18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.738457</td>\n",
       "      <td>-10.901443</td>\n",
       "      <td>11.417594</td>\n",
       "      <td>-0.174549</td>\n",
       "      <td>0.200042</td>\n",
       "      <td>-1.004832</td>\n",
       "      <td>-2.272362</td>\n",
       "      <td>1.291243</td>\n",
       "      <td>-0.184776</td>\n",
       "      <td>0.090314</td>\n",
       "      <td>...</td>\n",
       "      <td>1.025222e-15</td>\n",
       "      <td>-8.317999e-16</td>\n",
       "      <td>-1.104802e-16</td>\n",
       "      <td>-5.620504e-16</td>\n",
       "      <td>1.066855e-15</td>\n",
       "      <td>-4.466913e-17</td>\n",
       "      <td>7.441964e-16</td>\n",
       "      <td>2.255141e-16</td>\n",
       "      <td>3.382711e-16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.741884</td>\n",
       "      <td>-5.762823</td>\n",
       "      <td>7.334577</td>\n",
       "      <td>-0.143222</td>\n",
       "      <td>0.198285</td>\n",
       "      <td>-0.977237</td>\n",
       "      <td>-2.248057</td>\n",
       "      <td>1.234142</td>\n",
       "      <td>0.227470</td>\n",
       "      <td>-0.067357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.344411e-15</td>\n",
       "      <td>-8.040443e-16</td>\n",
       "      <td>9.768662e-17</td>\n",
       "      <td>-7.424616e-16</td>\n",
       "      <td>6.782769e-16</td>\n",
       "      <td>9.410875e-17</td>\n",
       "      <td>8.829742e-16</td>\n",
       "      <td>7.251144e-16</td>\n",
       "      <td>3.660267e-16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.783501</td>\n",
       "      <td>24.485242</td>\n",
       "      <td>-5.499398</td>\n",
       "      <td>-0.015502</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>-0.890922</td>\n",
       "      <td>-1.898497</td>\n",
       "      <td>0.905668</td>\n",
       "      <td>-0.373819</td>\n",
       "      <td>-0.738310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.191755e-15</td>\n",
       "      <td>-9.705778e-16</td>\n",
       "      <td>-2.631359e-16</td>\n",
       "      <td>4.857226e-17</td>\n",
       "      <td>1.344411e-15</td>\n",
       "      <td>-3.777360e-16</td>\n",
       "      <td>4.388850e-16</td>\n",
       "      <td>1.307982e-15</td>\n",
       "      <td>-3.139849e-16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.738325</td>\n",
       "      <td>-10.815425</td>\n",
       "      <td>11.288670</td>\n",
       "      <td>-0.172892</td>\n",
       "      <td>0.199916</td>\n",
       "      <td>-1.038345</td>\n",
       "      <td>-2.272757</td>\n",
       "      <td>1.286362</td>\n",
       "      <td>-0.228206</td>\n",
       "      <td>-0.121589</td>\n",
       "      <td>...</td>\n",
       "      <td>9.558326e-16</td>\n",
       "      <td>-3.044440e-16</td>\n",
       "      <td>-1.243580e-16</td>\n",
       "      <td>-2.151057e-16</td>\n",
       "      <td>9.003215e-16</td>\n",
       "      <td>-4.054916e-16</td>\n",
       "      <td>9.384854e-16</td>\n",
       "      <td>1.144917e-16</td>\n",
       "      <td>5.204170e-18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3         4         5         6  \\\n",
       "0  54.735016  -6.821420   5.321452 -0.121539  0.187416 -0.897372 -2.291834   \n",
       "1  54.738457 -10.901443  11.417594 -0.174549  0.200042 -1.004832 -2.272362   \n",
       "2  54.741884  -5.762823   7.334577 -0.143222  0.198285 -0.977237 -2.248057   \n",
       "3  54.783501  24.485242  -5.499398 -0.015502  0.232918 -0.890922 -1.898497   \n",
       "4  54.738325 -10.815425  11.288670 -0.172892  0.199916 -1.038345 -2.272757   \n",
       "\n",
       "          7         8         9  ...           141           142  \\\n",
       "0  1.178392 -0.646932 -0.396290  ...  7.060325e-16 -8.595555e-16   \n",
       "1  1.291243 -0.184776  0.090314  ...  1.025222e-15 -8.317999e-16   \n",
       "2  1.234142  0.227470 -0.067357  ...  1.344411e-15 -8.040443e-16   \n",
       "3  0.905668 -0.373819 -0.738310  ...  1.191755e-15 -9.705778e-16   \n",
       "4  1.286362 -0.228206 -0.121589  ...  9.558326e-16 -3.044440e-16   \n",
       "\n",
       "            143           144           145           146           147  \\\n",
       "0 -7.627362e-16 -1.020017e-15  7.615436e-16 -1.099381e-15  1.465841e-15   \n",
       "1 -1.104802e-16 -5.620504e-16  1.066855e-15 -4.466913e-17  7.441964e-16   \n",
       "2  9.768662e-17 -7.424616e-16  6.782769e-16  9.410875e-17  8.829742e-16   \n",
       "3 -2.631359e-16  4.857226e-17  1.344411e-15 -3.777360e-16  4.388850e-16   \n",
       "4 -1.243580e-16 -2.151057e-16  9.003215e-16 -4.054916e-16  9.384854e-16   \n",
       "\n",
       "            148           149  day_of_month  \n",
       "0  4.753142e-16  5.204170e-18            16  \n",
       "1  2.255141e-16  3.382711e-16            16  \n",
       "2  7.251144e-16  3.660267e-16            16  \n",
       "3  1.307982e-15 -3.139849e-16            16  \n",
       "4  1.144917e-16  5.204170e-18            16  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    1782\n",
       "17    1782\n",
       "18    1782\n",
       "19    1782\n",
       "20    1782\n",
       "21    1782\n",
       "22    1782\n",
       "23    1782\n",
       "24    1782\n",
       "25    1782\n",
       "26    1782\n",
       "27    1782\n",
       "28    1782\n",
       "29    1782\n",
       "30    1782\n",
       "31    1782\n",
       "Name: day_of_month, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['day_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment I -- Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spartan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "run_experiment_I = True\n",
    "if run_experiment_I:\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spartan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/spartan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS log-error train:  0.16114941007025096\n",
      "RMS log-error val:  0.16183531040518712\n",
      "RMS log-error train (actual):  0.4264715466621936\n",
      "RMS log-error val (actual):  0.42689531109800605\n"
     ]
    }
   ],
   "source": [
    "if run_experiment_I:\n",
    "    y_pred_train = lr.predict(X_train)\n",
    "    y_pred_train[y_pred_train < 0] = 0\n",
    "    y_pred_val = lr.predict(X_val)\n",
    "    y_pred_val[y_pred_val < 0] = 0\n",
    "\n",
    "    print(\"RMS log-error train: \", np.sqrt(mean_squared_log_error(y_train, y_pred_train)))\n",
    "    print(\"RMS log-error val: \", np.sqrt(mean_squared_log_error(y_val, y_pred_val)))\n",
    "    print(\"RMS log-error train (actual): \",\n",
    "          np.sqrt(mean_squared_log_error(np.expm1(y_train), np.expm1(y_pred_train))))\n",
    "    print(\"RMS log-error val (actual): \",\n",
    "          np.sqrt(mean_squared_log_error(np.expm1(y_val), np.expm1(y_pred_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment II -- Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'boosting_type' : 'gbdt',  # gradient boosting decision tree\n",
    "    'early_stopping_rounds': 200,\n",
    "    'force_col_wise': True,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 10,\n",
    "    'metric': 'mse',  # mean square error\n",
    "    'num_iterations': 5000,\n",
    "    'num_leaves': 10,\n",
    "    'random_state': 1,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "run_experiment_II = True  # should be true\n",
    "if run_experiment_II:\n",
    "    X_train_lgb = lightgbm.Dataset(data=X_train, label=y_train, feature_name='auto')\n",
    "    X_val_lgb = lightgbm.Dataset(data=X_val, label=y_val, reference=X_train_lgb, feature_name='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 3.08025\tvalid_1's l2: 3.32536\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2]\ttraining's l2: 2.64088\tvalid_1's l2: 2.8625\n",
      "[3]\ttraining's l2: 2.28494\tvalid_1's l2: 2.49129\n",
      "[4]\ttraining's l2: 1.99155\tvalid_1's l2: 2.18464\n",
      "[5]\ttraining's l2: 1.75269\tvalid_1's l2: 1.93936\n",
      "[6]\ttraining's l2: 1.55293\tvalid_1's l2: 1.73581\n",
      "[7]\ttraining's l2: 1.38871\tvalid_1's l2: 1.56638\n",
      "[8]\ttraining's l2: 1.2528\tvalid_1's l2: 1.43213\n",
      "[9]\ttraining's l2: 1.14397\tvalid_1's l2: 1.32266\n",
      "[10]\ttraining's l2: 1.05567\tvalid_1's l2: 1.23178\n",
      "[11]\ttraining's l2: 0.982369\tvalid_1's l2: 1.16004\n",
      "[12]\ttraining's l2: 0.919926\tvalid_1's l2: 1.10163\n",
      "[13]\ttraining's l2: 0.869092\tvalid_1's l2: 1.05099\n",
      "[14]\ttraining's l2: 0.826757\tvalid_1's l2: 1.01009\n",
      "[15]\ttraining's l2: 0.788786\tvalid_1's l2: 0.980336\n",
      "[16]\ttraining's l2: 0.753583\tvalid_1's l2: 0.945958\n",
      "[17]\ttraining's l2: 0.724031\tvalid_1's l2: 0.917791\n",
      "[18]\ttraining's l2: 0.69783\tvalid_1's l2: 0.900712\n",
      "[19]\ttraining's l2: 0.674961\tvalid_1's l2: 0.88267\n",
      "[20]\ttraining's l2: 0.65527\tvalid_1's l2: 0.867069\n",
      "[21]\ttraining's l2: 0.635683\tvalid_1's l2: 0.852144\n",
      "[22]\ttraining's l2: 0.618378\tvalid_1's l2: 0.84304\n",
      "[23]\ttraining's l2: 0.603779\tvalid_1's l2: 0.83786\n",
      "[24]\ttraining's l2: 0.591505\tvalid_1's l2: 0.829343\n",
      "[25]\ttraining's l2: 0.579092\tvalid_1's l2: 0.823097\n",
      "[26]\ttraining's l2: 0.568474\tvalid_1's l2: 0.815712\n",
      "[27]\ttraining's l2: 0.559804\tvalid_1's l2: 0.811969\n",
      "[28]\ttraining's l2: 0.550477\tvalid_1's l2: 0.808489\n",
      "[29]\ttraining's l2: 0.542975\tvalid_1's l2: 0.809544\n",
      "[30]\ttraining's l2: 0.531802\tvalid_1's l2: 0.806075\n",
      "[31]\ttraining's l2: 0.524114\tvalid_1's l2: 0.805714\n",
      "[32]\ttraining's l2: 0.516524\tvalid_1's l2: 0.802751\n",
      "[33]\ttraining's l2: 0.509771\tvalid_1's l2: 0.803387\n",
      "[34]\ttraining's l2: 0.50362\tvalid_1's l2: 0.804623\n",
      "[35]\ttraining's l2: 0.49801\tvalid_1's l2: 0.802205\n",
      "[36]\ttraining's l2: 0.492981\tvalid_1's l2: 0.803912\n",
      "[37]\ttraining's l2: 0.489222\tvalid_1's l2: 0.800584\n",
      "[38]\ttraining's l2: 0.48239\tvalid_1's l2: 0.800674\n",
      "[39]\ttraining's l2: 0.476237\tvalid_1's l2: 0.80025\n",
      "[40]\ttraining's l2: 0.470983\tvalid_1's l2: 0.799045\n",
      "[41]\ttraining's l2: 0.467405\tvalid_1's l2: 0.797951\n",
      "[42]\ttraining's l2: 0.461968\tvalid_1's l2: 0.797236\n",
      "[43]\ttraining's l2: 0.45723\tvalid_1's l2: 0.793899\n",
      "[44]\ttraining's l2: 0.454025\tvalid_1's l2: 0.794304\n",
      "[45]\ttraining's l2: 0.45049\tvalid_1's l2: 0.793346\n",
      "[46]\ttraining's l2: 0.44639\tvalid_1's l2: 0.793072\n",
      "[47]\ttraining's l2: 0.442613\tvalid_1's l2: 0.79165\n",
      "[48]\ttraining's l2: 0.438648\tvalid_1's l2: 0.789826\n",
      "[49]\ttraining's l2: 0.435054\tvalid_1's l2: 0.789902\n",
      "[50]\ttraining's l2: 0.430441\tvalid_1's l2: 0.788861\n",
      "[51]\ttraining's l2: 0.425729\tvalid_1's l2: 0.788516\n",
      "[52]\ttraining's l2: 0.423452\tvalid_1's l2: 0.7872\n",
      "[53]\ttraining's l2: 0.420252\tvalid_1's l2: 0.786272\n",
      "[54]\ttraining's l2: 0.417357\tvalid_1's l2: 0.786041\n",
      "[55]\ttraining's l2: 0.41448\tvalid_1's l2: 0.786407\n",
      "[56]\ttraining's l2: 0.411401\tvalid_1's l2: 0.786552\n",
      "[57]\ttraining's l2: 0.408482\tvalid_1's l2: 0.786856\n",
      "[58]\ttraining's l2: 0.405306\tvalid_1's l2: 0.784927\n",
      "[59]\ttraining's l2: 0.402033\tvalid_1's l2: 0.781681\n",
      "[60]\ttraining's l2: 0.39935\tvalid_1's l2: 0.782288\n",
      "[61]\ttraining's l2: 0.396676\tvalid_1's l2: 0.780807\n",
      "[62]\ttraining's l2: 0.394382\tvalid_1's l2: 0.781313\n",
      "[63]\ttraining's l2: 0.390461\tvalid_1's l2: 0.780675\n",
      "[64]\ttraining's l2: 0.388004\tvalid_1's l2: 0.78147\n",
      "[65]\ttraining's l2: 0.385359\tvalid_1's l2: 0.782599\n",
      "[66]\ttraining's l2: 0.382758\tvalid_1's l2: 0.782251\n",
      "[67]\ttraining's l2: 0.379802\tvalid_1's l2: 0.781525\n",
      "[68]\ttraining's l2: 0.37707\tvalid_1's l2: 0.779858\n",
      "[69]\ttraining's l2: 0.372632\tvalid_1's l2: 0.781032\n",
      "[70]\ttraining's l2: 0.370741\tvalid_1's l2: 0.781089\n",
      "[71]\ttraining's l2: 0.368922\tvalid_1's l2: 0.781595\n",
      "[72]\ttraining's l2: 0.365484\tvalid_1's l2: 0.779012\n",
      "[73]\ttraining's l2: 0.363519\tvalid_1's l2: 0.779265\n",
      "[74]\ttraining's l2: 0.360659\tvalid_1's l2: 0.778475\n",
      "[75]\ttraining's l2: 0.357881\tvalid_1's l2: 0.779096\n",
      "[76]\ttraining's l2: 0.355784\tvalid_1's l2: 0.778487\n",
      "[77]\ttraining's l2: 0.352304\tvalid_1's l2: 0.78135\n",
      "[78]\ttraining's l2: 0.348933\tvalid_1's l2: 0.782455\n",
      "[79]\ttraining's l2: 0.345629\tvalid_1's l2: 0.780705\n",
      "[80]\ttraining's l2: 0.343635\tvalid_1's l2: 0.780992\n",
      "[81]\ttraining's l2: 0.341694\tvalid_1's l2: 0.779597\n",
      "[82]\ttraining's l2: 0.339176\tvalid_1's l2: 0.779732\n",
      "[83]\ttraining's l2: 0.336759\tvalid_1's l2: 0.778902\n",
      "[84]\ttraining's l2: 0.334898\tvalid_1's l2: 0.777784\n",
      "[85]\ttraining's l2: 0.331913\tvalid_1's l2: 0.778624\n",
      "[86]\ttraining's l2: 0.329916\tvalid_1's l2: 0.778576\n",
      "[87]\ttraining's l2: 0.326711\tvalid_1's l2: 0.778811\n",
      "[88]\ttraining's l2: 0.325066\tvalid_1's l2: 0.778252\n",
      "[89]\ttraining's l2: 0.32314\tvalid_1's l2: 0.778306\n",
      "[90]\ttraining's l2: 0.321096\tvalid_1's l2: 0.778634\n",
      "[91]\ttraining's l2: 0.31922\tvalid_1's l2: 0.775673\n",
      "[92]\ttraining's l2: 0.31713\tvalid_1's l2: 0.776512\n",
      "[93]\ttraining's l2: 0.315367\tvalid_1's l2: 0.775309\n",
      "[94]\ttraining's l2: 0.31251\tvalid_1's l2: 0.777519\n",
      "[95]\ttraining's l2: 0.310316\tvalid_1's l2: 0.775026\n",
      "[96]\ttraining's l2: 0.308075\tvalid_1's l2: 0.774452\n",
      "[97]\ttraining's l2: 0.306352\tvalid_1's l2: 0.774176\n",
      "[98]\ttraining's l2: 0.304924\tvalid_1's l2: 0.773753\n",
      "[99]\ttraining's l2: 0.302985\tvalid_1's l2: 0.775048\n",
      "[100]\ttraining's l2: 0.301139\tvalid_1's l2: 0.774599\n",
      "[101]\ttraining's l2: 0.299297\tvalid_1's l2: 0.773963\n",
      "[102]\ttraining's l2: 0.296744\tvalid_1's l2: 0.773765\n",
      "[103]\ttraining's l2: 0.295025\tvalid_1's l2: 0.774236\n",
      "[104]\ttraining's l2: 0.292622\tvalid_1's l2: 0.77382\n",
      "[105]\ttraining's l2: 0.29164\tvalid_1's l2: 0.773717\n",
      "[106]\ttraining's l2: 0.289337\tvalid_1's l2: 0.772136\n",
      "[107]\ttraining's l2: 0.287777\tvalid_1's l2: 0.772126\n",
      "[108]\ttraining's l2: 0.285406\tvalid_1's l2: 0.773737\n",
      "[109]\ttraining's l2: 0.28307\tvalid_1's l2: 0.773927\n",
      "[110]\ttraining's l2: 0.281267\tvalid_1's l2: 0.772894\n",
      "[111]\ttraining's l2: 0.279576\tvalid_1's l2: 0.772528\n",
      "[112]\ttraining's l2: 0.27773\tvalid_1's l2: 0.774415\n",
      "[113]\ttraining's l2: 0.275475\tvalid_1's l2: 0.77377\n",
      "[114]\ttraining's l2: 0.273948\tvalid_1's l2: 0.770481\n",
      "[115]\ttraining's l2: 0.272418\tvalid_1's l2: 0.770097\n",
      "[116]\ttraining's l2: 0.271168\tvalid_1's l2: 0.769368\n",
      "[117]\ttraining's l2: 0.269922\tvalid_1's l2: 0.769852\n",
      "[118]\ttraining's l2: 0.267988\tvalid_1's l2: 0.771628\n",
      "[119]\ttraining's l2: 0.266069\tvalid_1's l2: 0.770328\n",
      "[120]\ttraining's l2: 0.26466\tvalid_1's l2: 0.770119\n",
      "[121]\ttraining's l2: 0.263486\tvalid_1's l2: 0.770632\n",
      "[122]\ttraining's l2: 0.261924\tvalid_1's l2: 0.770841\n",
      "[123]\ttraining's l2: 0.260013\tvalid_1's l2: 0.769309\n",
      "[124]\ttraining's l2: 0.258624\tvalid_1's l2: 0.770451\n",
      "[125]\ttraining's l2: 0.257282\tvalid_1's l2: 0.770852\n",
      "[126]\ttraining's l2: 0.255506\tvalid_1's l2: 0.769256\n",
      "[127]\ttraining's l2: 0.254087\tvalid_1's l2: 0.768208\n",
      "[128]\ttraining's l2: 0.252772\tvalid_1's l2: 0.769523\n",
      "[129]\ttraining's l2: 0.25184\tvalid_1's l2: 0.769613\n",
      "[130]\ttraining's l2: 0.2502\tvalid_1's l2: 0.769438\n",
      "[131]\ttraining's l2: 0.249426\tvalid_1's l2: 0.769188\n",
      "[132]\ttraining's l2: 0.247714\tvalid_1's l2: 0.768463\n",
      "[133]\ttraining's l2: 0.246743\tvalid_1's l2: 0.767329\n",
      "[134]\ttraining's l2: 0.244855\tvalid_1's l2: 0.766531\n",
      "[135]\ttraining's l2: 0.243714\tvalid_1's l2: 0.766686\n",
      "[136]\ttraining's l2: 0.242187\tvalid_1's l2: 0.766339\n",
      "[137]\ttraining's l2: 0.240221\tvalid_1's l2: 0.766926\n",
      "[138]\ttraining's l2: 0.239133\tvalid_1's l2: 0.767237\n",
      "[139]\ttraining's l2: 0.238135\tvalid_1's l2: 0.76707\n",
      "[140]\ttraining's l2: 0.237113\tvalid_1's l2: 0.767532\n",
      "[141]\ttraining's l2: 0.23638\tvalid_1's l2: 0.766961\n",
      "[142]\ttraining's l2: 0.234577\tvalid_1's l2: 0.764686\n",
      "[143]\ttraining's l2: 0.233179\tvalid_1's l2: 0.764869\n",
      "[144]\ttraining's l2: 0.231587\tvalid_1's l2: 0.765126\n",
      "[145]\ttraining's l2: 0.230687\tvalid_1's l2: 0.764128\n",
      "[146]\ttraining's l2: 0.229936\tvalid_1's l2: 0.764986\n",
      "[147]\ttraining's l2: 0.229016\tvalid_1's l2: 0.76516\n",
      "[148]\ttraining's l2: 0.227049\tvalid_1's l2: 0.764054\n",
      "[149]\ttraining's l2: 0.225362\tvalid_1's l2: 0.76372\n",
      "[150]\ttraining's l2: 0.223499\tvalid_1's l2: 0.764781\n",
      "[151]\ttraining's l2: 0.222697\tvalid_1's l2: 0.764384\n",
      "[152]\ttraining's l2: 0.221589\tvalid_1's l2: 0.762631\n",
      "[153]\ttraining's l2: 0.219814\tvalid_1's l2: 0.763187\n",
      "[154]\ttraining's l2: 0.219048\tvalid_1's l2: 0.76273\n",
      "[155]\ttraining's l2: 0.218343\tvalid_1's l2: 0.762059\n",
      "[156]\ttraining's l2: 0.216591\tvalid_1's l2: 0.76089\n",
      "[157]\ttraining's l2: 0.215603\tvalid_1's l2: 0.760183\n",
      "[158]\ttraining's l2: 0.214623\tvalid_1's l2: 0.759587\n",
      "[159]\ttraining's l2: 0.213697\tvalid_1's l2: 0.759123\n",
      "[160]\ttraining's l2: 0.212383\tvalid_1's l2: 0.758741\n",
      "[161]\ttraining's l2: 0.211055\tvalid_1's l2: 0.760094\n",
      "[162]\ttraining's l2: 0.209728\tvalid_1's l2: 0.760038\n",
      "[163]\ttraining's l2: 0.208635\tvalid_1's l2: 0.761386\n",
      "[164]\ttraining's l2: 0.207531\tvalid_1's l2: 0.760788\n",
      "[165]\ttraining's l2: 0.205964\tvalid_1's l2: 0.760915\n",
      "[166]\ttraining's l2: 0.204909\tvalid_1's l2: 0.76195\n",
      "[167]\ttraining's l2: 0.203804\tvalid_1's l2: 0.763434\n",
      "[168]\ttraining's l2: 0.203064\tvalid_1's l2: 0.764315\n",
      "[169]\ttraining's l2: 0.201717\tvalid_1's l2: 0.764315\n",
      "[170]\ttraining's l2: 0.200348\tvalid_1's l2: 0.764537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171]\ttraining's l2: 0.199387\tvalid_1's l2: 0.764011\n",
      "[172]\ttraining's l2: 0.197458\tvalid_1's l2: 0.763854\n",
      "[173]\ttraining's l2: 0.1966\tvalid_1's l2: 0.761488\n",
      "[174]\ttraining's l2: 0.195455\tvalid_1's l2: 0.761336\n",
      "[175]\ttraining's l2: 0.194324\tvalid_1's l2: 0.763025\n",
      "[176]\ttraining's l2: 0.193571\tvalid_1's l2: 0.763779\n",
      "[177]\ttraining's l2: 0.192727\tvalid_1's l2: 0.763965\n",
      "[178]\ttraining's l2: 0.191959\tvalid_1's l2: 0.764188\n",
      "[179]\ttraining's l2: 0.191085\tvalid_1's l2: 0.76299\n",
      "[180]\ttraining's l2: 0.190247\tvalid_1's l2: 0.761166\n",
      "[181]\ttraining's l2: 0.189809\tvalid_1's l2: 0.761296\n",
      "[182]\ttraining's l2: 0.188997\tvalid_1's l2: 0.761071\n",
      "[183]\ttraining's l2: 0.18798\tvalid_1's l2: 0.760581\n",
      "[184]\ttraining's l2: 0.186727\tvalid_1's l2: 0.760571\n",
      "[185]\ttraining's l2: 0.185686\tvalid_1's l2: 0.760414\n",
      "[186]\ttraining's l2: 0.185\tvalid_1's l2: 0.760588\n",
      "[187]\ttraining's l2: 0.183842\tvalid_1's l2: 0.76059\n",
      "[188]\ttraining's l2: 0.182729\tvalid_1's l2: 0.760463\n",
      "[189]\ttraining's l2: 0.181973\tvalid_1's l2: 0.761721\n",
      "[190]\ttraining's l2: 0.180765\tvalid_1's l2: 0.761305\n",
      "[191]\ttraining's l2: 0.179835\tvalid_1's l2: 0.761417\n",
      "[192]\ttraining's l2: 0.178643\tvalid_1's l2: 0.76246\n",
      "[193]\ttraining's l2: 0.177072\tvalid_1's l2: 0.761849\n",
      "[194]\ttraining's l2: 0.176546\tvalid_1's l2: 0.761548\n",
      "[195]\ttraining's l2: 0.175919\tvalid_1's l2: 0.761798\n",
      "[196]\ttraining's l2: 0.175428\tvalid_1's l2: 0.762367\n",
      "[197]\ttraining's l2: 0.174479\tvalid_1's l2: 0.763974\n",
      "[198]\ttraining's l2: 0.173377\tvalid_1's l2: 0.765065\n",
      "[199]\ttraining's l2: 0.173004\tvalid_1's l2: 0.765348\n",
      "[200]\ttraining's l2: 0.172406\tvalid_1's l2: 0.765139\n",
      "[201]\ttraining's l2: 0.171533\tvalid_1's l2: 0.764674\n",
      "[202]\ttraining's l2: 0.170407\tvalid_1's l2: 0.764188\n",
      "[203]\ttraining's l2: 0.169763\tvalid_1's l2: 0.764281\n",
      "[204]\ttraining's l2: 0.16911\tvalid_1's l2: 0.764185\n",
      "[205]\ttraining's l2: 0.167933\tvalid_1's l2: 0.76368\n",
      "[206]\ttraining's l2: 0.166927\tvalid_1's l2: 0.764203\n",
      "[207]\ttraining's l2: 0.166338\tvalid_1's l2: 0.763663\n",
      "[208]\ttraining's l2: 0.165577\tvalid_1's l2: 0.762597\n",
      "[209]\ttraining's l2: 0.1645\tvalid_1's l2: 0.762364\n",
      "[210]\ttraining's l2: 0.163777\tvalid_1's l2: 0.761718\n",
      "[211]\ttraining's l2: 0.162976\tvalid_1's l2: 0.761884\n",
      "[212]\ttraining's l2: 0.161958\tvalid_1's l2: 0.761245\n",
      "[213]\ttraining's l2: 0.161525\tvalid_1's l2: 0.760979\n",
      "[214]\ttraining's l2: 0.161015\tvalid_1's l2: 0.760675\n",
      "[215]\ttraining's l2: 0.160122\tvalid_1's l2: 0.760818\n",
      "[216]\ttraining's l2: 0.159756\tvalid_1's l2: 0.760803\n",
      "[217]\ttraining's l2: 0.158862\tvalid_1's l2: 0.759905\n",
      "[218]\ttraining's l2: 0.157649\tvalid_1's l2: 0.759831\n",
      "[219]\ttraining's l2: 0.157089\tvalid_1's l2: 0.758869\n",
      "[220]\ttraining's l2: 0.156291\tvalid_1's l2: 0.758317\n",
      "[221]\ttraining's l2: 0.155643\tvalid_1's l2: 0.758675\n",
      "[222]\ttraining's l2: 0.154987\tvalid_1's l2: 0.758985\n",
      "[223]\ttraining's l2: 0.154062\tvalid_1's l2: 0.760139\n",
      "[224]\ttraining's l2: 0.153685\tvalid_1's l2: 0.760578\n",
      "[225]\ttraining's l2: 0.152957\tvalid_1's l2: 0.761046\n",
      "[226]\ttraining's l2: 0.152197\tvalid_1's l2: 0.762625\n",
      "[227]\ttraining's l2: 0.151491\tvalid_1's l2: 0.763623\n",
      "[228]\ttraining's l2: 0.150259\tvalid_1's l2: 0.76427\n",
      "[229]\ttraining's l2: 0.149791\tvalid_1's l2: 0.764062\n",
      "[230]\ttraining's l2: 0.149091\tvalid_1's l2: 0.764326\n",
      "[231]\ttraining's l2: 0.148194\tvalid_1's l2: 0.766436\n",
      "[232]\ttraining's l2: 0.147192\tvalid_1's l2: 0.765936\n",
      "[233]\ttraining's l2: 0.146607\tvalid_1's l2: 0.766718\n",
      "[234]\ttraining's l2: 0.145756\tvalid_1's l2: 0.767488\n",
      "[235]\ttraining's l2: 0.145486\tvalid_1's l2: 0.767485\n",
      "[236]\ttraining's l2: 0.144558\tvalid_1's l2: 0.766541\n",
      "[237]\ttraining's l2: 0.144129\tvalid_1's l2: 0.766952\n",
      "[238]\ttraining's l2: 0.143511\tvalid_1's l2: 0.767194\n",
      "[239]\ttraining's l2: 0.143304\tvalid_1's l2: 0.767169\n",
      "[240]\ttraining's l2: 0.142452\tvalid_1's l2: 0.767334\n",
      "[241]\ttraining's l2: 0.141792\tvalid_1's l2: 0.767814\n",
      "[242]\ttraining's l2: 0.141199\tvalid_1's l2: 0.768202\n",
      "[243]\ttraining's l2: 0.140944\tvalid_1's l2: 0.768383\n",
      "[244]\ttraining's l2: 0.140306\tvalid_1's l2: 0.767768\n",
      "[245]\ttraining's l2: 0.139636\tvalid_1's l2: 0.767376\n",
      "[246]\ttraining's l2: 0.139\tvalid_1's l2: 0.767323\n",
      "[247]\ttraining's l2: 0.138473\tvalid_1's l2: 0.767146\n",
      "[248]\ttraining's l2: 0.137917\tvalid_1's l2: 0.766782\n",
      "[249]\ttraining's l2: 0.137252\tvalid_1's l2: 0.76637\n",
      "[250]\ttraining's l2: 0.136732\tvalid_1's l2: 0.766786\n",
      "[251]\ttraining's l2: 0.136165\tvalid_1's l2: 0.767289\n",
      "[252]\ttraining's l2: 0.135222\tvalid_1's l2: 0.765969\n",
      "[253]\ttraining's l2: 0.134643\tvalid_1's l2: 0.765295\n",
      "[254]\ttraining's l2: 0.134291\tvalid_1's l2: 0.76558\n",
      "[255]\ttraining's l2: 0.133828\tvalid_1's l2: 0.766023\n",
      "[256]\ttraining's l2: 0.132957\tvalid_1's l2: 0.766044\n",
      "[257]\ttraining's l2: 0.131984\tvalid_1's l2: 0.767109\n",
      "[258]\ttraining's l2: 0.131584\tvalid_1's l2: 0.76655\n",
      "[259]\ttraining's l2: 0.130854\tvalid_1's l2: 0.766534\n",
      "[260]\ttraining's l2: 0.130247\tvalid_1's l2: 0.766226\n",
      "[261]\ttraining's l2: 0.129642\tvalid_1's l2: 0.76632\n",
      "[262]\ttraining's l2: 0.129266\tvalid_1's l2: 0.766237\n",
      "[263]\ttraining's l2: 0.128707\tvalid_1's l2: 0.766554\n",
      "[264]\ttraining's l2: 0.128255\tvalid_1's l2: 0.765719\n",
      "[265]\ttraining's l2: 0.127712\tvalid_1's l2: 0.765418\n",
      "[266]\ttraining's l2: 0.12705\tvalid_1's l2: 0.765284\n",
      "[267]\ttraining's l2: 0.1266\tvalid_1's l2: 0.765661\n",
      "[268]\ttraining's l2: 0.125891\tvalid_1's l2: 0.765082\n",
      "[269]\ttraining's l2: 0.125489\tvalid_1's l2: 0.765615\n",
      "[270]\ttraining's l2: 0.125245\tvalid_1's l2: 0.765612\n",
      "[271]\ttraining's l2: 0.124597\tvalid_1's l2: 0.765315\n",
      "[272]\ttraining's l2: 0.124153\tvalid_1's l2: 0.764818\n",
      "[273]\ttraining's l2: 0.123753\tvalid_1's l2: 0.76539\n",
      "[274]\ttraining's l2: 0.123053\tvalid_1's l2: 0.764795\n",
      "[275]\ttraining's l2: 0.122557\tvalid_1's l2: 0.764124\n",
      "[276]\ttraining's l2: 0.122049\tvalid_1's l2: 0.763735\n",
      "[277]\ttraining's l2: 0.121245\tvalid_1's l2: 0.764504\n",
      "[278]\ttraining's l2: 0.120608\tvalid_1's l2: 0.764158\n",
      "[279]\ttraining's l2: 0.120196\tvalid_1's l2: 0.764314\n",
      "[280]\ttraining's l2: 0.119665\tvalid_1's l2: 0.76419\n",
      "[281]\ttraining's l2: 0.119303\tvalid_1's l2: 0.763971\n",
      "[282]\ttraining's l2: 0.118728\tvalid_1's l2: 0.763938\n",
      "[283]\ttraining's l2: 0.117611\tvalid_1's l2: 0.763742\n",
      "[284]\ttraining's l2: 0.117286\tvalid_1's l2: 0.763956\n",
      "[285]\ttraining's l2: 0.116765\tvalid_1's l2: 0.764687\n",
      "[286]\ttraining's l2: 0.116221\tvalid_1's l2: 0.765407\n",
      "[287]\ttraining's l2: 0.115648\tvalid_1's l2: 0.765974\n",
      "[288]\ttraining's l2: 0.115266\tvalid_1's l2: 0.766112\n",
      "[289]\ttraining's l2: 0.114824\tvalid_1's l2: 0.766069\n",
      "[290]\ttraining's l2: 0.113705\tvalid_1's l2: 0.765227\n",
      "[291]\ttraining's l2: 0.113311\tvalid_1's l2: 0.765285\n",
      "[292]\ttraining's l2: 0.11298\tvalid_1's l2: 0.766089\n",
      "[293]\ttraining's l2: 0.112516\tvalid_1's l2: 0.765138\n",
      "[294]\ttraining's l2: 0.112144\tvalid_1's l2: 0.764329\n",
      "[295]\ttraining's l2: 0.111692\tvalid_1's l2: 0.764335\n",
      "[296]\ttraining's l2: 0.110942\tvalid_1's l2: 0.764481\n",
      "[297]\ttraining's l2: 0.110597\tvalid_1's l2: 0.76497\n",
      "[298]\ttraining's l2: 0.110184\tvalid_1's l2: 0.76561\n",
      "[299]\ttraining's l2: 0.109984\tvalid_1's l2: 0.765772\n",
      "[300]\ttraining's l2: 0.109786\tvalid_1's l2: 0.765774\n",
      "[301]\ttraining's l2: 0.109408\tvalid_1's l2: 0.765695\n",
      "[302]\ttraining's l2: 0.109114\tvalid_1's l2: 0.766037\n",
      "[303]\ttraining's l2: 0.108732\tvalid_1's l2: 0.765692\n",
      "[304]\ttraining's l2: 0.108586\tvalid_1's l2: 0.765718\n",
      "[305]\ttraining's l2: 0.107805\tvalid_1's l2: 0.765765\n",
      "[306]\ttraining's l2: 0.107503\tvalid_1's l2: 0.765921\n",
      "[307]\ttraining's l2: 0.107333\tvalid_1's l2: 0.765663\n",
      "[308]\ttraining's l2: 0.106975\tvalid_1's l2: 0.766616\n",
      "[309]\ttraining's l2: 0.106564\tvalid_1's l2: 0.766636\n",
      "[310]\ttraining's l2: 0.106093\tvalid_1's l2: 0.766701\n",
      "[311]\ttraining's l2: 0.105512\tvalid_1's l2: 0.767665\n",
      "[312]\ttraining's l2: 0.10511\tvalid_1's l2: 0.767153\n",
      "[313]\ttraining's l2: 0.104799\tvalid_1's l2: 0.767618\n",
      "[314]\ttraining's l2: 0.104441\tvalid_1's l2: 0.767494\n",
      "[315]\ttraining's l2: 0.104234\tvalid_1's l2: 0.767032\n",
      "[316]\ttraining's l2: 0.103848\tvalid_1's l2: 0.767268\n",
      "[317]\ttraining's l2: 0.103567\tvalid_1's l2: 0.767473\n",
      "[318]\ttraining's l2: 0.103406\tvalid_1's l2: 0.767456\n",
      "[319]\ttraining's l2: 0.103054\tvalid_1's l2: 0.769254\n",
      "[320]\ttraining's l2: 0.102748\tvalid_1's l2: 0.769554\n",
      "[321]\ttraining's l2: 0.10237\tvalid_1's l2: 0.76867\n",
      "[322]\ttraining's l2: 0.102067\tvalid_1's l2: 0.76854\n",
      "[323]\ttraining's l2: 0.101681\tvalid_1's l2: 0.768418\n",
      "[324]\ttraining's l2: 0.101583\tvalid_1's l2: 0.768341\n",
      "[325]\ttraining's l2: 0.101187\tvalid_1's l2: 0.768727\n",
      "[326]\ttraining's l2: 0.100838\tvalid_1's l2: 0.768622\n",
      "[327]\ttraining's l2: 0.100679\tvalid_1's l2: 0.76856\n",
      "[328]\ttraining's l2: 0.100155\tvalid_1's l2: 0.76935\n",
      "[329]\ttraining's l2: 0.0998025\tvalid_1's l2: 0.768959\n",
      "[330]\ttraining's l2: 0.0995509\tvalid_1's l2: 0.769298\n",
      "[331]\ttraining's l2: 0.0993084\tvalid_1's l2: 0.769823\n",
      "[332]\ttraining's l2: 0.0989394\tvalid_1's l2: 0.769731\n",
      "[333]\ttraining's l2: 0.0986379\tvalid_1's l2: 0.769842\n",
      "[334]\ttraining's l2: 0.0983433\tvalid_1's l2: 0.770304\n",
      "[335]\ttraining's l2: 0.097904\tvalid_1's l2: 0.770316\n",
      "[336]\ttraining's l2: 0.0975948\tvalid_1's l2: 0.770119\n",
      "[337]\ttraining's l2: 0.0972859\tvalid_1's l2: 0.77009\n",
      "[338]\ttraining's l2: 0.0967495\tvalid_1's l2: 0.769817\n",
      "[339]\ttraining's l2: 0.0963065\tvalid_1's l2: 0.769722\n",
      "[340]\ttraining's l2: 0.0959279\tvalid_1's l2: 0.770429\n",
      "[341]\ttraining's l2: 0.0954299\tvalid_1's l2: 0.769985\n",
      "[342]\ttraining's l2: 0.0949888\tvalid_1's l2: 0.770882\n",
      "[343]\ttraining's l2: 0.0942714\tvalid_1's l2: 0.772089\n",
      "[344]\ttraining's l2: 0.0939617\tvalid_1's l2: 0.772404\n",
      "[345]\ttraining's l2: 0.0935529\tvalid_1's l2: 0.772116\n",
      "[346]\ttraining's l2: 0.0932927\tvalid_1's l2: 0.771611\n",
      "[347]\ttraining's l2: 0.0929042\tvalid_1's l2: 0.771644\n",
      "[348]\ttraining's l2: 0.0926785\tvalid_1's l2: 0.77152\n",
      "[349]\ttraining's l2: 0.0923831\tvalid_1's l2: 0.771165\n",
      "[350]\ttraining's l2: 0.0921467\tvalid_1's l2: 0.771242\n",
      "[351]\ttraining's l2: 0.0917373\tvalid_1's l2: 0.771591\n",
      "[352]\ttraining's l2: 0.091619\tvalid_1's l2: 0.771504\n",
      "[353]\ttraining's l2: 0.0912734\tvalid_1's l2: 0.770944\n",
      "[354]\ttraining's l2: 0.0908974\tvalid_1's l2: 0.770279\n",
      "[355]\ttraining's l2: 0.0904048\tvalid_1's l2: 0.769952\n",
      "[356]\ttraining's l2: 0.0903087\tvalid_1's l2: 0.769887\n",
      "[357]\ttraining's l2: 0.0899301\tvalid_1's l2: 0.769771\n",
      "[358]\ttraining's l2: 0.0897197\tvalid_1's l2: 0.769593\n",
      "[359]\ttraining's l2: 0.089497\tvalid_1's l2: 0.769227\n",
      "[360]\ttraining's l2: 0.0891655\tvalid_1's l2: 0.769492\n",
      "[361]\ttraining's l2: 0.0888918\tvalid_1's l2: 0.769312\n",
      "[362]\ttraining's l2: 0.088714\tvalid_1's l2: 0.769203\n",
      "[363]\ttraining's l2: 0.0884941\tvalid_1's l2: 0.769335\n",
      "[364]\ttraining's l2: 0.088029\tvalid_1's l2: 0.769207\n",
      "[365]\ttraining's l2: 0.0878384\tvalid_1's l2: 0.769575\n",
      "[366]\ttraining's l2: 0.0874606\tvalid_1's l2: 0.770039\n",
      "[367]\ttraining's l2: 0.0869458\tvalid_1's l2: 0.771189\n",
      "[368]\ttraining's l2: 0.0866322\tvalid_1's l2: 0.771014\n",
      "[369]\ttraining's l2: 0.0861687\tvalid_1's l2: 0.770193\n",
      "[370]\ttraining's l2: 0.0859409\tvalid_1's l2: 0.770656\n",
      "[371]\ttraining's l2: 0.0855255\tvalid_1's l2: 0.770826\n",
      "[372]\ttraining's l2: 0.0854058\tvalid_1's l2: 0.770992\n",
      "[373]\ttraining's l2: 0.0850415\tvalid_1's l2: 0.770806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[374]\ttraining's l2: 0.0847432\tvalid_1's l2: 0.771207\n",
      "[375]\ttraining's l2: 0.0843536\tvalid_1's l2: 0.77109\n",
      "[376]\ttraining's l2: 0.0840959\tvalid_1's l2: 0.770744\n",
      "[377]\ttraining's l2: 0.0837883\tvalid_1's l2: 0.771273\n",
      "[378]\ttraining's l2: 0.0834566\tvalid_1's l2: 0.771106\n",
      "[379]\ttraining's l2: 0.0833779\tvalid_1's l2: 0.771085\n",
      "[380]\ttraining's l2: 0.0832138\tvalid_1's l2: 0.770778\n",
      "[381]\ttraining's l2: 0.082857\tvalid_1's l2: 0.770971\n",
      "[382]\ttraining's l2: 0.0827012\tvalid_1's l2: 0.771202\n",
      "[383]\ttraining's l2: 0.0824927\tvalid_1's l2: 0.771702\n",
      "[384]\ttraining's l2: 0.0821722\tvalid_1's l2: 0.771245\n",
      "[385]\ttraining's l2: 0.0817519\tvalid_1's l2: 0.770176\n",
      "[386]\ttraining's l2: 0.0814709\tvalid_1's l2: 0.770151\n",
      "[387]\ttraining's l2: 0.0810742\tvalid_1's l2: 0.769944\n",
      "[388]\ttraining's l2: 0.0809308\tvalid_1's l2: 0.769869\n",
      "[389]\ttraining's l2: 0.0807303\tvalid_1's l2: 0.769868\n",
      "[390]\ttraining's l2: 0.0804766\tvalid_1's l2: 0.769616\n",
      "[391]\ttraining's l2: 0.0801384\tvalid_1's l2: 0.768602\n",
      "[392]\ttraining's l2: 0.0797511\tvalid_1's l2: 0.767753\n",
      "[393]\ttraining's l2: 0.0795231\tvalid_1's l2: 0.767923\n",
      "[394]\ttraining's l2: 0.0791314\tvalid_1's l2: 0.767602\n",
      "[395]\ttraining's l2: 0.0789393\tvalid_1's l2: 0.767884\n",
      "[396]\ttraining's l2: 0.0788266\tvalid_1's l2: 0.767729\n",
      "[397]\ttraining's l2: 0.0785831\tvalid_1's l2: 0.767269\n",
      "[398]\ttraining's l2: 0.0784981\tvalid_1's l2: 0.767263\n",
      "[399]\ttraining's l2: 0.078018\tvalid_1's l2: 0.768063\n",
      "[400]\ttraining's l2: 0.0777383\tvalid_1's l2: 0.768337\n",
      "[401]\ttraining's l2: 0.0774521\tvalid_1's l2: 0.768287\n",
      "[402]\ttraining's l2: 0.0773796\tvalid_1's l2: 0.7682\n",
      "[403]\ttraining's l2: 0.0772328\tvalid_1's l2: 0.768002\n",
      "[404]\ttraining's l2: 0.07693\tvalid_1's l2: 0.767189\n",
      "[405]\ttraining's l2: 0.0767822\tvalid_1's l2: 0.767054\n",
      "[406]\ttraining's l2: 0.0765249\tvalid_1's l2: 0.766558\n",
      "[407]\ttraining's l2: 0.0762458\tvalid_1's l2: 0.766917\n",
      "[408]\ttraining's l2: 0.0759852\tvalid_1's l2: 0.766945\n",
      "[409]\ttraining's l2: 0.0756313\tvalid_1's l2: 0.766237\n",
      "[410]\ttraining's l2: 0.0753391\tvalid_1's l2: 0.766972\n",
      "[411]\ttraining's l2: 0.0751486\tvalid_1's l2: 0.767153\n",
      "[412]\ttraining's l2: 0.0746729\tvalid_1's l2: 0.765816\n",
      "[413]\ttraining's l2: 0.0744871\tvalid_1's l2: 0.766059\n",
      "[414]\ttraining's l2: 0.0743109\tvalid_1's l2: 0.766367\n",
      "[415]\ttraining's l2: 0.0740356\tvalid_1's l2: 0.766073\n",
      "[416]\ttraining's l2: 0.0737345\tvalid_1's l2: 0.765587\n",
      "[417]\ttraining's l2: 0.073501\tvalid_1's l2: 0.765321\n",
      "[418]\ttraining's l2: 0.0731574\tvalid_1's l2: 0.766042\n",
      "[419]\ttraining's l2: 0.0727941\tvalid_1's l2: 0.765554\n",
      "[420]\ttraining's l2: 0.0725667\tvalid_1's l2: 0.766071\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's l2: 0.156291\tvalid_1's l2: 0.758317\n"
     ]
    }
   ],
   "source": [
    "if run_experiment_II:\n",
    "    lgb = lightgbm.train(\n",
    "        params=lgb_params, \n",
    "        train_set=X_train_lgb,\n",
    "        valid_sets=[X_train_lgb, X_val_lgb],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS log-error train:  0.09706488341239258\n",
      "RMS log-error val:  0.2018445806471314\n",
      "RMS log-error train (actual):  0.3953365923801808\n",
      "RMS log-error val (actual):  0.8708139540731853\n"
     ]
    }
   ],
   "source": [
    "if run_experiment_II:\n",
    "    y_pred_train = lgb.predict(X_train, num_iteration=lgb.best_iteration)\n",
    "    y_pred_train[y_pred_train < 0] = 0\n",
    "    y_pred_val = lgb.predict(X_val, num_iteration=lgb.best_iteration)\n",
    "    y_pred_val[y_pred_val < 0] = 0\n",
    "\n",
    "    print(\"RMS log-error train: \", np.sqrt(mean_squared_log_error(y_train, y_pred_train)))\n",
    "    print(\"RMS log-error val: \", np.sqrt(mean_squared_log_error(y_val, y_pred_val)))\n",
    "    print(\"RMS log-error train (actual): \",\n",
    "          np.sqrt(mean_squared_log_error(np.expm1(y_train), np.expm1(y_pred_train))))\n",
    "    print(\"RMS log-error val (actual): \",\n",
    "          np.sqrt(mean_squared_log_error(np.expm1(y_val), np.expm1(y_pred_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment III -- Random Forest (Too Slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_experiment_III:\n\u001b[1;32m      3\u001b[0m     random_forest \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mrandom_forest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_experiment_III = True\n",
    "if run_experiment_III:\n",
    "    random_forest = RandomForestRegressor(random_state=1)\n",
    "    random_forest.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS log-error train:  0.07991230493098243\n",
      "RMS log-error val:  0.198402429075905\n",
      "RMS log-error train (actual):  0.29627903576647857\n",
      "RMS log-error val (actual):  0.8535536261784764\n"
     ]
    }
   ],
   "source": [
    "if run_experiment_III:\n",
    "    y_pred_train = random_forest.predict(X_train)\n",
    "    y_pred_train[y_pred_train < 0] = 0\n",
    "    y_pred_val = random_forest.predict(X_val)\n",
    "    y_pred_val[y_pred_val < 0] = 0\n",
    "\n",
    "    print(\"RMS log-error train: \", np.sqrt(mean_squared_log_error(y_train, y_pred_train)))\n",
    "    print(\"RMS log-error val: \", np.sqrt(mean_squared_log_error(y_val, y_pred_val)))\n",
    "    print(\"RMS log-error train (actual): \",\n",
    "          np.sqrt(mean_squared_log_error(np.expm1(y_train), np.expm1(y_pred_train))))\n",
    "    print(\"RMS log-error val (actual): \",\n",
    "          np.sqrt(mean_squared_log_error(np.expm1(y_val), np.expm1(y_pred_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment IV -- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "      \"max_depth\": [6,10],\n",
    "      \"n_estimators\": [80,100],\n",
    "#        \"early_stopping_rounds\"=[50,55,60],\n",
    "      \"learning_rate\": [0.01,0.1],\n",
    "      #'colsample_bylevel': [0.1,0.5,1]\n",
    "      \n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment_IV = True\n",
    "if run_experiment_IV:\n",
    "    xgb = xgboost.XGBRegressor()\n",
    "# xgb.fit(X_train, y_train,\n",
    "#         eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "#         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    n_jobs = -1,\n",
    "    cv = 2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[0]\tvalidation_0-rmse:3.81863\tvalidation_1-rmse:3.82278\n",
      "[0]\tvalidation_0-rmse:3.81863\tvalidation_1-rmse:3.82278\n",
      "[0]\tvalidation_0-rmse:3.81863\tvalidation_1-rmse:3.82278\n",
      "[0]\tvalidation_0-rmse:3.81863\tvalidation_1-rmse:3.82278\n",
      "[0]\tvalidation_0-rmse:3.81854\tvalidation_1-rmse:3.82270\n",
      "[0]\tvalidation_0-rmse:3.81855\tvalidation_1-rmse:3.82270\n",
      "[0]\tvalidation_0-rmse:3.81855\tvalidation_1-rmse:3.82270\n",
      "[0]\tvalidation_0-rmse:3.81854\tvalidation_1-rmse:3.82270\n",
      "[1]\tvalidation_0-rmse:3.78101\tvalidation_1-rmse:3.78513\n",
      "[1]\tvalidation_0-rmse:3.78101\tvalidation_1-rmse:3.78513\n",
      "[1]\tvalidation_0-rmse:3.78101\tvalidation_1-rmse:3.78513\n",
      "[1]\tvalidation_0-rmse:3.78101\tvalidation_1-rmse:3.78513\n",
      "[1]\tvalidation_0-rmse:3.78083\tvalidation_1-rmse:3.78497\n",
      "[1]\tvalidation_0-rmse:3.78085\tvalidation_1-rmse:3.78498\n",
      "[1]\tvalidation_0-rmse:3.78085\tvalidation_1-rmse:3.78498\n",
      "[1]\tvalidation_0-rmse:3.78083\tvalidation_1-rmse:3.78497\n",
      "[2]\tvalidation_0-rmse:3.74378\tvalidation_1-rmse:3.74786\n",
      "[2]\tvalidation_0-rmse:3.74377\tvalidation_1-rmse:3.74785\n",
      "[2]\tvalidation_0-rmse:3.74378\tvalidation_1-rmse:3.74786\n",
      "[2]\tvalidation_0-rmse:3.74351\tvalidation_1-rmse:3.74761\n",
      "[3]\tvalidation_0-rmse:3.70692\tvalidation_1-rmse:3.71097\n",
      "[3]\tvalidation_0-rmse:3.70692\tvalidation_1-rmse:3.71097\n",
      "[3]\tvalidation_0-rmse:3.70690\tvalidation_1-rmse:3.71095\n",
      "[2]\tvalidation_0-rmse:3.74352\tvalidation_1-rmse:3.74763\n",
      "[2]\tvalidation_0-rmse:3.74351\tvalidation_1-rmse:3.74761\n",
      "[2]\tvalidation_0-rmse:3.74352\tvalidation_1-rmse:3.74763\n",
      "[2]\tvalidation_0-rmse:3.74377\tvalidation_1-rmse:3.74785\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:2.35245\tvalidation_1-rmse:2.35540\n",
      "[1]\tvalidation_0-rmse:1.46719\tvalidation_1-rmse:1.46957\n",
      "[2]\tvalidation_0-rmse:0.96064\tvalidation_1-rmse:0.96253\n",
      "[3]\tvalidation_0-rmse:0.68641\tvalidation_1-rmse:0.68819\n",
      "[4]\tvalidation_0-rmse:0.54877\tvalidation_1-rmse:0.55048\n",
      "[5]\tvalidation_0-rmse:0.48273\tvalidation_1-rmse:0.48479\n",
      "[6]\tvalidation_0-rmse:0.45276\tvalidation_1-rmse:0.45509\n",
      "[7]\tvalidation_0-rmse:0.43745\tvalidation_1-rmse:0.43973\n",
      "[8]\tvalidation_0-rmse:0.42934\tvalidation_1-rmse:0.43185\n",
      "[9]\tvalidation_0-rmse:0.42333\tvalidation_1-rmse:0.42601\n",
      "[10]\tvalidation_0-rmse:0.42010\tvalidation_1-rmse:0.42289\n",
      "[11]\tvalidation_0-rmse:0.41676\tvalidation_1-rmse:0.41988\n",
      "[12]\tvalidation_0-rmse:0.41425\tvalidation_1-rmse:0.41774\n",
      "[13]\tvalidation_0-rmse:0.41218\tvalidation_1-rmse:0.41607\n",
      "[14]\tvalidation_0-rmse:0.41042\tvalidation_1-rmse:0.41482\n",
      "[15]\tvalidation_0-rmse:0.40899\tvalidation_1-rmse:0.41352\n",
      "[16]\tvalidation_0-rmse:0.40782\tvalidation_1-rmse:0.41252\n",
      "[17]\tvalidation_0-rmse:0.40704\tvalidation_1-rmse:0.41182\n",
      "[18]\tvalidation_0-rmse:0.40606\tvalidation_1-rmse:0.41099\n",
      "[19]\tvalidation_0-rmse:0.40490\tvalidation_1-rmse:0.41044\n",
      "[20]\tvalidation_0-rmse:0.40413\tvalidation_1-rmse:0.41005\n",
      "[21]\tvalidation_0-rmse:0.40339\tvalidation_1-rmse:0.40949\n",
      "[22]\tvalidation_0-rmse:0.40242\tvalidation_1-rmse:0.40882\n",
      "[23]\tvalidation_0-rmse:0.40043\tvalidation_1-rmse:0.40688\n",
      "[24]\tvalidation_0-rmse:0.39963\tvalidation_1-rmse:0.40642\n",
      "[25]\tvalidation_0-rmse:0.39862\tvalidation_1-rmse:0.40592\n",
      "[26]\tvalidation_0-rmse:0.39799\tvalidation_1-rmse:0.40557\n",
      "[27]\tvalidation_0-rmse:0.39709\tvalidation_1-rmse:0.40488\n",
      "[28]\tvalidation_0-rmse:0.39639\tvalidation_1-rmse:0.40435\n",
      "[29]\tvalidation_0-rmse:0.39575\tvalidation_1-rmse:0.40385\n",
      "[30]\tvalidation_0-rmse:0.39548\tvalidation_1-rmse:0.40369\n",
      "[31]\tvalidation_0-rmse:0.39472\tvalidation_1-rmse:0.40298\n",
      "[32]\tvalidation_0-rmse:0.39424\tvalidation_1-rmse:0.40260\n",
      "[33]\tvalidation_0-rmse:0.39312\tvalidation_1-rmse:0.40172\n",
      "[34]\tvalidation_0-rmse:0.39242\tvalidation_1-rmse:0.40113\n",
      "[35]\tvalidation_0-rmse:0.39198\tvalidation_1-rmse:0.40088\n",
      "[36]\tvalidation_0-rmse:0.39118\tvalidation_1-rmse:0.40010\n",
      "[37]\tvalidation_0-rmse:0.39083\tvalidation_1-rmse:0.39988\n",
      "[38]\tvalidation_0-rmse:0.39044\tvalidation_1-rmse:0.39979\n",
      "[39]\tvalidation_0-rmse:0.38984\tvalidation_1-rmse:0.39933\n",
      "[40]\tvalidation_0-rmse:0.38889\tvalidation_1-rmse:0.39854\n",
      "[41]\tvalidation_0-rmse:0.38801\tvalidation_1-rmse:0.39764\n",
      "[42]\tvalidation_0-rmse:0.38761\tvalidation_1-rmse:0.39756\n",
      "[43]\tvalidation_0-rmse:0.38744\tvalidation_1-rmse:0.39746\n",
      "[44]\tvalidation_0-rmse:0.38716\tvalidation_1-rmse:0.39740\n",
      "[45]\tvalidation_0-rmse:0.38692\tvalidation_1-rmse:0.39719\n",
      "[46]\tvalidation_0-rmse:0.38651\tvalidation_1-rmse:0.39704\n",
      "[47]\tvalidation_0-rmse:0.38625\tvalidation_1-rmse:0.39689\n",
      "[48]\tvalidation_0-rmse:0.38582\tvalidation_1-rmse:0.39655\n",
      "[49]\tvalidation_0-rmse:0.38538\tvalidation_1-rmse:0.39623\n",
      "[50]\tvalidation_0-rmse:0.38477\tvalidation_1-rmse:0.39578\n",
      "[51]\tvalidation_0-rmse:0.38438\tvalidation_1-rmse:0.39544\n",
      "[52]\tvalidation_0-rmse:0.38366\tvalidation_1-rmse:0.39509\n",
      "[53]\tvalidation_0-rmse:0.38339\tvalidation_1-rmse:0.39500\n",
      "[54]\tvalidation_0-rmse:0.38315\tvalidation_1-rmse:0.39495\n",
      "[55]\tvalidation_0-rmse:0.38259\tvalidation_1-rmse:0.39453\n",
      "[56]\tvalidation_0-rmse:0.38234\tvalidation_1-rmse:0.39435\n",
      "[57]\tvalidation_0-rmse:0.38192\tvalidation_1-rmse:0.39405\n",
      "[58]\tvalidation_0-rmse:0.38175\tvalidation_1-rmse:0.39393\n",
      "[59]\tvalidation_0-rmse:0.38149\tvalidation_1-rmse:0.39372\n",
      "[60]\tvalidation_0-rmse:0.38126\tvalidation_1-rmse:0.39360\n",
      "[61]\tvalidation_0-rmse:0.38108\tvalidation_1-rmse:0.39349\n",
      "[62]\tvalidation_0-rmse:0.38077\tvalidation_1-rmse:0.39321\n",
      "[63]\tvalidation_0-rmse:0.38058\tvalidation_1-rmse:0.39310\n",
      "[64]\tvalidation_0-rmse:0.38043\tvalidation_1-rmse:0.39309\n",
      "[65]\tvalidation_0-rmse:0.38035\tvalidation_1-rmse:0.39307\n",
      "[66]\tvalidation_0-rmse:0.38014\tvalidation_1-rmse:0.39297\n",
      "[67]\tvalidation_0-rmse:0.38000\tvalidation_1-rmse:0.39291\n",
      "[68]\tvalidation_0-rmse:0.37976\tvalidation_1-rmse:0.39283\n",
      "[69]\tvalidation_0-rmse:0.37958\tvalidation_1-rmse:0.39273\n",
      "[70]\tvalidation_0-rmse:0.37924\tvalidation_1-rmse:0.39271\n",
      "[71]\tvalidation_0-rmse:0.37920\tvalidation_1-rmse:0.39269\n",
      "[72]\tvalidation_0-rmse:0.37909\tvalidation_1-rmse:0.39265\n",
      "[73]\tvalidation_0-rmse:0.37874\tvalidation_1-rmse:0.39239\n",
      "[74]\tvalidation_0-rmse:0.37849\tvalidation_1-rmse:0.39232\n",
      "[75]\tvalidation_0-rmse:0.37817\tvalidation_1-rmse:0.39208\n",
      "[76]\tvalidation_0-rmse:0.37800\tvalidation_1-rmse:0.39195\n",
      "[77]\tvalidation_0-rmse:0.37792\tvalidation_1-rmse:0.39192\n",
      "[78]\tvalidation_0-rmse:0.37772\tvalidation_1-rmse:0.39177\n",
      "[79]\tvalidation_0-rmse:0.37743\tvalidation_1-rmse:0.39158\n",
      "[80]\tvalidation_0-rmse:0.37717\tvalidation_1-rmse:0.39147\n",
      "[81]\tvalidation_0-rmse:0.37695\tvalidation_1-rmse:0.39139\n",
      "[82]\tvalidation_0-rmse:0.37684\tvalidation_1-rmse:0.39132\n",
      "[83]\tvalidation_0-rmse:0.37673\tvalidation_1-rmse:0.39127\n",
      "[84]\tvalidation_0-rmse:0.37652\tvalidation_1-rmse:0.39126\n",
      "[85]\tvalidation_0-rmse:0.37632\tvalidation_1-rmse:0.39113\n",
      "[86]\tvalidation_0-rmse:0.37618\tvalidation_1-rmse:0.39114\n",
      "[87]\tvalidation_0-rmse:0.37605\tvalidation_1-rmse:0.39105\n",
      "[88]\tvalidation_0-rmse:0.37567\tvalidation_1-rmse:0.39075\n",
      "[89]\tvalidation_0-rmse:0.37554\tvalidation_1-rmse:0.39065\n",
      "[90]\tvalidation_0-rmse:0.37535\tvalidation_1-rmse:0.39056\n",
      "[91]\tvalidation_0-rmse:0.37468\tvalidation_1-rmse:0.38990\n",
      "[92]\tvalidation_0-rmse:0.37449\tvalidation_1-rmse:0.38981\n",
      "[93]\tvalidation_0-rmse:0.37423\tvalidation_1-rmse:0.38962\n",
      "[94]\tvalidation_0-rmse:0.37403\tvalidation_1-rmse:0.38946\n",
      "[95]\tvalidation_0-rmse:0.37398\tvalidation_1-rmse:0.38949\n",
      "[96]\tvalidation_0-rmse:0.37365\tvalidation_1-rmse:0.38930\n",
      "[97]\tvalidation_0-rmse:0.37287\tvalidation_1-rmse:0.38856\n",
      "[98]\tvalidation_0-rmse:0.37267\tvalidation_1-rmse:0.38851\n",
      "[99]\tvalidation_0-rmse:0.37259\tvalidation_1-rmse:0.38850\n",
      "[100]\tvalidation_0-rmse:0.37226\tvalidation_1-rmse:0.38829\n",
      "[101]\tvalidation_0-rmse:0.37214\tvalidation_1-rmse:0.38831\n",
      "[102]\tvalidation_0-rmse:0.37178\tvalidation_1-rmse:0.38804\n",
      "[103]\tvalidation_0-rmse:0.37129\tvalidation_1-rmse:0.38751\n",
      "[104]\tvalidation_0-rmse:0.37105\tvalidation_1-rmse:0.38733\n",
      "[105]\tvalidation_0-rmse:0.37072\tvalidation_1-rmse:0.38710\n",
      "[106]\tvalidation_0-rmse:0.37056\tvalidation_1-rmse:0.38707\n",
      "[107]\tvalidation_0-rmse:0.37043\tvalidation_1-rmse:0.38705\n",
      "[108]\tvalidation_0-rmse:0.37033\tvalidation_1-rmse:0.38701\n",
      "[109]\tvalidation_0-rmse:0.37017\tvalidation_1-rmse:0.38690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=60, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy='depthwise', importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.4, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=110, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBRegressor(n_estimators = 110, early_stopping_rounds=60, learning_rate=0.4)\n",
    "xgb.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_val, y_val)], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS log-error train:  0.14556416036555803\n",
      "RMS log-error val:  0.14916261370334957\n",
      "RMS log-error train (actual):  0.37001666967804664\n",
      "RMS log-error val (actual):  0.3866786406166397\n"
     ]
    }
   ],
   "source": [
    "#if run_experiment_IV:\n",
    "y_pred_train = xgb.predict(X_train)\n",
    "y_pred_train[y_pred_train < 0] = 0\n",
    "y_pred_val = xgb.predict(X_val)\n",
    "y_pred_val[y_pred_val < 0] = 0\n",
    "\n",
    "print(\"RMS log-error train: \", np.sqrt(mean_squared_log_error(y_train, y_pred_train)))\n",
    "print(\"RMS log-error val: \", np.sqrt(mean_squared_log_error(y_val, y_pred_val)))\n",
    "print(\"RMS log-error train (actual): \",\n",
    "        np.sqrt(mean_squared_log_error(np.expm1(y_train), np.expm1(y_pred_train))))\n",
    "print(\"RMS log-error val (actual): \",\n",
    "        np.sqrt(mean_squared_log_error(np.expm1(y_val), np.expm1(y_pred_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment V -- SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "run_experiment_V = False  # slow\n",
    "if run_experiment_V:\n",
    "    # svr = SVR(C=1.0, epsilon=0.2)\n",
    "    svr = SVR(kernel='rbf')\n",
    "    svr.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_experiment_V:\n",
    "    y_pred_train = svr.predict(X_train)\n",
    "    y_pred_train[y_pred_train < 0] = 0\n",
    "    y_pred_val = svr.predict(X_val)\n",
    "    y_pred_val[y_pred_val < 0] = 0\n",
    "\n",
    "    print(\"RMS log-error train: \", np.sqrt(mean_squared_log_error(y_train, y_pred_train)))\n",
    "    print(\"RMS log-error val: \", np.sqrt(mean_squared_log_error(y_val, y_pred_val)))\n",
    "    print(\"RMS log-error train (actual): \",\n",
    "          np.sqrt(mean_squared_log_error(np.expm1(y_train), np.expm1(y_pred_train))))\n",
    "    print(\"RMS log-error val (actual): \",\n",
    "          np.sqrt(mean_squared_log_error(np.expm1(y_val), np.expm1(y_pred_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test (Moment of Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16\n",
       "1    16\n",
       "2    16\n",
       "3    16\n",
       "4    16\n",
       "Name: day_of_month, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['day_of_month'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28512, 151)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()\n",
    "X_test_mod = X_test.copy()\n",
    "# pred = xgb.predict(X_test_mod[X_test_mod['day_of_month'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_predict(model, X_test):\n",
    "    X_test_mod = X_test.copy()\n",
    "    output = np.array([])\n",
    "    start_day, end_day = X_test['day_of_month'].min(), X_test['day_of_month'].max()\n",
    "        # we lost the dates, but we still have day_of_month, which is good enough for our experiment\n",
    "        \n",
    "    for day in range(start_day, end_day + 1):\n",
    "        pred = model.predict(X_test_mod[X_test_mod['day_of_month'] == day])\n",
    "        pred[pred < 0] = 0\n",
    "        print(pred)\n",
    "        print(pred.shape)\n",
    "        output = np.concatenate([output, pred], axis=0)\n",
    "        for future in range(day + 1, end_day + 1):\n",
    "            X_test_mod.loc[X_test_mod[X_test_mod['day_of_month'] == future].index,f'sales_lag_{(future - day):02d}'] = pred\n",
    "            # fill out future values now that this sales figure is available\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "            ...\n",
       "            1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781],\n",
       "           dtype='int64', length=1782)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mod[X_test_mod['day_of_month'] == 16].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6163301  0.05990369 1.7578124  ... 7.614691   5.3166647  2.7478967 ]\n",
      "(1782,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 151, got 166",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [143]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mmain_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [141]\u001b[0m, in \u001b[0;36mmain_predict\u001b[0;34m(model, X_test)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# we lost the dates, but we still have day_of_month, which is good enough for our experiment\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m day \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_day, end_day \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_mod\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test_mod\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mday_of_month\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     pred[pred \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1140\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m   1149\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:2268\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2265\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2266\u001b[0m         )\n\u001b[1;32m   2267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 2268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2269\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2270\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2271\u001b[0m         )\n\u001b[1;32m   2273\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   2274\u001b[0m     _array_interface,\n\u001b[1;32m   2275\u001b[0m     _is_cudf_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     _transform_pandas_df,\n\u001b[1;32m   2279\u001b[0m )\n\u001b[1;32m   2281\u001b[0m enable_categorical \u001b[38;5;241m=\u001b[39m _has_categorical(\u001b[38;5;28mself\u001b[39m, data)\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 151, got 166"
     ]
    }
   ],
   "source": [
    "y_pred_test = main_predict(xgb, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_index = 3008016 - 3000888  # we inserted 4 Christmas days, 4 x 54 x 33 = 7128, which is the difference\n",
    "#submission = pd.DataFrame({'id': X_test.index - delta_index, 'sales': np.expm1(y_pred_test)})\n",
    "#submission = pd.DataFrame({'id': X_test.index - delta_index, 'sales': max(y_pred_test, 0)})\n",
    "submission = pd.DataFrame({'id': X_test.index - delta_index, 'sales': np.expm1(y_pred_test)})\n",
    "submission.to_csv('submissionxgboostpca.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
